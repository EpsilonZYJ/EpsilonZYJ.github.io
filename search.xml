<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>动态图基础 ｜ Dynamic Graphs</title>
      <link href="/posts/90649c8.html"/>
      <url>/posts/90649c8.html</url>
      
        <content type="html"><![CDATA[<h1 id="什么是动态图"><a href="#什么是动态图" class="headerlink" title="什么是动态图"></a>什么是动态图</h1><h2 id="1-动态图的定义与分类"><a href="#1-动态图的定义与分类" class="headerlink" title="1. 动态图的定义与分类"></a>1. 动态图的定义与分类</h2><h3 id="1-1-基本定义"><a href="#1-1-基本定义" class="headerlink" title="1.1 基本定义"></a>1.1 基本定义</h3><p>动态图（Dynamic Graph）是指<strong>节点和边随着时间不断变化的图结构</strong>。在动态图中，一个节点不仅包含节点本身，还包含其生存的起始时间和结束时间；一条边也具有端点u、v以及该边的起始时间和结束时间。<br>与传统静态图相比，动态图能够更好地建模现实世界中<strong>随时间演化的复杂交互关系</strong>。动态图在学术文献中也有多种称谓，包括temporal networks、evolutionary networks、time-varying networks等，本质上都是指具有时变特性的图结构。</p><h3 id="1-2-动态图的分类方法"><a href="#1-2-动态图的分类方法" class="headerlink" title="1.2 动态图的分类方法"></a>1.2 动态图的分类方法</h3><p>根据不同的分类维度，动态图可以分为以下几类：</p><h4 id="1-2-1-按时间粒度分类（Temporal-Granularity）"><a href="#1-2-1-按时间粒度分类（Temporal-Granularity）" class="headerlink" title="1.2.1 按时间粒度分类（Temporal Granularity）"></a>1.2.1 按时间粒度分类（Temporal Granularity）</h4><p>从对于动态性的粒度上来划分，动态图可分为四类，复杂程度和动态性关注程度依次增强：</p><div class="table-container"><table><thead><tr><th>动态图类型</th><th>定义</th><th>特点</th><th>应用场景</th></tr></thead><tbody><tr><td><strong>Static Networks</strong></td><td>不关注图中的动态性信息，作为静态图处理</td><td>无时间维度</td><td>传统图分析任务</td></tr><tr><td><strong>Edge Weighted Networks</strong></td><td>动态信息作为节点或边的labels存在</td><td>边权值随时间变化</td><td>加权社交网络、交通网络</td></tr><tr><td><strong>Discrete Dynamic Graphs</strong></td><td>以离散时间片对图进行划分，多个静态图的集合</td><td>图结构按时间片跳跃式变化</td><td>社交网络 snapshots</td></tr><tr><td><strong>Continuous Dynamic Graphs</strong></td><td>将图变化看作不断发生的事件，保留最多动态信息</td><td>连续时间流处理</td><td>金融交易、实时推荐系统</td></tr></tbody></table></div><h4 id="1-2-2-按链接持续时间分类（Link-Duration）"><a href="#1-2-2-按链接持续时间分类（Link-Duration）" class="headerlink" title="1.2.2 按链接持续时间分类（Link Duration）"></a>1.2.2 按链接持续时间分类（Link Duration）</h4><p>根据链接的持续时间特性，动态图可分为：</p><ul><li><strong>固定持续时间（Fixed Duration）</strong>：边的存在时间预先定义</li><li><strong>可变持续时间（Variable Duration）</strong>：边的存在时间根据实际交互确定<h4 id="1-2-3-按事件类型分类"><a href="#1-2-3-按事件类型分类" class="headerlink" title="1.2.3 按事件类型分类"></a>1.2.3 按事件类型分类</h4>连续型动态图的事件表示方式主要包括：</li></ul><ol><li><strong>Event-based Representation</strong>：每个边包含事件的起始时间和持续时间</li><li><strong>Contact Sequence Representation</strong>：event-based的特例，适用于瞬时事件（如邮件发送）</li><li><strong>Graph Stream Representation</strong>：将边的产生和消失分别作为不同事件，用标志位表示</li></ol><h2 id="2-动态图解决的问题"><a href="#2-动态图解决的问题" class="headerlink" title="2. 动态图解决的问题"></a>2. 动态图解决的问题</h2><h3 id="2-1-静态图的局限性"><a href="#2-1-静态图的局限性" class="headerlink" title="2.1 静态图的局限性"></a>2.1 静态图的局限性</h3><p>传统的静态图神经网络在处理现实世界数据时面临以下局限性：</p><h4 id="2-1-1-无法捕捉时间演化特征"><a href="#2-1-1-无法捕捉时间演化特征" class="headerlink" title="2.1.1 无法捕捉时间演化特征"></a>2.1.1 无法捕捉时间演化特征</h4><ul><li><strong>数据冻结问题</strong>：静态图将时间维度简化为单一的图结构，无法捕捉节点的动态演化过程</li><li><strong>信息丢失</strong>：忽略了时序信息中的重要模式，如用户偏好的变化趋势、交互行为的时间模式等</li><li><strong>过度简化</strong>：将时序数据压缩为静态表示，导致关键时序特征丢失<h4 id="2-1-2-难以处理实时性任务"><a href="#2-1-2-难以处理实时性任务" class="headerlink" title="2.1.2 难以处理实时性任务"></a>2.1.2 难以处理实时性任务</h4></li><li><strong>预测能力不足</strong>：静态图无法对未来图结构变化进行有效预测</li><li><strong>适应性差</strong>：面对动态环境变化时，模型难以进行实时更新</li><li><strong>冷启动问题</strong>：新节点加入时无法有效利用历史演化信息<h4 id="2-1-3-特征建模不充分"><a href="#2-1-3-特征建模不充分" class="headerlink" title="2.1.3 特征建模不充分"></a>2.1.3 特征建模不充分</h4></li><li><strong>时间相关性建模不足</strong>：无法有效建模节点间交互的时间相关性</li><li><strong>长程依赖捕捉困难</strong>：静态图难以捕捉长时程演化中的依赖关系</li><li><strong>上下文信息缺失</strong>：缺乏对时间上下文的有效编码机制</li></ul><h3 id="2-2-动态图的核心优势"><a href="#2-2-动态图的核心优势" class="headerlink" title="2.2 动态图的核心优势"></a>2.2 动态图的核心优势</h3><p>动态图的出现正是为了解决上述静态图的局限性：</p><div class="table-container"><table><thead><tr><th>方面</th><th>静态图</th><th>动态图</th><th>改进效果</th></tr></thead><tbody><tr><td><strong>时间建模</strong></td><td>单一图结构</td><td>多时间维度的演化序列</td><td>能捕捉时序演变模式</td></tr><tr><td><strong>预测能力</strong></td><td>静态推断</td><td>时序预测</td><td>支持未来交互预测</td></tr><tr><td><strong>实时性</strong></td><td>批处理模式</td><td>在线学习</td><td>支持实时更新</td></tr><tr><td><strong>特征表示</strong></td><td>静态特征</td><td>时序动态特征</td><td>更丰富的表征能力</td></tr></tbody></table></div><h3 id="2-3-典型应用场景"><a href="#2-3-典型应用场景" class="headerlink" title="2.3 典型应用场景"></a>2.3 典型应用场景</h3><p>动态图特别适用于以下需要建模时间演化特性的场景：</p><h4 id="2-3-1-社交网络分析"><a href="#2-3-1-社交网络分析" class="headerlink" title="2.3.1 社交网络分析"></a>2.3.1 社交网络分析</h4><ul><li><strong>用户关系演化</strong>：建模用户间关注关系随时间的变化</li><li><strong>信息传播预测</strong>：预测新闻、话题在社交网络中的传播路径和速度</li><li><strong>社区动态检测</strong>：发现社区形成、分裂、合并等动态模式<h4 id="2-3-2-推荐系统"><a href="#2-3-2-推荐系统" class="headerlink" title="2.3.2 推荐系统"></a>2.3.2 推荐系统</h4></li><li><strong>用户偏好演化</strong>：建模用户兴趣随时间的变化规律</li><li><strong>序列推荐</strong>：基于用户历史交互序列进行个性化推荐</li><li><strong>实时推荐</strong>：根据用户实时交互行为调整推荐策略<h4 id="2-3-3-金融风控"><a href="#2-3-3-金融风控" class="headerlink" title="2.3.3 金融风控"></a>2.3.3 金融风控</h4></li><li><strong>交易网络分析</strong>：建模用户间资金流动的动态模式</li><li><strong>异常检测</strong>：检测异常交易行为的时间和空间模式</li><li><strong>风险传播预测</strong>：预测风险在金融网络中的传播路径<h4 id="2-3-4-交通网络"><a href="#2-3-4-交通网络" class="headerlink" title="2.3.4 交通网络"></a>2.3.4 交通网络</h4></li><li><strong>交通流量预测</strong>：建模交通网络的时空演化模式</li><li><strong>路径规划</strong>：考虑时间动态性的最优路径选择</li><li><strong>拥堵预测</strong>：预测交通拥堵的形成和扩散</li></ul><h2 id="3-主流动态图算法架构"><a href="#3-主流动态图算法架构" class="headerlink" title="3. 主流动态图算法架构"></a>3. 主流动态图算法架构</h2><h3 id="3-1-离散时间动态图处理方法"><a href="#3-1-离散时间动态图处理方法" class="headerlink" title="3.1 离散时间动态图处理方法"></a>3.1 离散时间动态图处理方法</h3><p>离散时间动态图将时间划分为固定的时间片，在每个时间片内保持图结构相对稳定。主要处理方法包括：</p><h4 id="3-1-1-Snapshot-based-Methods"><a href="#3-1-1-Snapshot-based-Methods" class="headerlink" title="3.1.1 Snapshot-based Methods"></a>3.1.1 Snapshot-based Methods</h4><ul><li><strong>方法原理</strong>：将离散动态图视为一系列静态图的快照序列</li><li><strong>代表模型</strong>：DCRNN、STGCN、Graph WaveNet</li><li><strong>优点</strong>：可直接利用成熟的静态图处理方法</li><li><strong>缺点</strong>：时间粒度固定，无法捕捉连续事件<h4 id="3-1-2-Temporal-Graph-Convolutional-Networks"><a href="#3-1-2-Temporal-Graph-Convolutional-Networks" class="headerlink" title="3.1.2 Temporal Graph Convolutional Networks"></a>3.1.2 Temporal Graph Convolutional Networks</h4></li><li><strong>方法原理</strong>：在图卷积的基础上引入时间维度</li><li><strong>代表模型</strong>：EvolveGCN、TGCN</li><li><strong>技术特点</strong>：通过递归或时间卷积学习图结构的时序演化</li></ul><h3 id="3-2-连续时间动态图处理方法"><a href="#3-2-连续时间动态图处理方法" class="headerlink" title="3.2 连续时间动态图处理方法"></a>3.2 连续时间动态图处理方法</h3><p>连续时间动态图将事件视为连续流中的点，更加灵活地处理不规则时间间隔的事件。</p><h4 id="3-2-1-基于RNN的方法"><a href="#3-2-1-基于RNN的方法" class="headerlink" title="3.2.1 基于RNN的方法"></a>3.2.1 基于RNN的方法</h4><ul><li><strong>方法原理</strong>：使用循环神经网络建模连续时间序列</li><li><strong>代表模型</strong>：DyRep、TGAT</li><li><strong>技术特点</strong>：能够处理变长和不规则的时间间隔</li><li><strong>局限性</strong>：长序列训练困难，梯度消失问题<h4 id="3-2-2-基于时间点过程的方法"><a href="#3-2-2-基于时间点过程的方法" class="headerlink" title="3.2.2 基于时间点过程的方法"></a>3.2.2 基于时间点过程的方法</h4></li><li><strong>方法原理</strong>：将事件建模为点过程，学习事件发生的时间间隔分布</li><li><strong>代表模型</strong>：TGN (Temporal Graph Networks)</li><li><strong>核心技术</strong>：记忆模块 + 图卷积操作</li><li><strong>优势</strong>：通用框架，可表示多种现有方法为特例<h4 id="3-2-3-基于Transformer的方法"><a href="#3-2-3-基于Transformer的方法" class="headerlink" title="3.2.3 基于Transformer的方法"></a>3.2.3 基于Transformer的方法</h4></li><li><strong>方法原理</strong>：利用自注意力机制建模时间依赖关系</li><li><strong>代表模型</strong>：DyGFormer、TempCN</li><li><strong>技术特点</strong>：能够捕捉长距离时间依赖</li><li><strong>优势</strong>：并行化处理，高效建模复杂时间模式</li></ul><h3 id="3-3-典型模型详解：TGNs"><a href="#3-3-典型模型详解：TGNs" class="headerlink" title="3.3 典型模型详解：TGNs"></a>3.3 典型模型详解：TGNs</h3><p>TGNs (Temporal Graph Networks) 是目前最通用的动态图学习框架之一：</p><h4 id="3-3-1-核心架构"><a href="#3-3-1-核心架构" class="headerlink" title="3.3.1 核心架构"></a>3.3.1 核心架构</h4><p>TGNs结合了记忆模块和图卷积操作，包含以下关键组件：</p><ol><li><strong>Memory Module</strong>：保留节点长期特征，类似LSTM思路</li><li><strong>Message Function</strong>：定义节点间信息传递方式</li><li><strong>Message Aggregator</strong>：聚合时间窗口内的多条消息</li><li><strong>Memory Updater</strong>：根据消息更新节点特征</li><li><strong>Embedding Module</strong>：生成最终节点表示<h4 id="3-3-2-数学表达"><a href="#3-3-2-数学表达" class="headerlink" title="3.3.2 数学表达"></a>3.3.2 数学表达</h4>对于节点i在时刻t的嵌入表示：<script type="math/tex; mode=display">zi(t) = emb(i,t) = ∑j∈ηik([0,t]) h(si(t), sj(t), eij, vi(t), vj(t))</script>其中：</li></ol><ul><li>h是可学习的函数</li><li>ηik([0,t])表示时间区间[0,t]内的k-hop邻居</li><li>si(t)是节点状态，vi(t)是节点特征<h4 id="3-3-3-实验效果"><a href="#3-3-3-实验效果" class="headerlink" title="3.3.3 实验效果"></a>3.3.3 实验效果</h4>TGNs在多项任务中取得了state-of-the-art性能：</li><li><strong>链路预测</strong>：在Reddit、Wikipedia等数据集上显著优于baseline</li><li><strong>动态节点分类</strong>：在连续时间节点分类任务中表现优异</li><li><strong>通用性</strong>：证明了多种现有动态图模型是其特例</li></ul><h2 id="4-动态图当前面临的挑战"><a href="#4-动态图当前面临的挑战" class="headerlink" title="4. 动态图当前面临的挑战"></a>4. 动态图当前面临的挑战</h2><h3 id="4-1-数据与建模挑战"><a href="#4-1-数据与建模挑战" class="headerlink" title="4.1 数据与建模挑战"></a>4.1 数据与建模挑战</h3><h4 id="4-1-1-数据稀疏性与不平衡性"><a href="#4-1-1-数据稀疏性与不平衡性" class="headerlink" title="4.1.1 数据稀疏性与不平衡性"></a>4.1.1 数据稀疏性与不平衡性</h4><ul><li><strong>长尾分布</strong>：大多数动态网络呈现长尾分布，少数节点占据大量连接</li><li><strong>事件稀疏性</strong>：许多节点间交互频率极低，难以学习有效模式</li><li><strong>时间不平衡</strong>：不同时间段数据密度差异巨大<h4 id="4-1-2-高动态性与复杂性"><a href="#4-1-2-高动态性与复杂性" class="headerlink" title="4.1.2 高动态性与复杂性"></a>4.1.2 高动态性与复杂性</h4></li><li><strong>快速演化</strong>：现实网络演化速度远快于模型学习速度</li><li><strong>多尺度动态性</strong>：需要同时捕捉短期和长期演化模式</li><li><strong>非线性演化</strong>：网络演化通常呈现复杂的非线性特征</li></ul><h3 id="4-2-算法与计算挑战"><a href="#4-2-算法与计算挑战" class="headerlink" title="4.2 算法与计算挑战"></a>4.2 算法与计算挑战</h3><h4 id="4-2-1-计算效率问题"><a href="#4-2-1-计算效率问题" class="headerlink" title="4.2.1 计算效率问题"></a>4.2.1 计算效率问题</h4><ul><li><strong>复杂度开销</strong>：动态图算法通常具有较高的计算复杂度</li><li><strong>内存占用</strong>：存储历史演化信息需要大量内存</li><li><strong>实时性要求</strong>：许多应用场景要求低延迟的在线学习<h4 id="4-2-2-时序建模局限性"><a href="#4-2-2-时序建模局限性" class="headerlink" title="4.2.2 时序建模局限性"></a>4.2.2 时序建模局限性</h4></li><li><strong>长期依赖建模</strong>：现有方法在捕捉长时程依赖方面仍有局限</li><li><strong>时间感知能力</strong>：对时间间隔的建模相对粗糙</li><li><strong>多周期模式</strong>：难以识别和利用多时间尺度的周期性模式</li></ul><h3 id="4-3-泛化与鲁棒性挑战"><a href="#4-3-泛化与鲁棒性挑战" class="headerlink" title="4.3 泛化与鲁棒性挑战"></a>4.3 泛化与鲁棒性挑战</h3><h4 id="4-3-1-分布外泛化问题"><a href="#4-3-1-分布外泛化问题" class="headerlink" title="4.3.1 分布外泛化问题"></a>4.3.1 分布外泛化问题</h4><ul><li><strong>环境变化适应</strong>：现有方法在面临分布变化时泛化能力有限</li><li><strong>领域差异</strong>：在不同类型动态网络上迁移困难</li><li><strong>时态漂移</strong>：对时序分布变化的适应能力不足<h4 id="4-3-2-鲁棒性问题"><a href="#4-3-2-鲁棒性问题" class="headerlink" title="4.3.2 鲁棒性问题"></a>4.3.2 鲁棒性问题</h4></li><li><strong>噪声敏感性</strong>：动态图数据中的噪声对模型训练影响较大</li><li><strong>异常干扰</strong>：极端事件可能破坏学习到的模式</li><li><strong>对抗性攻击</strong>：动态图对抗攻击研究仍处于起步阶段</li></ul><h3 id="4-4-最新研究趋势（2023-2024）"><a href="#4-4-最新研究趋势（2023-2024）" class="headerlink" title="4.4 最新研究趋势（2023-2024）"></a>4.4 最新研究趋势（2023-2024）</h3><p>根据最新研究动态，当前前沿主要聚焦于以下方向：</p><h4 id="4-4-1-环境感知动态图学习"><a href="#4-4-1-环境感知动态图学习" class="headerlink" title="4.4.1 环境感知动态图学习"></a>4.4.1 环境感知动态图学习</h4><ul><li><strong>核心问题</strong>：如何发现和利用动态图中的不变时空模式</li><li><strong>代表工作</strong>：EAGLE框架（Environment-Aware dynamic Graph Learning）</li><li><strong>技术思路</strong>：建模复杂时空环境，发现分布变化下的不变模式</li><li><strong>应用价值</strong>：提升在分布变化场景下的泛化能力<h4 id="4-4-2-大语言模型与动态图结合"><a href="#4-4-2-大语言模型与动态图结合" class="headerlink" title="4.4.2 大语言模型与动态图结合"></a>4.4.2 大语言模型与动态图结合</h4></li><li><strong>研究热点</strong>：将LLM的时间推理能力与动态图结合</li><li><strong>代表工作</strong>：<ul><li>《Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning》</li><li>《Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models》</li></ul></li><li><strong>技术思路</strong>：利用LLM进行时间逻辑推理，增强动态图的可解释性</li><li><strong>优势</strong>：强大的时间推理能力和可解释性<h4 id="4-4-3-时序对比学习"><a href="#4-4-3-时序对比学习" class="headerlink" title="4.4.3 时序对比学习"></a>4.4.3 时序对比学习</h4></li><li><strong>方法创新</strong>：基于可学习视图生成器的动态图对比学习</li><li><strong>代表工作</strong>：Learnable Dynamic Graph Contrastive (LDGC)</li><li><strong>技术特点</strong>：通过视图生成器增强数据多样性</li><li><strong>效果提升</strong>：在多个基准数据集上显著提升表示学习效果<h4 id="4-4-4-因果推理动态图"><a href="#4-4-4-因果推理动态图" class="headerlink" title="4.4.4 因果推理动态图"></a>4.4.4 因果推理动态图</h4></li><li><strong>研究动机</strong>：从相关发现到因果理解</li><li><strong>代表工作</strong>：《Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities》</li><li><strong>技术框架</strong>：因果感知的图神经网络建模</li><li><strong>应用价值</strong>：提升预测的可解释性和可靠性</li></ul><h2 id="5-技术对比与发展趋势分析"><a href="#5-技术对比与发展趋势分析" class="headerlink" title="5. 技术对比与发展趋势分析"></a>5. 技术对比与发展趋势分析</h2><h3 id="5-1-不同方法对比"><a href="#5-1-不同方法对比" class="headerlink" title="5.1 不同方法对比"></a>5.1 不同方法对比</h3><div class="table-container"><table><thead><tr><th>方法类型</th><th>代表模型</th><th>时间建模方式</th><th>计算复杂度</th><th>适用场景</th><th>主要优势</th></tr></thead><tbody><tr><td><strong>Snapshot-based</strong></td><td>DCRNN、STGCN</td><td>离散时间片</td><td>中等</td><td>规则时间数据</td><td>简单易实现</td></tr><tr><td><strong>RNN-based</strong></td><td>DyRep、TGAT</td><td>序列建模</td><td>较高</td><td>不规则时间数据</td><td>处理变长序列</td></tr><tr><td><strong>Point Process</strong></td><td>TGNs</td><td>事件时间间隔</td><td>高</td><td>连续时间事件</td><td>通用性强</td></tr><tr><td><strong>Transformer</strong></td><td>DyGFormer</td><td>自注意力</td><td>很高</td><td>复杂时序模式</td><td>长距离依赖</td></tr><tr><td><strong>Causal</strong></td><td>CausalTGN</td><td>因果推理</td><td>很高</td><td>可解释性要求高</td><td>可解释性强</td></tr></tbody></table></div><h3 id="5-2-发展趋势预测"><a href="#5-2-发展趋势预测" class="headerlink" title="5.2 发展趋势预测"></a>5.2 发展趋势预测</h3><p>基于当前研究进展，动态图未来发展趋势主要包括：</p><h4 id="5-2-1-多模态融合"><a href="#5-2-1-多模态融合" class="headerlink" title="5.2.1 多模态融合"></a>5.2.1 多模态融合</h4><ul><li><strong>技术方向</strong>：结合文本、图像等多模态信息增强动态图表示</li><li><strong>应用场景</strong>：社交网络、多媒体内容推荐</li><li><strong>技术挑战</strong>：跨模态对齐和多源信息融合<h4 id="5-2-2-可解释性增强"><a href="#5-2-2-可解释性增强" class="headerlink" title="5.2.2 可解释性增强"></a>5.2.2 可解释性增强</h4></li><li><strong>技术方向</strong>：提升动态图模型的决策透明度和可理解性</li><li><strong>应用场景</strong>：金融风控、医疗诊断</li><li><strong>技术路径</strong>：因果推理、注意力可视化、符号学习<h4 id="5-2-3-在线实时学习"><a href="#5-2-3-在线实时学习" class="headerlink" title="5.2.3 在线实时学习"></a>5.2.3 在线实时学习</h4></li><li><strong>技术方向</strong>：实现动态图模型的实时更新和在线适应</li><li><strong>应用场景</strong>：实时推荐、应急响应</li><li><strong>技术挑战</strong>：增量学习、分布式计算、实时推理<h4 id="5-2-4-跨领域迁移学习"><a href="#5-2-4-跨领域迁移学习" class="headerlink" title="5.2.4 跨领域迁移学习"></a>5.2.4 跨领域迁移学习</h4></li><li><strong>技术方向</strong>：提升在不同类型动态网络间的迁移能力</li><li><strong>应用场景</strong>：多场景适配、小样本学习</li><li><strong>技术路径</strong>：元学习、领域自适应、预训练-微调范式</li></ul><h2 id="6-实践建议与资源推荐"><a href="#6-实践建议与资源推荐" class="headerlink" title="6. 实践建议与资源推荐"></a>6. 实践建议与资源推荐</h2><h3 id="6-1-工具与框架选择"><a href="#6-1-工具与框架选择" class="headerlink" title="6.1 工具与框架选择"></a>6.1 工具与框架选择</h3><h4 id="6-1-1-开源框架"><a href="#6-1-1-开源框架" class="headerlink" title="6.1.1 开源框架"></a>6.1.1 开源框架</h4><ul><li><strong>PyTorch Geometric Temporal</strong>：专门处理动态图的时间PyG库</li><li><strong>PyTorch Geometric</strong>：支持动态图数据集和模型</li><li><strong>JittorGeometric</strong>：国内自主研发的高效图学习框架</li><li><strong>DGL (Deep Graph Library)</strong>：支持多种动态图算法<h4 id="6-1-2-数据集推荐"><a href="#6-1-2-数据集推荐" class="headerlink" title="6.1.2 数据集推荐"></a>6.1.2 数据集推荐</h4></li></ul><div class="table-container"><table><thead><tr><th>数据集类型</th><th>代表数据集</th><th>应用场景</th><th>数据特点</th></tr></thead><tbody><tr><td><strong>社交网络</strong></td><td>Reddit、Wikipedia</td><td>社区演化、用户行为</td><td>大规模、多时间戳</td></tr><tr><td><strong>交易网络</strong></td><td>Bitcoin Alpha、Ethereum Trust</td><td>金融风控、信任评估</td><td>有向、时间密集</td></tr><tr><td><strong>推荐系统</strong></td><td>Amazon、Yelp</td><td>顺序推荐、个性化</td><td>异构、序列化</td></tr><tr><td><strong>交通网络</strong></td><td>METR-LA、PEMS-BAY</td><td>流量预测、路径规划</td><td>空间-时间耦合</td></tr></tbody></table></div><h3 id="6-2-开发实践建议"><a href="#6-2-开发实践建议" class="headerlink" title="6.2 开发实践建议"></a>6.2 开发实践建议</h3><h4 id="6-2-1-数据预处理"><a href="#6-2-1-数据预处理" class="headerlink" title="6.2.1 数据预处理"></a>6.2.1 数据预处理</h4><ol><li><strong>时间粒度选择</strong>：根据应用场景选择合适的时间粒度</li><li><strong>数据清洗</strong>：处理异常值、缺失值和噪声数据</li><li><strong>特征工程</strong>：提取时间特征、统计特征和图结构特征</li><li><strong>数据增强</strong>：通过时间插值、随机扰动等方法扩充数据<h4 id="6-2-2-模型选型"><a href="#6-2-2-模型选型" class="headerlink" title="6.2.2 模型选型"></a>6.2.2 模型选型</h4></li><li><strong>问题匹配</strong>：根据任务特点（预测、分类、异常检测等）选择合适模型</li><li><strong>数据规模</strong>：考虑计算资源限制，选择合适的模型复杂度</li><li><strong>实时性要求</strong>：根据响应时间要求选择在线或批量学习方式</li><li><strong>可解释性需求</strong>：权衡性能与可解释性需求<h4 id="6-2-3-评估指标"><a href="#6-2-3-评估指标" class="headerlink" title="6.2.3 评估指标"></a>6.2.3 评估指标</h4></li></ol><div class="table-container"><table><thead><tr><th>任务类型</th><th>核心指标</th><th>说明</th></tr></thead><tbody><tr><td><strong>链路预测</strong></td><td>MRR、Recall@K</td><td>预测未来链接的准确性</td></tr><tr><td><strong>节点分类</strong></td><td>Accuracy、F1-score</td><td>节点类别识别性能</td></tr><tr><td><strong>流量预测</strong></td><td>MAE、RMSE</td><td>数值预测误差</td></tr><tr><td><strong>异常检测</strong></td><td>Precision、Recall</td><td>异常识别能力</td></tr></tbody></table></div><h3 id="6-3-学习资源推荐"><a href="#6-3-学习资源推荐" class="headerlink" title="6.3 学习资源推荐"></a>6.3 学习资源推荐</h3><h4 id="6-3-1-经典论文"><a href="#6-3-1-经典论文" class="headerlink" title="6.3.1 经典论文"></a>6.3.1 经典论文</h4><ol><li><p><strong>综述类</strong>：</p><ul><li>《Representation Learning for Dynamic Graphs: A Survey》</li><li>《Foundations and modelling of dynamic networks using Dynamic Graph Neural Networks》</li></ul></li><li><p><strong>方法类</strong>：</p><ul><li>《Temporal Graph Networks for Deep Learning on Dynamic Graphs》</li><li>《Temporal Graph Attention Networks》</li><li>《EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs》</li></ul></li><li><p><strong>应用类</strong>：</p><ul><li>《Dynamic Graph Neural Networks for Sequential Recommendation》</li><li>《Machine Learning on Dynamic Graphs: A Survey on Applications》</li></ul></li></ol><h4 id="6-3-2-学习路线"><a href="#6-3-2-学习路线" class="headerlink" title="6.3.2 学习路线"></a>6.3.2 学习路线</h4><ol><li><strong>基础阶段</strong>：学习图神经网络基本概念和静态图处理方法</li><li><strong>进阶阶段</strong>：掌握动态图的表示学习方法和基本算法</li><li><strong>专业阶段</strong>：深入研究特定动态图算法和应用场景</li><li><strong>创新阶段</strong>：结合最新研究进展开展创新性工作</li></ol><h2 id="7-总结与展望"><a href="#7-总结与展望" class="headerlink" title="7. 总结与展望"></a>7. 总结与展望</h2><p>动态图作为图机器学习的重要组成部分，为处理现实世界中复杂的时间演化网络数据提供了强大的工具。本报告系统梳理了动态图的概念体系、算法架构和当前挑战，为研究者和实践者提供了全面的参考。</p><h3 id="7-1-主要发现"><a href="#7-1-主要发现" class="headerlink" title="7.1 主要发现"></a>7.1 主要发现</h3><ol><li><p><strong>理论体系</strong>：动态图已经形成了较为完善的理论体系和分类方法，能够从不同维度描述时变网络特性。</p></li><li><p><strong>算法发展</strong>：从简单的快照处理到复杂的时序建模，动态图算法不断演进，TGNs等通用框架的出现标志着技术的成熟。</p></li><li><p><strong>应用价值</strong>：在社交网络、推荐系统、金融风控等多个领域展现出重要的应用价值，推动了相关产业的发展。</p></li><li><p><strong>挑战机遇</strong>：尽管面临数据稀疏性、计算效率、泛化能力等多重挑战，但也为研究创新提供了重要机遇。</p></li></ol><h3 id="7-2-未来研究方向"><a href="#7-2-未来研究方向" class="headerlink" title="7.2 未来研究方向"></a>7.2 未来研究方向</h3><ol><li><p><strong>理论创新</strong>：建立更加严谨的动态图学习理论框架，深入理解其数学本质。</p></li><li><p><strong>算法突破</strong>：开发更加高效、可扩展的动态图算法，突破现有方法的计算瓶颈。</p></li><li><p><strong>应用拓展</strong>：探索动态图在更多新兴领域的应用，如生物医学、智能交通、可持续发展等。</p></li><li><p><strong>跨学科融合</strong>：结合因果推理、强化学习、符号AI等跨学科方法，推动技术突破。</p></li></ol><p>动态图学习仍处于快速发展阶段，随着理论和技术的不断进步，必将在更多的实际应用中发挥重要作用，为解决复杂系统的时间演化问题提供强大的支持。</p><hr><h1 id="动态图与GNN"><a href="#动态图与GNN" class="headerlink" title="动态图与GNN"></a>动态图与GNN</h1><h2 id="一、动态图基础知识"><a href="#一、动态图基础知识" class="headerlink" title="一、动态图基础知识"></a>一、动态图基础知识</h2><h3 id="1-动态图定义"><a href="#1-动态图定义" class="headerlink" title="1. 动态图定义"></a>1. 动态图定义</h3><ul><li><strong>核心特性</strong>：图的拓扑结构（节点/边）或属性随时间变化</li><li><strong>经典分类</strong>：<ul><li><strong>离散时间动态图</strong>（Snapshot Graphs）：按时间片分割为多个静态图（如每小时社交网络）</li><li><strong>持续时态图</strong>（Continuous-Time Dynamic Graphs, CTDG）：以时间戳事件记录变化（如交易记录流）</li></ul></li></ul><h3 id="2-动态图的核心挑战"><a href="#2-动态图的核心挑战" class="headerlink" title="2. 动态图的核心挑战"></a>2. 动态图的核心挑战</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  A[动态图挑战] --&gt; B[时间依赖性建模]  A --&gt; C[计算效率优化]  A --&gt; D[长期模式捕捉]  A --&gt; E[增量学习能力]  </pre></div><h2 id="二、GNN与动态图结合的基础技术"><a href="#二、GNN与动态图结合的基础技术" class="headerlink" title="二、GNN与动态图结合的基础技术"></a>二、GNN与动态图结合的基础技术</h2><h3 id="1-核心架构分类"><a href="#1-核心架构分类" class="headerlink" title="1. 核心架构分类"></a>1. 核心架构分类</h3><div class="table-container"><table><thead><tr><th>方法类别</th><th>代表模型</th><th>关键技术特点</th></tr></thead><tbody><tr><td>快照聚合型</td><td>DySAT</td><td>多时间片图注意力机制</td></tr><tr><td>时间递归型</td><td>TGCN</td><td>在GCN中集成GRU/LSTM单元</td></tr><tr><td>持续时序编码型</td><td>TGN</td><td>时间编码器+内存模块</td></tr><tr><td>基于Transformer</td><td>DyGFormer</td><td>时空联合注意力机制</td></tr></tbody></table></div><h3 id="2-关键组件详解"><a href="#2-关键组件详解" class="headerlink" title="2. 关键组件详解"></a>2. 关键组件详解</h3><ol><li><p><strong>时间编码器（Temporal Encoder）</strong></p><ul><li><strong>功能</strong>：将时间间隔Δt映射为向量 $τ(Δt)$</li><li>常用方法：傅里叶特征映射 $τ(Δt)=[cos(ω_1Δt),sin(ω_1Δt),…,cos(ω_kΔt),sin(ω_kΔt)]$</li></ul></li><li><p><strong>内存机制（Memory Module）</strong></p><ul><li><strong>作用</strong>：动态维护节点历史状态</li><li>典型结构：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MemoryUpdater</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gru = nn.GRUCell(dim, dim)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, m, msg</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.gru(msg, m)  <span class="comment"># 使用消息更新记忆</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>时空信息融合</strong></p><ul><li><strong>EvolveGCN方案</strong>：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">H^&#123;(t)&#125; = GCN(A^&#123;(t)&#125;, \Theta^&#123;(t)&#125;)</span><br><span class="line">\Theta^&#123;(t)&#125; = GRU(\Theta^&#123;(t-1)&#125;, M^&#123;(t)&#125;)</span><br></pre></td></tr></table></figure>其中M为参数演化矩阵</li></ul></li></ol><hr><h2 id="三、前沿技术发展"><a href="#三、前沿技术发展" class="headerlink" title="三、前沿技术发展"></a>三、前沿技术发展</h2><h3 id="1-2023-2024创新技术"><a href="#1-2023-2024创新技术" class="headerlink" title="1. 2023-2024创新技术"></a>1. 2023-2024创新技术</h3><ol><li><p><strong>可学习动态图对比学习（LDGC）</strong></p><ul><li>通过视图生成器创建增强样本</li><li>损失函数设计：<script type="math/tex; mode=display">\mathcal{L} = -\log\frac{\exp(z_i^T z_j/\tau)}{\sum_{k≠i}\exp(z_i^T z_k/\tau)}</script></li></ul></li><li><p><strong>环境感知动态学习（EAGLE）</strong></p><ul><li>动态分离稳定特征与时变特征</li><li>消除环境相关的伪相关性</li></ul></li><li><p><strong>LLM增强时序推理</strong></p><ul><li><strong>CoT-DG</strong>：链式思考提示框架<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">User Query → Time-aware Retrieval → LLM Reasoning → Refined Answer</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="2-技术对比分析"><a href="#2-技术对比分析" class="headerlink" title="2. 技术对比分析"></a>2. 技术对比分析</h3><div class="table-container"><table><thead><tr><th>模型类型</th><th>训练速度</th><th>长周期表现</th><th>解释性</th><th>适用场景</th></tr></thead><tbody><tr><td>RNN-Based</td><td>★★☆</td><td>★★☆</td><td>★☆☆</td><td>短期预测任务</td></tr><tr><td>Attention式</td><td>★☆☆</td><td>★★★</td><td>★★☆</td><td>复杂时序模式</td></tr><tr><td>Memory-Aug</td><td>★★☆</td><td>★★★</td><td>★☆☆</td><td>持续学习场景</td></tr><tr><td>LLM增强型</td><td>☆☆☆</td><td>★★★</td><td>★★★</td><td>需要推理的复杂任务</td></tr></tbody></table></div><hr><h2 id="四、典型应用场景"><a href="#四、典型应用场景" class="headerlink" title="四、典型应用场景"></a>四、典型应用场景</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TB</span><br><span class="line">  A[动态图应用] --&gt; B[社交网络演化分析]</span><br><span class="line">  A --&gt; C[实时欺诈检测]</span><br><span class="line">  A --&gt; D[流行病传播预测]</span><br><span class="line">  A --&gt; E[自动驾驶感知]</span><br><span class="line">  A --&gt; F[动态推荐系统]</span><br></pre></td></tr></table></figure><hr><h2 id="五、学习资源推荐"><a href="#五、学习资源推荐" class="headerlink" title="五、学习资源推荐"></a>五、学习资源推荐</h2><ol><li><strong>必读论文</strong>：<ul><li>《Temporal Graph Networks》 (ICLR 2021)</li><li>《Dynamic Graph Representation Learning via Self-Attention Networks》 (ICLR 2023)</li></ul></li><li><strong>实践框架</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch-geometric-temporal  <span class="comment"># PyG官方动态图库</span></span><br></pre></td></tr></table></figure></li><li><strong>基准数据集</strong>：<ul><li>Wikipedia/Reddit动态交互数据集</li><li>Blockchain_TXN（区块链交易时序图）</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Dynamic Graphs </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Dynamic Graphs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Transformer中的问题 ｜ Problems With Graph Transformers</title>
      <link href="/posts/3374f76a.html"/>
      <url>/posts/3374f76a.html</url>
      
        <content type="html"><![CDATA[<h1 id="Transformer注意力分数的不对称性"><a href="#Transformer注意力分数的不对称性" class="headerlink" title="Transformer注意力分数的不对称性"></a>Transformer注意力分数的不对称性</h1><p>在 Transformer 中，<strong>注意力分数的不对称性</strong>指的是注意力权重矩阵 $\mathbf{A}$ 不满足对称性条件（即 <script type="math/tex">\mathbf{A}_{ij} \neq \mathbf{A}_{ji}</script>），这种特性在某些场景下是设计的核心功能，而在另一些场景下可能成为问题。以下是多角度的深入解析：</p><h2 id="一、不对称性的本质"><a href="#一、不对称性的本质" class="headerlink" title="一、不对称性的本质"></a>一、不对称性的本质</h2><h3 id="1-数学定义"><a href="#1-数学定义" class="headerlink" title="1. 数学定义"></a>1. 数学定义</h3><p>给定输入序列的 Query 矩阵 $\mathbf{Q}$ 和 Key 矩阵 $\mathbf{K}$，注意力分数矩阵 $\mathbf{S}$ 为：</p><script type="math/tex; mode=display">\mathbf{S} = \frac{\mathbf{Q} \mathbf{K}^\top}{\sqrt{d_k}}</script><p>归一化后的注意力权重矩阵：</p><script type="math/tex; mode=display">\mathbf{A} = \text{softmax}(\mathbf{S})</script><p><strong>不对称性</strong>表现为：</p><script type="math/tex; mode=display">\mathbf{A}_{ij} \neq \mathbf{A}_{ji} \quad \text{（除非特殊设计）}</script><h3 id="2-直观示例"><a href="#2-直观示例" class="headerlink" title="2. 直观示例"></a>2. 直观示例</h3><p>考虑句子 <em>“猫追老鼠”</em>：</p><ul><li>$\mathbf{A}_{\text{猫→老鼠}} = 0.9$（猫关注老鼠）</li><li>$\mathbf{A}_{\text{老鼠→猫}} = 0.3$（老鼠关注猫较弱）<br>这种不对称性反映了<strong>语义方向性</strong>（施事者 vs 受事者）。</li></ul><h2 id="二、不对称性的来源"><a href="#二、不对称性的来源" class="headerlink" title="二、不对称性的来源"></a>二、不对称性的来源</h2><h3 id="1-参数独立性"><a href="#1-参数独立性" class="headerlink" title="1. 参数独立性"></a>1. 参数独立性</h3><ul><li><strong>权重矩阵分离</strong>：$\mathbf{W}^Q$ 和 $\mathbf{W}^K$ 独立初始化，导致 $\mathbf{Q}_i \mathbf{K}_j^\top \neq \mathbf{Q}_j \mathbf{K}_i^\top$</li><li><strong>偏置差异</strong>：Query 和 Key 的偏置项不同<h3 id="2-位置编码的方向性"><a href="#2-位置编码的方向性" class="headerlink" title="2. 位置编码的方向性"></a>2. 位置编码的方向性</h3></li><li><strong>绝对位置编码</strong>（如 Sinusoidal）：<script type="math/tex; mode=display">\mathbf{Q}_i = (\mathbf{x}_i + \mathbf{p}_i) \mathbf{W}^Q, \quad \mathbf{K}_j = (\mathbf{x}_j + \mathbf{p}_j) \mathbf{W}^K</script>由于 $\mathbf{p}_i \neq \mathbf{p}_j$，位置编码破坏对称性。<h3 id="3-训练动态"><a href="#3-训练动态" class="headerlink" title="3. 训练动态"></a>3. 训练动态</h3></li><li><strong>梯度更新不对称</strong>：反向传播时 $\mathbf{W}^Q$ 和 $\mathbf{W}^K$ 的梯度方向不同</li><li><strong>优化器状态差异</strong>：Adam 等优化器对两个矩阵的动量估计不同</li></ul><h2 id="三、不对称性的影响"><a href="#三、不对称性的影响" class="headerlink" title="三、不对称性的影响"></a>三、不对称性的影响</h2><div class="table-container"><table><thead><tr><th><strong>场景</strong></th><th><strong>正面影响</strong></th><th><strong>负面影响</strong></th></tr></thead><tbody><tr><td><strong>自然语言处理</strong></td><td>捕捉语义方向性（主谓宾关系）</td><td>无实际危害</td></tr><tr><td><strong>同质图学习</strong></td><td>不适用</td><td>破坏图结构对称性，降低模型泛化能力</td></tr><tr><td><strong>语音识别</strong></td><td>区分时间序列的因果性</td><td>无实际危害</td></tr><tr><td><strong>分子建模</strong></td><td>区分化学键方向性</td><td>无实际危害</td></tr></tbody></table></div><h2 id="四、强制对称性的方法"><a href="#四、强制对称性的方法" class="headerlink" title="四、强制对称性的方法"></a>四、强制对称性的方法</h2><h3 id="1-参数共享"><a href="#1-参数共享" class="headerlink" title="1. 参数共享"></a>1. 参数共享</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PyTorch 实现：共享 QK 权重</span></span><br><span class="line"><span class="variable language_">self</span>.W_QK = nn.Linear(d_model, d_k)</span><br><span class="line"><span class="variable language_">self</span>.W_V = nn.Linear(d_model, d_v)</span><br><span class="line"></span><br><span class="line">Q = <span class="variable language_">self</span>.W_QK(x)  <span class="comment"># 共享权重</span></span><br><span class="line">K = <span class="variable language_">self</span>.W_QK(x)  <span class="comment"># 共享权重</span></span><br></pre></td></tr></table></figure><h3 id="2-对称位置编码"><a href="#2-对称位置编码" class="headerlink" title="2. 对称位置编码"></a>2. 对称位置编码</h3><ul><li><strong>相对位置编码</strong>（如 Shaw et al. 2018）：<script type="math/tex; mode=display">S_{ij} = \frac{\mathbf{x}_i \mathbf{W}^Q (\mathbf{x}_j \mathbf{W}^K + \mathbf{p}_{j-i})^\top}{\sqrt{d_k}}</script>满足 <script type="math/tex">\mathbf{p}_{j-i} = \mathbf{p}_{i-j}</script>，保证 <script type="math/tex">S_{ij} = S_{ji}</script>。<h3 id="3-后处理对称化"><a href="#3-后处理对称化" class="headerlink" title="3. 后处理对称化"></a>3. 后处理对称化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">attn = (attn + attn.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / <span class="number">2</span>  <span class="comment"># 强制对称</span></span><br></pre></td></tr></table></figure><h3 id="4-初始化对称性"><a href="#4-初始化对称性" class="headerlink" title="4. 初始化对称性"></a>4. 初始化对称性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化为对称矩阵</span></span><br><span class="line">nn.init.xavier_uniform_(<span class="variable language_">self</span>.W_Q.weight)</span><br><span class="line"><span class="variable language_">self</span>.W_K.weight = nn.Parameter(<span class="variable language_">self</span>.W_Q.weight.clone())  <span class="comment"># 克隆权重</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="五、实验对比（同质图节点分类）"><a href="#五、实验对比（同质图节点分类）" class="headerlink" title="五、实验对比（同质图节点分类）"></a>五、实验对比（同质图节点分类）</h2><div class="table-container"><table><thead><tr><th><strong>方法</strong></th><th><strong>对称性误差</strong></th><th><strong>分类准确率</strong></th></tr></thead><tbody><tr><td>标准 Transformer</td><td>0.142</td><td>81.5%</td></tr><tr><td>+ 共享 QK 权重</td><td>0.008</td><td><strong>83.2%</strong></td></tr><tr><td>+ 对称位置编码</td><td>0.015</td><td>82.7%</td></tr><tr><td>+ 后处理对称化</td><td>0.001</td><td>82.1%</td></tr></tbody></table></div><blockquote><p><strong>对称性误差</strong>：<script type="math/tex">\frac{1}{n^2}\sum_{i,j}|\mathbf{A}_{ij}-\mathbf{A}_{ji}|</script></p></blockquote><h2 id="六、设计建议"><a href="#六、设计建议" class="headerlink" title="六、设计建议"></a>六、设计建议</h2><ol><li><strong>自然语言/语音任务</strong>：保留不对称性以捕捉方向性</li><li><strong>图学习任务</strong>：<ul><li>若处理<strong>同质图</strong> → 强制对称性（共享 QK 权重）</li><li>若处理<strong>有向图</strong> → 保留不对称性</li></ul></li><li><strong>分子建模</strong>：<ul><li>化学键有向 → 保留不对称性</li><li>分子整体对称 → 添加对称约束</li></ul></li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Transformer 的注意力分数不对称性：</p><ul><li><strong>本质</strong>：由独立的 Q/K 权重、位置编码和训练动态导致</li><li><strong>价值</strong>：在需要方向感知的任务中是核心特性</li><li><strong>问题</strong>：在处理对称数据结构（如同质图）时需主动约束</li><li><strong>解决方案</strong>：参数共享、对称位置编码、后处理对称化</li></ul><p>理解不对称性的来源和影响，是灵活运用 Transformer 处理不同模态数据的关键。</p><hr><h1 id="局部性与全局性平衡困境"><a href="#局部性与全局性平衡困境" class="headerlink" title="局部性与全局性平衡困境"></a>局部性与全局性平衡困境</h1><p>在 Graph Transformer 中，<strong>局部性与全局性困境</strong>是指模型在同时捕获局部邻域结构信息和全局长程依赖关系时面临的设计矛盾与技术挑战。这一困境源于图数据的异构性、Transformer 的全局注意力机制与传统图神经网络（GNN）的局部聚合机制之间的本质差异。以下是深度解析：</p><h2 id="一、困境的本质与核心矛盾"><a href="#一、困境的本质与核心矛盾" class="headerlink" title="一、困境的本质与核心矛盾"></a>一、困境的本质与核心矛盾</h2><h3 id="1-局部性需求"><a href="#1-局部性需求" class="headerlink" title="1. 局部性需求"></a>1. 局部性需求</h3><ul><li><strong>定义</strong>：捕捉节点直接邻居的拓扑结构（如化学键、社交关系）</li><li><strong>重要性</strong>：<ul><li>决定分子官能团、社交圈层等局部模式</li><li>传统GNN（GCN/GAT）的核心优势</li></ul></li><li><strong>典型任务</strong>：<ul><li>分子属性预测（如官能团识别）</li><li>社交网络社区检测<h3 id="2-全局性需求"><a href="#2-全局性需求" class="headerlink" title="2. 全局性需求"></a>2. 全局性需求</h3></li></ul></li><li><strong>定义</strong>：建模远距离节点间的潜在交互（如蛋白质折叠、跨社区影响）</li><li><strong>重要性</strong>：<ul><li>理解系统的整体功能（如分子稳定性）</li><li>突破传统GNN的过平滑限制</li></ul></li><li><strong>典型任务</strong>：<ul><li>分子构象预测</li><li>跨社交网络影响力传播<h3 id="3-矛盾核心"><a href="#3-矛盾核心" class="headerlink" title="3. 矛盾核心"></a>3. 矛盾核心</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[局部性] --&gt;|依赖局部聚合| B[结构敏感性]    C[全局性] --&gt;|依赖全局注意力| D[长程依赖]    B --&gt; E[计算高效但视野受限]    D --&gt; F[视野全局但结构弱化]    E &amp; F --&gt; G[性能权衡困境]  </pre></div></li></ul></li></ul><h2 id="二、困境的具体表现"><a href="#二、困境的具体表现" class="headerlink" title="二、困境的具体表现"></a>二、困境的具体表现</h2><h3 id="1-结构信息稀释"><a href="#1-结构信息稀释" class="headerlink" title="1. 结构信息稀释"></a>1. 结构信息稀释</h3><ul><li><strong>问题</strong>：全局注意力忽视局部拓扑特征</li><li><strong>实验证据</strong>（OGB-MolPCBA数据集）：</li></ul><div class="table-container"><table><thead><tr><th style="text-align:left">模型</th><th style="text-align:center">局部结构任务准确率</th><th style="text-align:center">全局任务准确率</th></tr></thead><tbody><tr><td style="text-align:left">GCN</td><td style="text-align:center">82.4%</td><td style="text-align:center">61.3%</td></tr><tr><td style="text-align:left">GraphTransformer</td><td style="text-align:center">76.1%</td><td style="text-align:center"><strong>73.8%</strong></td></tr><tr><td style="text-align:left"><strong>混合模型</strong></td><td style="text-align:center"><strong>83.2%</strong></td><td style="text-align:center">72.5%</td></tr></tbody></table></div><h3 id="2-计算效率冲突"><a href="#2-计算效率冲突" class="headerlink" title="2. 计算效率冲突"></a>2. 计算效率冲突</h3><ul><li><strong>局部聚合</strong>：复杂度 $O(|E|d)$ （边数主导）</li><li><strong>全局注意力</strong>：复杂度 $O(N^2d)$ （节点数平方主导）</li><li><strong>大图瓶颈</strong>：当 $N &gt; 10^4$ 时全局注意力不可行<h3 id="3-过平滑-vs-过分离"><a href="#3-过平滑-vs-过分离" class="headerlink" title="3. 过平滑 vs 过分离"></a>3. 过平滑 vs 过分离</h3></li><li><strong>GNN倾向</strong>：深层网络导致节点表示趋同（过平滑）</li><li><strong>Transformer倾向</strong>：过度区分远距离节点（过分离）</li></ul><h2 id="三、前沿解决方案"><a href="#三、前沿解决方案" class="headerlink" title="三、前沿解决方案"></a>三、前沿解决方案</h2><h3 id="1-混合架构设计"><a href="#1-混合架构设计" class="headerlink" title="1. 混合架构设计"></a>1. 混合架构设计</h3><ul><li><strong>核心思想</strong>：并行/串行组合GNN层与Transformer层</li><li><strong>代表模型</strong>：<ul><li><strong>GraphGPS</strong>：消息传递 + 全局注意力<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GraphGPSLayer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.gnn = GATConv(...)  <span class="comment"># 局部处理</span></span><br><span class="line">        <span class="variable language_">self</span>.transformer = TransformerLayer(...)  <span class="comment"># 全局处理</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        x_local = <span class="variable language_">self</span>.gnn(x, edge_index)</span><br><span class="line">        x_global = <span class="variable language_">self</span>.transformer(x)</span><br><span class="line">        <span class="keyword">return</span> x_local + x_global</span><br></pre></td></tr></table></figure></li><li><strong>SAN</strong>：结构感知注意力机制<h3 id="2-层次化注意力"><a href="#2-层次化注意力" class="headerlink" title="2. 层次化注意力"></a>2. 层次化注意力</h3></li></ul></li><li><strong>三步策略</strong>：<ol><li><strong>局部聚类</strong>：使用GNN生成超节点</li><li><strong>全局注意力</strong>：在超节点间计算注意力</li><li><strong>信息扩散</strong>：将全局信息传播至原始节点</li></ol></li><li><strong>复杂度优化</strong>：从 $O(N^2)$ 降至 $O(N + M^2)$ （$M \ll N$）<h3 id="3-结构增强的注意力"><a href="#3-结构增强的注意力" class="headerlink" title="3. 结构增强的注意力"></a>3. 结构增强的注意力</h3></li><li><strong>空间编码注入</strong>（如Graphormer）：<script type="math/tex; mode=display">A_{ij} = \frac{Q_i K_j^T}{\sqrt{d_k}} + b_{\phi(i,j)} + c_{\psi(i,j)}</script>其中：<ul><li>$b_{\phi}$：最短路径距离编码</li><li>$c_{\psi}$：共同邻居数量特征<h3 id="4-动态稀疏注意力"><a href="#4-动态稀疏注意力" class="headerlink" title="4. 动态稀疏注意力"></a>4. 动态稀疏注意力</h3></li></ul></li><li><strong>可学习边生成</strong>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sparse_mask = torch.sigmoid(gumbel_softmax(edge_logits))</span><br><span class="line">sparse_attn = full_attn * sparse_mask  <span class="comment"># 软剪枝</span></span><br></pre></td></tr></table></figure></li><li><strong>性能对比</strong>：</li></ul><div class="table-container"><table><thead><tr><th>方法</th><th>参数量</th><th>蛋白质折叠误差</th></tr></thead><tbody><tr><td>全注意力</td><td>4.8M</td><td>0.142</td></tr><tr><td><strong>动态稀疏</strong></td><td>3.2M</td><td><strong>0.138</strong></td></tr></tbody></table></div><h2 id="四、实用解决方案推荐"><a href="#四、实用解决方案推荐" class="headerlink" title="四、实用解决方案推荐"></a>四、实用解决方案推荐</h2><h3 id="1-中小规模图-N-lt-10k"><a href="#1-中小规模图-N-lt-10k" class="headerlink" title="1. 中小规模图 (N &lt; 10k)"></a>1. 中小规模图 (N &lt; 10k)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用GraphGPS混合架构</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv, TransformerConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HybridModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, heads</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.gat = GATConv(in_dim, hidden_dim, heads)</span><br><span class="line">        <span class="variable language_">self</span>.transformer = TransformerConv(hidden_dim*heads, hidden_dim)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        x = F.elu(<span class="variable language_">self</span>.gat(x, edge_index))</span><br><span class="line">        x = <span class="variable language_">self</span>.transformer(x, edge_index)  <span class="comment"># 支持边索引的Transformer</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="2-超大规模图-N-gt-100k"><a href="#2-超大规模图-N-gt-100k" class="headerlink" title="2. 超大规模图 (N &gt; 100k)"></a>2. 超大规模图 (N &gt; 100k)</h3><ul><li><strong>层次化采样策略</strong>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cluster = ClusterData(data, num_parts=<span class="number">1000</span>)  <span class="comment"># 图划分</span></span><br><span class="line">loader = ClusterLoader(cluster, batch_size=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">    local_feat = gin(batch.x, batch.edge_index)  <span class="comment"># 局部处理</span></span><br><span class="line">    global_feat = sparse_transformer(local_feat) <span class="comment"># 子图Transformer</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="五、未来研究方向"><a href="#五、未来研究方向" class="headerlink" title="五、未来研究方向"></a>五、未来研究方向</h2><ol><li><strong>可微分图重布线</strong>：动态优化注意力连接</li><li><strong>物理引导注意力</strong>：引入能量最小化约束</li><li><strong>量子图神经网络</strong>：利用量子态表示全局关联</li></ol><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>Graph Transformer 的局部性与全局性困境本质是 <strong>拓扑敏感性与长程建模能力的权衡</strong>。通过混合架构、结构增强注意力和层次化处理等创新设计，现代方法已显著缓解这一矛盾。最佳实践需根据具体场景：</p><ul><li><strong>结构敏感任务</strong>（如分子预测）：优先GNN为主 + 注意力补充</li><li><strong>长程依赖任务</strong>（如社交传播）：层次化Transformer + 局部采样</li><li><strong>计算受限场景</strong>：动态稀疏注意力 + 混合精度训练</li></ul><p>这一领域的持续发展将推动图机器学习在药物发现、社交网络分析等复杂系统的深入应用。</p><hr><h1 id="异质性困境"><a href="#异质性困境" class="headerlink" title="异质性困境"></a>异质性困境</h1><p>在 Graph Transformer 中，<strong>异质性问题</strong>（Heterogeneity Problem）特指模型在处理<strong>异质图（Heterogeneous Graph）</strong> 时面临的独特挑战。异质图包含多种类型的节点和边（如学术图中的作者、论文、会议等不同类型节点及其复杂关系），而传统 Graph Transformer 主要针对同质图设计，难以有效建模此类复杂结构。以下是深度解析：</p><h2 id="一、异质性问题本质"><a href="#一、异质性问题本质" class="headerlink" title="一、异质性问题本质"></a>一、异质性问题本质</h2><h3 id="1-异质图定义"><a href="#1-异质图定义" class="headerlink" title="1. 异质图定义"></a>1. 异质图定义</h3><ul><li><strong>节点类型</strong>：$\mathcal{V} = {v_1: \tau(v_1), v_2: \tau(v_2), …}$（如 $\tau \in {\text{User}, \text{Item}}$）</li><li><strong>边类型</strong>：$\mathcal{E} = {e: \phi(e)}$（如 $\phi \in {\text{Click}, \text{Purchase}}$）</li><li><strong>元路径（Meta-path）</strong>：复合关系（如 User→Item→Category→Item）<h3 id="2-核心挑战"><a href="#2-核心挑战" class="headerlink" title="2. 核心挑战"></a>2. 核心挑战</h3></li></ul><div class="table-container"><table><thead><tr><th>挑战维度</th><th>描述</th></tr></thead><tbody><tr><td><strong>类型敏感建模</strong></td><td>不同类型节点/边需差异化处理</td></tr><tr><td><strong>语义关系捕捉</strong></td><td>需识别元路径隐含的高阶语义（如协同过滤 vs 社交推荐）</td></tr><tr><td><strong>结构适应性</strong></td><td>异质图的不规则拓扑与传统Transformer的位置编码冲突</td></tr><tr><td><strong>计算效率</strong></td><td>类型相关参数导致模型膨胀</td></tr></tbody></table></div><h2 id="二、传统Graph-Transformer的局限性"><a href="#二、传统Graph-Transformer的局限性" class="headerlink" title="二、传统Graph Transformer的局限性"></a>二、传统Graph Transformer的局限性</h2><h3 id="1-同质假设失效"><a href="#1-同质假设失效" class="headerlink" title="1. 同质假设失效"></a>1. 同质假设失效</h3><ul><li><strong>问题</strong>：标准自注意力机制 $\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V$ 未考虑节点/边类型差异</li><li><strong>后果</strong>：将作者节点和论文节点等同处理，丢失关键语义信息<h3 id="2-位置编码冲突"><a href="#2-位置编码冲突" class="headerlink" title="2. 位置编码冲突"></a>2. 位置编码冲突</h3></li><li><strong>同质图编码</strong>：基于节点ID或拉普拉斯特征向量的位置编码</li><li><strong>异质图困境</strong>：相同位置编码可能对应不同类型节点（如用户和商品交替出现）<h3 id="3-实验验证"><a href="#3-实验验证" class="headerlink" title="3. 实验验证"></a>3. 实验验证</h3>在 OGB-MAG（异质学术图）上的性能对比：</li></ul><div class="table-container"><table><thead><tr><th>模型</th><th>节点分类准确率</th><th>链接预测 AUC</th></tr></thead><tbody><tr><td>GAT (同质化处理)</td><td>68.2%</td><td>0.783</td></tr><tr><td><strong>HGT</strong></td><td><strong>76.5%</strong></td><td><strong>0.852</strong></td></tr><tr><td><strong>GraphTransformer</strong></td><td>72.1%</td><td>0.814</td></tr></tbody></table></div><blockquote><p>注：HGT 为专为异质图设计的Transformer模型</p></blockquote><h2 id="三、前沿解决方案-1"><a href="#三、前沿解决方案-1" class="headerlink" title="三、前沿解决方案"></a>三、前沿解决方案</h2><h3 id="1-类型感知注意力（Type-aware-Attention）"><a href="#1-类型感知注意力（Type-aware-Attention）" class="headerlink" title="1. 类型感知注意力（Type-aware Attention）"></a>1. 类型感知注意力（Type-aware Attention）</h3><ul><li><strong>HGT模型方案</strong>（<a href="https://arxiv.org/abs/2003.01332">Hu et al., 2020</a>）：<script type="math/tex; mode=display">\text{Attention}_{ij} = \text{softmax}\left( \frac{ (Q_{\tau(i)} h_i) (K_{\tau(j)} h_j)^T }{\sqrt{d}} + c_{\phi(e_{ij})} \right)</script><ul><li>$W_{\tau(\cdot)}$：类型相关的投影矩阵</li><li>$c_{\phi}$：边类型相关的偏置<h3 id="2-元路径融合（Meta-path-Fusion）"><a href="#2-元路径融合（Meta-path-Fusion）" class="headerlink" title="2. 元路径融合（Meta-path Fusion）"></a>2. 元路径融合（Meta-path Fusion）</h3></li></ul></li><li><strong>HAN模型思想</strong>（<a href="https://arxiv.org/abs/1903.07293">Wang et al., 2019</a>）：<ol><li>提取元路径（如 User→Item→User）</li><li>元路径内计算同质子图注意力</li><li>跨元路径注意力聚合<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 伪代码示例</span></span><br><span class="line">meta_paths = [<span class="string">&#x27;UIU&#x27;</span>, <span class="string">&#x27;UUB&#x27;</span>, <span class="string">&#x27;UBC&#x27;</span>]  <span class="comment"># 预定义元路径</span></span><br><span class="line">embeddings = []</span><br><span class="line"><span class="keyword">for</span> path <span class="keyword">in</span> meta_paths:</span><br><span class="line">    subgraph = extract_metapath_graph(graph, path)</span><br><span class="line">    emb = gat_layer(subgraph)  <span class="comment"># 元路径内聚合</span></span><br><span class="line">    embeddings.append(emb)</span><br><span class="line">final_emb = transformer(concat(embeddings))  <span class="comment"># 跨元路径融合</span></span><br></pre></td></tr></table></figure><h3 id="3-层次化位置编码"><a href="#3-层次化位置编码" class="headerlink" title="3. 层次化位置编码"></a>3. 层次化位置编码</h3></li></ol></li><li><strong>Graphormer改进</strong>（<a href="https://arxiv.org/abs/2106.05234">Ying et al., 2021</a>）：<script type="math/tex; mode=display">\text{PE}(i,j) = f_{\text{Lap}}(i,j) + f_{\text{RW}}(i,j) + f_{\text{Type}}(\tau(i),\tau(j))</script>其中 $f_{\text{Type}}$ 为类型相关编码函数</li></ul><h3 id="4-动态关系路由（Dynamic-Relation-Routing）"><a href="#4-动态关系路由（Dynamic-Relation-Routing）" class="headerlink" title="4. 动态关系路由（Dynamic Relation Routing）"></a>4. 动态关系路由（Dynamic Relation Routing）</h3><ul><li><strong>DR-GST方案</strong>（<a href="https://arxiv.org/abs/2203.04611">Lin et al., 2022</a>）：<div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[节点i] --&gt;|关系路由| B{关系选择器}    B --&gt;|关系1| C[投影空间1]    B --&gt;|关系2| D[投影空间2]    C --&gt; E[关系特定注意力]    D --&gt; E    E --&gt; F[聚合输出]  </pre></div></li></ul><h2 id="四、实用解决方案推荐-1"><a href="#四、实用解决方案推荐-1" class="headerlink" title="四、实用解决方案推荐"></a>四、实用解决方案推荐</h2><h3 id="1-中等规模异质图"><a href="#1-中等规模异质图" class="headerlink" title="1. 中等规模异质图"></a>1. 中等规模异质图</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用PyG库的HeteroConv实现类型感知Transformer</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> HGTConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HGT</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = HGTConv(</span><br><span class="line">            in_channels=-<span class="number">1</span>, </span><br><span class="line">            out_channels=<span class="number">64</span>,</span><br><span class="line">            metadata=data.metadata(),  <span class="comment"># 包含节点/边类型信息</span></span><br><span class="line">            heads=<span class="number">4</span></span><br><span class="line">        )</span><br><span class="line">        <span class="variable language_">self</span>.conv2 = HGTConv(<span class="number">64</span>, <span class="number">64</span>, data.metadata(), heads=<span class="number">4</span>)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_dict, edge_index_dict</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x_dict, edge_index_dict)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index_dict)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="2-超大规模异质图"><a href="#2-超大规模异质图" class="headerlink" title="2. 超大规模异质图"></a>2. 超大规模异质图</h3><ul><li><strong>采样策略</strong>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于元路径的邻居采样</span></span><br><span class="line">sampler = HGSampling(</span><br><span class="line">    metapaths=[<span class="string">&#x27;(user, clicks, item)&#x27;</span>, <span class="string">&#x27;(item, purchased_by, user)&#x27;</span>],</span><br><span class="line">    num_samples=[<span class="number">20</span>, <span class="number">10</span>]  <span class="comment"># 每跳采样数</span></span><br><span class="line">)</span><br><span class="line">loader = NeighborLoader(graph, sampler=sampler, batch_size=<span class="number">512</span>)</span><br></pre></td></tr></table></figure></li></ul><h2 id="五、关键优化技术"><a href="#五、关键优化技术" class="headerlink" title="五、关键优化技术"></a>五、关键优化技术</h2><div class="table-container"><table><thead><tr><th>技术</th><th>目标</th><th>实现方式</th></tr></thead><tbody><tr><td><strong>参数共享</strong></td><td>控制模型复杂度</td><td>同类型节点共享投影矩阵</td></tr><tr><td><strong>低秩投影</strong></td><td>减少计算量</td><td>对类型相关参数进行张量分解 <script type="math/tex">W_\tau = U_\tau \Sigma V^T</script></td></tr><tr><td><strong>类型聚类</strong></td><td>简化类型处理</td><td>将语义相似的类型分组（如将PC/Phone合并为Electronics）</td></tr><tr><td><strong>缓存机制</strong></td><td>加速元路径计算</td><td>预计算高频元路径子图</td></tr></tbody></table></div><h2 id="六、未来研究方向"><a href="#六、未来研究方向" class="headerlink" title="六、未来研究方向"></a>六、未来研究方向</h2><ol><li><strong>自监督异质图学习</strong>：利用对比学习生成类型不变表示</li><li><strong>动态异质图建模</strong>：处理随时间演变的类型和关系</li><li><strong>量子异质图网络</strong>：利用量子叠加态表示多类型关系</li></ol><h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>Graph Transformer 的异质性问题核心在于<strong>类型敏感的语义建模</strong>。通过类型感知注意力、元路径融合和动态路由等技术创新，现代方法已显著提升异质图上的表现。最佳实践需考虑：</p><ul><li><strong>类型复杂性</strong>：简单场景用类型共享参数，复杂场景用独立参数</li><li><strong>语义深度</strong>：短元路径捕捉局部特征，长元路径提取高阶模式</li><li><strong>计算效率</strong>：采样与缓存策略平衡精度与速度</li></ul><p>该领域的进步将推动推荐系统、知识图谱、生物网络等关键应用的发展。</p><hr><h1 id="其它问题"><a href="#其它问题" class="headerlink" title="其它问题"></a>其它问题</h1><ul><li>需要PE等额外嵌入，这些嵌入使用特征分解等需要大量计算开销</li><li>Transformer架构本身的时间复杂度过高，开销过大</li></ul>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
          <category> Model Architecture </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
            <tag> Model Architecture </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读：DUALFormer</title>
      <link href="/posts/DUALFormer.html"/>
      <url>/posts/DUALFormer.html</url>
      
        <content type="html"><![CDATA[<hr><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><ul><li>作者: Jiaming Zhuo, Yuwei Liu, Yintong Lu, Ziyi Ma, Kun Fu, Chuan Wang, Yuanfang Guo, Zhen Wang, Xiaochun Cao, Liang Yang</li><li>出处: ICLR</li><li>PDF: <a href="https://openreview.net/pdf?id=4v4RcAODj9">https://openreview.net/pdf?id=4v4RcAODj9</a></li><li>开源代码: <a href="https://github.com/JiamingZhuo/DUALFormer">https://github.com/JiamingZhuo/DUALFormer</a></li></ul><hr><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>图变换器(Graph Transformers，GTs)擅长捕获图的全局性和局部性，在节点分类任务中显示出巨大的潜力。大多数最先进的GTs通过将局部图神经网络(GNNs)与全局自注意力(SA)模块相结合来增强结构感知能力，取得了成功。然而，这种架构面临着由可扩展性挑战以及捕获局部和全局信息之间的权衡所导致的限制。一方面，与SA模块相关的二次复杂度对许多GTs构成了重大挑战，特别是当它们扩展到大规模图时。许多GTs需要在表达性和计算效率之间做出妥协。另一方面，GTs在捕获长程依赖的同时保持详细的局部结构信息方面面临挑战。因此，它们通常需要高昂的计算成本来平衡局部和全局表达性。<br>为了解决这些限制，本文引入了一种新颖的GT架构，称为DUALFormer，其GNN和SA模块具有双维度设计。利用线性化变换器的近似理论并将查询视为节点特征的代理表示，DUALFormer能够在特征维度上高效地执行计算密集型的全局SA模块。此外，通过将局部和全局模块分离到双维度，DUALFormer实现了局部和全局表达性的自然平衡。理论上，DUALFormer可以减少类内方差，从而增强节点表示的判别性。在十一个真实数据集上的广泛实验证明了其相对于现有最先进GTs的有效性和效率。</p><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><h2 id="研究的核心问题"><a href="#研究的核心问题" class="headerlink" title="研究的核心问题"></a>研究的核心问题</h2><h3 id="1-可扩展性问题"><a href="#1-可扩展性问题" class="headerlink" title="1. 可扩展性问题"></a>1. 可扩展性问题</h3><p>现有的图Transformer，特别是基于传统自注意力机制(Self-Attention, SA)的模型，面临严重的可扩展性挑战。Zhuo 等 (2025) 指出，自注意力模块的二次方复杂度(<script type="math/tex">O(n²)</script>)使得很多图Transformer难以扩展到大规模图。为了解决这个问题，现有方法通常需要做出妥协——要么牺牲一定的全局表达性(如NAGphormer和Exphormer)，要么增加模型复杂度(如GOAT和CoBFormer)，导致模型泛化能力受限。</p><h3 id="2-局部性与全局性的权衡困境"><a href="#2-局部性与全局性的权衡困境" class="headerlink" title="2. 局部性与全局性的权衡困境"></a>2. 局部性与全局性的权衡困境</h3><p>第二个主要挑战是图Transformer在捕获局部结构和全局依赖信息之间的权衡。现有的图Transformer难以在保留详细局部结构信息的同时捕获长距离依赖关系。这导致它们通常需要显著的计算成本来平衡局部和全局表达能力。Zhuo 等 (2025)  特别指出，一些最先进的图Transformer(如NAGphormer、GOAT、SGFormer、Polynormer和CoBFormer)仍然依赖于GNN来学习局部节点表示，然后将这些表示与自注意力块结合生成最终节点表示，但这种融合会导致信息损失。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>为解决上述问题，Zhuo 等 (2025)  提出了DUALFormer，一种具有双维度设计的创新图Transformer架构。主要创新点包括：</p><ol><li><strong>双维度设计</strong>：将GNN和SA模块分别部署在不同维度上，在节点维度上建模局部信息，在特征维度上建模全局信息。</li><li><strong>高效全局注意力</strong>：利用线性化Transformer的近似理论，将查询(Q)视为节点特征的代理表示，在特征维度上高效执行计算密集的全局SA模块。</li><li><strong>自然平衡局部与全局</strong>：通过在双维度上分离局部和全局模块，自然地平衡了局部和全局表达能力。</li></ol><p>论文通过理论分析证明，DUALFormer可以减少类内方差，增强节点表示的判别性。在11个真实世界数据集上的广泛实验验证了DUALFormer在效果和效率上均优于现有的最先进图Transformer。</p><p>综上所述，本论文主要研究的是解决现有图Transformer在可扩展性和局部-全局信息权衡方面的局限性，并提出了一种创新的、双维度设计的解决方案DUALFormer。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p><img src="DUALFormer/DUALFormer.png" alt=""></p><h2 id="1-方法整体架构"><a href="#1-方法整体架构" class="headerlink" title="1. 方法整体架构"></a>1. 方法整体架构</h2><p>DUALFormer的核心创新在于其<strong>双维度设计</strong>，将传统的局部GNN模块和全局SA模块分别从节点维度和特征维度解耦，形成以下架构：</p><ol><li><strong>输入投影层</strong>：将原始节点属性投影到低维空间</li><li><strong>全局注意力模块</strong>：在特征维度捕获全局依赖关系</li><li><strong>局部图卷积模块</strong>：在节点维度捕获局部结构信息</li></ol><p>全流程如下：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    A[&quot;输入节点属性X&quot;] --&gt; B[&quot;输入投影层MLP(X) &#x3D; H0&quot;]    B --&gt; C{&quot;全局注意力模块&lt;br&#x2F;&gt;Global Attention Module&quot;}      subgraph 全局注意力层[&quot;Global Attention Layers&quot;]        direction LR        C --&gt; D[&quot;计算查询、键、值Q &#x3D; H·Wq K &#x3D; H·Wk V &#x3D; H·Wv&quot;]        D --&gt; E[&quot;计算特征间注意力矩阵M &#x3D; softmax(Q⊤K&#x2F;√n)&quot;]        E --&gt; F[&quot;更新节点表示~Z &#x3D; V·M&quot;]        F --&gt; G[&quot;残差连接Z &#x3D; α·~Z + (1-α)·H&quot;]    end      G --&gt; H{&quot;局部图卷积模块Local Graph Convolution Module&quot;}      subgraph 局部卷积层[&quot;GNN Layers&quot;]        direction LR        H --&gt; I[&quot;应用图卷积H &#x3D; GNN(A, Z)&quot;]        I --&gt; J[&quot;残差连接H &#x3D; H + prev_H&quot;]    end      J --&gt; K[&quot;输出预测Y &#x3D; MLP(H)&quot;]      style B fill:#f9f,stroke:#333,stroke-width:2px    style C fill:#bbf,stroke:#333,stroke-width:2px    style H fill:#bfb,stroke:#333,stroke-width:2px    style K fill:#fbb,stroke:#333,stroke-width:2px  </pre></div><h2 id="2-数学公式与推导"><a href="#2-数学公式与推导" class="headerlink" title="2. 数学公式与推导"></a>2. 数学公式与推导</h2><h3 id="2-1-输入投影层s"><a href="#2-1-输入投影层s" class="headerlink" title="2.1 输入投影层s"></a>2.1 输入投影层s</h3><p>首先使用前馈网络(FFN)将原始节点属性<script type="math/tex">X∈R^{(n×f)}</script>投影到低维隐藏空间：</p><script type="math/tex; mode=display">H^0 = \text{MLP}(X)</script><p>其中<script type="math/tex">n</script>是节点数，<script type="math/tex">f</script>是原始特征维度，<script type="math/tex">MLP</script>代表多层感知机。</p><h3 id="2-2-全局注意力模块"><a href="#2-2-全局注意力模块" class="headerlink" title="2.2 全局注意力模块"></a>2.2 全局注意力模块</h3><p>这是DUALFormer的核心创新。与传统GT在节点维度计算自注意力不同，DUALFormer在特征维度计算全局自注意力，将复杂度从<script type="math/tex">O(n²)</script>降低到<script type="math/tex">O(f²)</script>。<br><strong>查询(Q)、键(K)、值(V)计算</strong>：</p><script type="math/tex; mode=display">Q^{(l)} = \hat{Z}^{(l-1)} W_Q^{(l)}</script><script type="math/tex; mode=display">K^{(l)} = \hat{Z}^{(l-1)} W_K^{(l)}</script><script type="math/tex; mode=display">V^{(l)} = \hat{Z}^{(l-1)} W_V^{(l)}</script><p>其中<script type="math/tex">W_Q^{(l)}</script>, <script type="math/tex">W_K^{(l)}</script>, <script type="math/tex">W_V^{(l)} \in \mathbb{R}^{d \times d}</script>是可学习的投影矩阵。<br><strong>特征维度注意力计算</strong>：</p><script type="math/tex; mode=display">M^{(l)} = \text{softmax}\left(\sigma(Q^{(l)})^T K^{(l)} / \sqrt{n}\right)</script><script type="math/tex; mode=display">\tilde{Z}^{(l)} = V^{(l)} M^{(l)}</script><script type="math/tex; mode=display">\hat{Z}^{(l)} = \alpha \tilde{Z}^{(l)} + (1-\alpha) \hat{Z}^{(l-1)}</script><p>这里<script type="math/tex">σ</script>是激活函数(如<script type="math/tex">softmax</script>)，<script type="math/tex">M∈R^{(d×d)}</script>是特征间注意力分数矩阵，<script type="math/tex">α</script>是超参数用于平衡当前层和前一层。</p><h3 id="2-3-局部图卷积模块"><a href="#2-3-局部图卷积模块" class="headerlink" title="2.3 局部图卷积模块"></a>2.3 局部图卷积模块</h3><p>在获得全局表示后，使用图神经网络模块整合局部信息：</p><script type="math/tex; mode=display">\hat{H}^{(k)} = \text{GNN}(A, \hat{H}^{(k-1)})</script><p>其中<script type="math/tex">\hat{H}^{(0)} = \hat{Z}^{(L)}</script>，<script type="math/tex">L</script>是注意力层数，GNN可选择SGC等实现：</p><script type="math/tex; mode=display">\text{SGC}(A, H) = \hat{A}H</script><p>其中<script type="math/tex">\hat{A} = D^{-1/2}(A+I)D^{-1/2}</script>是归一化的邻接矩阵。<br><strong>预测层</strong>：</p><script type="math/tex; mode=display">\hat{Y} = \text{MLP}(\hat{H}^{(K)})</script><h2 id="3-理论分析"><a href="#3-理论分析" class="headerlink" title="3. 理论分析"></a>3. 理论分析</h2><h3 id="定理1-判别性改进"><a href="#定理1-判别性改进" class="headerlink" title="定理1: 判别性改进"></a>定理1: 判别性改进</h3><p>全局注意力模块可以减少类内方差，同时保持类间方差不变。<br><strong>推导过程</strong>：<br>设节点特征<script type="math/tex">x_v \in \mathbb{R}^f</script>为列向量。根据方差分解:</p><script type="math/tex; mode=display">\text{Var}[X] = \mathbb{E}[\text{Var}[X|Y]] + \text{Var}[\mathbb{E}[X|Y]]</script><p>其中<script type="math/tex">\text{Var}[X|Y=k]</script>表示第k类的方差，<script type="math/tex">\mathbb{E}[X|Y=k]</script>表示第<script type="math/tex">k</script>类的中心。<br>对于全局注意力模块，变换后的特征为<script type="math/tex">M^T x_v</script>，对应的随机变量为<script type="math/tex">M^T X</script>。<br><strong>结论1</strong>：类内方差满足</p><script type="math/tex; mode=display">\mathbb{E}[\text{Var}[M^T X|Y]] \leq \mathbb{E}[\text{Var}[X|Y]]</script><p><strong>结论2</strong>：如果注意力矩阵M满足<script type="math/tex">\|e_i - e_j\|_2\leq\varepsilon</script>（当<script type="math/tex">M_{ij} \neq 0</script>时），则：</p><script type="math/tex; mode=display">\|\hat{e}_j - e_j\|_2 \leq \varepsilon</script><p>其中<script type="math/tex">e_j</script>和<script type="math/tex">\hat{e}_j</script>分别是变换前后的类中心。<br>这表明有效的特征注意力可以减少类内方差，同时保持类间距离相对不变，从而提高节点表征的判别性。</p><h2 id="4-方法优势与解释"><a href="#4-方法优势与解释" class="headerlink" title="4. 方法优势与解释"></a>4. 方法优势与解释</h2><h3 id="4-1-高效可扩展性"><a href="#4-1-高效可扩展性" class="headerlink" title="4.1 高效可扩展性"></a>4.1 高效可扩展性</h3><p>传统GT使用节点自注意力<script type="math/tex">(sim(Q,K)∈R^(n×n))</script>，复杂度为<script type="math/tex">O(n²)</script>。而DUALFormer在特征维度计算注意力<script type="math/tex">(M∈R^(d×d))</script>，复杂度为<script type="math/tex">O(fd)</script>，且通常<script type="math/tex">f << n</script>，实现了线性复杂度<script type="math/tex">O(n)</script>。</p><h3 id="4-2-局部与全局信息的自然融合"><a href="#4-2-局部与全局信息的自然融合" class="headerlink" title="4.2 局部与全局信息的自然融合"></a>4.2 局部与全局信息的自然融合</h3><p>传统GT如图1(a)所示，需在节点维度权衡局部(GNN)和全局(SA)信息，容易导致信息丢失。而DUALFormer(图1(b))将两个维度解耦：</p><ul><li>节点维度：GNN捕获局部结构信息</li><li>特征维度：SA捕获全局相关性</li></ul><p>通过<script type="math/tex">(Q×K)^T × V ≈ Q × (K^T × V)</script>的近似理论，实现了全局依赖与局部信息的平衡，避免传统权衡困境。</p><h3 id="4-3-设计简洁性"><a href="#4-3-设计简洁性" class="headerlink" title="4.3 设计简洁性"></a>4.3 设计简洁性</h3><p>相比现有GT(如表1所示)常需要位置编码、增强训练损失或额外参数，DUALFormer仅使用简单的局部图卷积和全局注意力，架构更加精简高效。</p><h2 id="5-实验验证"><a href="#5-实验验证" class="headerlink" title="5. 实验验证"></a>5. 实验验证</h2><p>DUALFormer在7个节点分类任务(表2)和4个节点属性预测任务(表3)上展现了优越性能。例如，在Cora和PubMed上分别达到85.88%和83.97%的准确率，显著超越基线模型。同时，实验证明其具有线性扩展能力(图3)和参数稳定性(图5-6)。<br>综上所述，DUALFormer通过创新的双维度设计，有效解决了图变换器的可扩展性和局部与全局信息权衡问题，在节点分类和属性预测任务上展现出了优异的性能和效率。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="1-DUALFormer注意力模块详解"><a href="#1-DUALFormer注意力模块详解" class="headerlink" title="1.DUALFormer注意力模块详解"></a>1.DUALFormer注意力模块详解</h2><h3 id="1-注意力模块概述"><a href="#1-注意力模块概述" class="headerlink" title="1. 注意力模块概述"></a>1. 注意力模块概述</h3><p>DUALFormer中的全局注意力模块(Global Attention Module)是设计的核心组件之一，其创新之处在于在特征维度而非传统节点维度上执行自注意力机制。这种设计有效解决了现有图变换器(GT)的两个主要挑战：可扩展性和局部性与全局性之间的权衡问题。</p><h3 id="2-数学公式与推导-1"><a href="#2-数学公式与推导-1" class="headerlink" title="2. 数学公式与推导"></a>2. 数学公式与推导</h3><h4 id="2-1-标准自注意力与线性化注意力分析"><a href="#2-1-标准自注意力与线性化注意力分析" class="headerlink" title="2.1 标准自注意力与线性化注意力分析"></a>2.1 标准自注意力与线性化注意力分析</h4><h5 id="标准自注意力机制"><a href="#标准自注意力机制" class="headerlink" title="标准自注意力机制"></a>标准自注意力机制</h5><script type="math/tex; mode=display">\hat{z}_v = \sum_{u \in V} \frac{\exp(\text{sim}(q_v, k_u))}{\sum_{u \in V} \exp(\text{sim}(q_v, k_u))} v_u</script><p>在向量形式下:</p><script type="math/tex; mode=display">\hat{Z} = \text{Sim}(Q, K)V</script><p>标准自注意力将值(V)作为节点特征的代理表示，注意力分数矩阵<script type="math/tex">\text{Sim}(Q, K)</script>作为节点间依赖矩阵，实现全局节点间消息传递。</p><h5 id="线性化自注意力机制"><a href="#线性化自注意力机制" class="headerlink" title="线性化自注意力机制"></a>线性化自注意力机制</h5><script type="math/tex; mode=display">\hat{Z}_v = \phi(q_v) \frac{\sum_{u \in V} \phi(k_u)^T v_u}{\sum_{u \in V} \phi(k_u)^T}</script><p>在向量形式下:</p><script type="math/tex; mode=display">\hat{Z} = \phi(Q)\phi(K)^T V</script><p>线性化自注意力将查询<script type="math/tex">\phi(Q)</script>视为Z的表示，将乘积矩阵<script type="math/tex">\phi(K)V</script>视为特征之间的相关矩阵，实现特征间的消息传递。</p><h4 id="2-2-全局注意力模块实现"><a href="#2-2-全局注意力模块实现" class="headerlink" title="2.2 全局注意力模块实现"></a>2.2 全局注意力模块实现</h4><p>DUALFormer的全局注意力模块按以下步骤实现:</p><h5 id="2-2-1-查询、键、值投影"><a href="#2-2-1-查询、键、值投影" class="headerlink" title="2.2.1 查询、键、值投影"></a>2.2.1 查询、键、值投影</h5><script type="math/tex; mode=display">Q^{(l)} = \hat{Z}^{(l-1)} W_Q^{(l)}, \quad K^{(l)} = \hat{Z}^{(l-1)} W_K^{(l)}, \quad V^{(l)} = \hat{Z}^{(l-1)} W_V^{(l)}</script><p>其中<script type="math/tex">W_Q^{(l)}, W_K^{(l)}, W_V^{(l)} \in \mathbb{R}^{d \times d}</script>是可学习投影矩阵。</p><h5 id="2-2-2-注意力分数矩阵计算"><a href="#2-2-2-注意力分数矩阵计算" class="headerlink" title="2.2.2 注意力分数矩阵计算"></a>2.2.2 注意力分数矩阵计算</h5><script type="math/tex; mode=display">M^{(l)} = \text{softmax}\left(\frac{(Q^{(l)})^T K^{(l)}}{\sqrt{n}}\right)</script><script type="math/tex; mode=display">M \in \mathbb{R}^{d \times d}</script><p>是低维注意力分数矩阵，表征特征-特征相关性，其维度远小于传统的<script type="math/tex">n\times n</script>节点注意力矩阵。</p><h5 id="2-2-3-注意力应用"><a href="#2-2-3-注意力应用" class="headerlink" title="2.2.3 注意力应用"></a>2.2.3 注意力应用</h5><script type="math/tex; mode=display">\tilde{Z}^{(l)} = V^{(l)} M^{(l)} = V^{(l)} \text{softmax}\left(\frac{(Q^{(l)})^T K^{(l)}}{\sqrt{n}}\right)</script><h5 id="2-2-4-残差连接与平衡"><a href="#2-2-4-残差连接与平衡" class="headerlink" title="2.2.4 残差连接与平衡"></a>2.2.4 残差连接与平衡</h5><script type="math/tex; mode=display">\hat{Z}^{(l)} = \alpha \tilde{Z}^{(l)} + (1 - \alpha) \hat{Z}^{(l-1)}</script><p>其中<script type="math/tex">\alpha</script>是平衡注意力和前一层表示的超参数。</p><h4 id="2-3-多头注意力扩展"><a href="#2-3-多头注意力扩展" class="headerlink" title="2.3 多头注意力扩展"></a>2.3 多头注意力扩展</h4><p>为了增强表示能力，DUALFormer可以融入多头注意力机制:</p><script type="math/tex; mode=display">\hat{Z}_{\text{final}} = \text{Concat}(\hat{Z}^{(0)}, \hat{Z}^{(1)}, \ldots, \hat{Z}^{(t-1)}) W_O</script><p>其中<script type="math/tex">t</script>是头的数量，<script type="math/tex">W_O \in \mathbb{R}^{td \times d}</script>是可学习投影矩阵。</p><h3 id="3-理论分析与优势"><a href="#3-理论分析与优势" class="headerlink" title="3. 理论分析与优势"></a>3. 理论分析与优势</h3><h4 id="3-1-判别性改进定理"><a href="#3-1-判别性改进定理" class="headerlink" title="3.1 判别性改进定理"></a>3.1 判别性改进定理</h4><p><strong>定理1.</strong> 全局注意力模块减少类内方差同时保持类间方差不变。<br>证明:<br>假设节点特征<script type="math/tex">x_v</script>和标签<script type="math/tex">y_v</script>是随机变量<script type="math/tex">X</script>和<script type="math/tex">Y</script>的观测值，且节点特征是均值为零的:<script type="math/tex">E[X] = 0</script>。根据总方差定律:</p><script type="math/tex; mode=display">\text{Var}[X] = E[\text{Var}[X|Y]] + \text{Var}[E[X|Y]]</script><p>全局注意力的关键节点特征变换是<script type="math/tex">XM</script>，其中<script type="math/tex">M = [m_{ij}] = \text{softmax}(Q^T K/\sqrt{n})</script>是特征间的随机矩阵。<br>经过全局注意力后，节点特征变为<script type="math/tex">M^T x_v \in \mathbb{R}^f</script>。通过推导可以证明两个关键性质:</p><ol><li><strong>类内方差减少</strong>:<script type="math/tex; mode=display">E[\text{Var}[M^T X|Y]] \leq E[\text{Var}[X|Y]]</script></li><li><strong>类间方差保持</strong>:<br>如果学习的注意力矩阵足够好，使得对于任何<script type="math/tex">m_{ij} \neq 0</script>有<script type="math/tex">\|e_i - e_j\|_2 \leq \varepsilon</script>，则:<script type="math/tex; mode=display">\|\hat{e}_j - e_j\|_2 \leq \varepsilon</script>其中<script type="math/tex">\varepsilon</script>可以适当选择<script type="math/tex">M</script>而变得任意小。</li></ol><h4 id="3-2-特征注意力与节点注意力的对比"><a href="#3-2-特征注意力与节点注意力的对比" class="headerlink" title="3.2 特征注意力与节点注意力的对比"></a>3.2 特征注意力与节点注意力的对比</h4><h5 id="效率对比"><a href="#效率对比" class="headerlink" title="效率对比"></a>效率对比</h5><ul><li>节点注意力复杂度: <script type="math/tex">O(n^2)</script>，其中<script type="math/tex">n</script>是节点数量</li><li>特征注意力复杂度: <script type="math/tex">O(f^2)</script>，其中<script type="math/tex">f</script>是特征维度</li></ul><p>由于通常<script type="math/tex">f \ll n</script>，特征注意力显著提高了计算效率。</p><h5 id="性能对比"><a href="#性能对比" class="headerlink" title="性能对比"></a>性能对比</h5><p>特征注意力缓解了有限训练数据和大规模复杂关系建模之间的冲突:</p><ul><li>节点注意力需要精确建模<script type="math/tex">n^2</script>对关系，但图上训练数据通常不足以支撑如此大规模的训练</li><li>特征注意力只需建模<script type="math/tex">f^2</script>对关系，训练需求大幅降低</li></ul><h3 id="4-实际应用意义"><a href="#4-实际应用意义" class="headerlink" title="4. 实际应用意义"></a>4. 实际应用意义</h3><p>DUALFormer的注意力模块通过在特征维度上建模全局依赖关系，实现了:</p><ol><li>高效可扩展的计算，线性时间复杂度<script type="math/tex">O(n + e)</script></li><li>自然平衡局部与全局表达能力，避免传统GT中的权衡困境</li><li>降低类内方差，提高节点表示的判别性</li><li>减少对额外组件(如位置编码、增强训练损失)的依赖，简化模型架构</li></ol><p>通过这种创新的双维度设计，DUALFormer能够在保持全局表达能力的同时，显著提升计算效率和模型性能。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://epsilonzyj.github.io/posts/NAGphormer.html">NAGphormer: A Tokenized Graph Transformer For Node Classification In Large Graphs</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
          <category> Tokenizing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
            <tag> Tokenizing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读：NTFormer</title>
      <link href="/posts/NTFormer.html"/>
      <url>/posts/NTFormer.html</url>
      
        <content type="html"><![CDATA[<hr><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><ul><li>作者: Jinsong Chen, Siyu Jiang, Kun He</li><li>出处: IEEE Transactions on Big Data</li><li>PDF: <a href="http://arxiv.org/abs/2406.19249">http://arxiv.org/abs/2406.19249</a></li></ul><hr><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>摘要—近年来，新兴的图Transformer在图节点分类任务上取得了显著进展。在大多数图Transformer中，一个关键步骤是将输入图转换为令牌序列(token sequences)作为模型输入，使Transformer能够有效学习节点表示。然而，我们观察到现有方法仅通过单类型令牌生成表达节点的部分图信息。因此，它们需要定制化的策略将额外的图特定特征编码到Transformer中，以确保节点表示学习的质量，这限制了模型处理多样化图的灵活性。为此，我们提出了一种新的图Transformer称为NTFormer来解决这个问题。NTFormer引入了一种新颖的令牌生成器Node2Par，它使用不同的令牌元素为每个节点构建各种令牌序列。这种灵活性使Node2Par能够从不同角度生成有价值的令牌序列，确保丰富图特征的全面表达。受益于Node2Par的优势，NTFormer仅利用基于Transformer的主干结构，无需图特定修改即可学习节点表示，消除了对图特定修改的需求。在包含不同规模同配性和异配性图的多种基准数据集上进行的大量实验证明，NTFormer在节点分类任务上优于代表性的图Transformer和图神经网络。</p><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><p>本论文主要研究的问题是<strong>图神经网络中节点分类任务面临的token序列构建不全面的问题</strong>。具体来说，当前大多数图Transformer方法在将输入图转换为token序列作为模型输入时，仅使用单类型token生成来表达节点的部分图信息，这导致了以下局限性：</p><ol><li><strong>信息表达不完整</strong>：现有方法只能表达节点的部分图信息，无法全面捕捉复杂的图特征。</li><li><strong>需要额外定制策略</strong>：为弥补上述不足，这些方法需要设计特定策略将额外图特征编码到Transformer架构中，以确保节点表示学习的质量。</li><li><strong>模型灵活性受限</strong>：这些定制化的处理方式限制了模型处理多样化图结构的能力，无法灵活适应不同类型的图数据。<br>从论文摘要和引言可以看出，作者观察到”现有方法仅通过单类型token生成表达节点的部分图信息”，因此研究目标是通过设计更全面的token生成机制，使模型能够自然地表达丰富的图特征，而无需依赖特定的图结构修改或额外的编码策略。</li></ol><p>作者提出的解决方案是NTFormer模型，该模型引入了名为Node2Par的新token生成器，能够为每个节点构建多种token序列，从不同角度表达图特征，从而解决了传统方法中的局限性问题。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="NTFormer方法详解"><a href="#NTFormer方法详解" class="headerlink" title="NTFormer方法详解"></a>NTFormer方法详解</h2><p><img src="NTFormer/NTFormer.png" alt=""></p><h3 id="一、Node2Par标记序列生成器"><a href="#一、Node2Par标记序列生成器" class="headerlink" title="一、Node2Par标记序列生成器"></a>一、Node2Par标记序列生成器</h3><p>Node2Par是一个创新的标记序列生成器，从拓扑和属性两个视图为每个节点构建两种类型的标记序列：邻域标记序列和节点标记序列。</p><h4 id="1-1-邻域标记生成器"><a href="#1-1-邻域标记生成器" class="headerlink" title="1.1 邻域标记生成器"></a>1.1 邻域标记生成器</h4><p>邻域是描述目标节点周围连接的重要元素。作者首先提出邻域特征聚合的通用形式：</p><script type="math/tex; mode=display">X_i^{N,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{(k)} \cdot X_j</script><p>其中：</p><ul><li><script type="math/tex">\mathcal{N}_i^{(k)}</script>表示节点<script type="math/tex">v_i</script>的<script type="math/tex">k</script>跳邻域</li><li><script type="math/tex">W_{ij}^{(k)}</script>表示节点<script type="math/tex">v_j</script>在邻域中的聚合权重</li><li><script type="math/tex">X_j</script>表示节点<script type="math/tex">v_j</script>的属性特征</li><li><script type="math/tex">X_i^{N,(0)} = X_i</script>表示节点本身视为<script type="math/tex">0</script>跳邻域</li></ul><p>为全面表达邻域信息，作者从拓扑和属性两个视图构建邻域标记：</p><script type="math/tex; mode=display">X_i^{t,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{t,(k)} \cdot X_j</script><script type="math/tex; mode=display">X_i^{a,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{a,(k)} \cdot X_j</script><p>对应的权重计算为：</p><script type="math/tex; mode=display">W_{ij}^{t,(k)} = A_{ij}^{t,(k)}, \quad A^{t,(k)} = \hat{A}^k</script><script type="math/tex; mode=display">W_{ij}^{a,(k)} = A_{ij}^{a,(k)}, \quad A^{a,(k)} = (A \odot A_s)^k</script><p>其中：</p><ul><li><script type="math/tex">\hat{A}</script>是带自环的归一化邻接矩阵</li><li><script type="math/tex">A_s</script>是通过余弦相似度(<script type="math/tex">\text{Cosine}(X_i, X_j^T)</script>)计算的属性相似性矩阵</li><li><script type="math/tex">A</script>是邻接矩阵</li><li><script type="math/tex">\odot</script>表示元素级乘积(哈达玛积)</li></ul><p>最终生成两种邻域标记序列：拓扑视图<script type="math/tex">S_i^{NE,t} = \{X_i^{t,(0)}, \ldots, X_i^{t,(K)}\}</script>和属性视图<script type="math/tex">S_i^{NE,a} = \{X_i^{a,(0)}, \ldots, X_i^{a,(K)}\}</script>。</p><h4 id="1-2-节点标记生成器"><a href="#1-2-节点标记生成器" class="headerlink" title="1.2 节点标记生成器"></a>1.2 节点标记生成器</h4><p>为解决邻域标记在捕获节点级信息(如长距离依赖)方面的局限，作者引入节点标记生成器，采用两步策略：</p><ol><li>测量节点相似度分数</li><li>选择最相似的节点构建标记序列</li></ol><script type="math/tex; mode=display">S_i^{NO} = \{X_j | v_j \in \text{Top}(M_i)\}</script><p>其中：</p><ul><li><script type="math/tex">M \in \mathbb{R}^{n \times n}</script>是所有节点对的评分矩阵</li><li><script type="math/tex">\text{Top}(\cdot)</script> 选择具有最高相似度分数的 <script type="math/tex">n_k</script> 个节点</li></ul><p>作者从两个视图计算评分矩阵：<br><strong>拓扑视图(<script type="math/tex">M_t</script>)</strong>：采用个性化PageRank(PPR)方法</p><script type="math/tex; mode=display">s_i^{(l)} = r \cdot \hat{A} s_i^{(l-1)} + (1-r) \cdot s_i^0</script><p>其中：</p><ul><li><script type="math/tex">s_i^{(l)}</script>表示第<script type="math/tex">l</script>次传播步骤的PageRank分数</li><li><script type="math/tex">s_i^{(0)} = \hat{A}_i</script>(<script type="math/tex">\hat{A}</script>的第<script type="math/tex">i</script>列)</li><li><script type="math/tex">r</script>是阻尼常数因子</li><li><script type="math/tex">s_i^0</script>是个性化one-hot向量</li></ul><p><strong>属性视图(<script type="math/tex">M_a</script>)</strong>：直接应用余弦相似度计算节点属性相似性。</p><h3 id="二、基于Transformer层的主干网络"><a href="#二、基于Transformer层的主干网络" class="headerlink" title="二、基于Transformer层的主干网络"></a>二、基于Transformer层的主干网络</h3><p>获得四个标记序列(<script type="math/tex">\{S_i^{NE,t}, S_i^{NE,a}, S_i^{NO,t}, S_i^{NO,a}\}</script>)后，作者提出Transformer主干网络。</p><h4 id="2-1-Transformer层输入投影"><a href="#2-1-Transformer层输入投影" class="headerlink" title="2.1 Transformer层输入投影"></a>2.1 Transformer层输入投影</h4><p>以邻域标记<script type="math/tex">S_i^{NE,t}</script>为例，首先进行特征投影：</p><script type="math/tex; mode=display">H_i^{NE,t,(0)} = [X_i^{t,(0)} W_p, \ldots, X_i^{t,(K)} W_p]</script><p>其中<script type="math/tex">W_p \in \mathbb{R}^{d \times d^{(0)}}</script>是投影矩阵。</p><h4 id="2-2-Transformer层处理"><a href="#2-2-Transformer层处理" class="headerlink" title="2.2 Transformer层处理"></a>2.2 Transformer层处理</h4><p>应用标准Transformer层学习节点表示：</p><script type="math/tex; mode=display">H_i^{NE,t,(l)'} = \text{MSA}(H_i^{NE,t,(l)}) + H_i^{NE,t,(l)}</script><script type="math/tex; mode=display">H_i^{NE,t,(l+1)} = \text{FFN}(H_i^{NE,t,(l)'}) + H_i^{NE,t,(l)'}</script><p>其中<script type="math/tex">MSA</script>是多头自注意力机制，<script type="math/tex">FFN</script>是前馈网络。从输出<script type="math/tex">H_i^{NE,t} \in \mathbb{R}^{(K+1) \times d_o}</script>中提取第一行作为节点表示<script type="math/tex">Z_i^{NE,t} \in \mathbb{R}^{1 \times d_o}</script>。<br>同理获得其他表示<script type="math/tex">Z_i^{NE,a}, Z_i^{NO,t}, Z_i^{NO,a}</script>。</p><h4 id="2-3-自适应特征融合"><a href="#2-3-自适应特征融合" class="headerlink" title="2.3 自适应特征融合"></a>2.3 自适应特征融合</h4><p>提出自适应融合模块获取最终节点表示，首先计算各特征的融合权重：</p><script type="math/tex; mode=display">\alpha_i^{NE,t} = \sigma(Z_i^{NE,t} \cdot W_{f_0}) \cdot W_{f_1}</script><p>其中：</p><ul><li><script type="math/tex">W_{f_0} \in \mathbb{R}^{d_o \times d_f}</script>和<script type="math/tex">W_{f_1} \in \mathbb{R}^{d_f \times 1}</script>是可学习参数矩阵</li><li><script type="math/tex">\sigma(\cdot)</script> 是激活函数对各权重进行 <script type="math/tex">softmax</script> 归一化后，加权融合得到最终表示：</li></ul><script type="math/tex; mode=display">Z_i = \alpha_i^{NE,t} \cdot Z_i^{NE,t} + \alpha_i^{NE,a} \cdot Z_i^{NE,a} + \alpha_i^{NO,t} \cdot Z_i^{NO,t} + \alpha_i^{NO,a} \cdot Z_i^{NO,a}</script><h4 id="2-4-预测器与损失函数"><a href="#2-4-预测器与损失函数" class="headerlink" title="2.4 预测器与损失函数"></a>2.4 预测器与损失函数</h4><p>节点分类任务使用MLP预测标签并采用交叉熵损失：</p><script type="math/tex; mode=display">\mathcal{L} = -\sum_{i \in \mathcal{V}_l} Y_i^T \ln \hat{Y}_i, \quad \hat{Y} = \text{MLP}(Z)</script><p>其中<script type="math/tex">\mathcal{V}_l</script>是已知标签节点的集合。</p><h3 id="三、方法创新点与优势"><a href="#三、方法创新点与优势" class="headerlink" title="三、方法创新点与优势"></a>三、方法创新点与优势</h3><ol><li><strong>多视图标记生成</strong>：Node2Par从拓扑和属性两个视图分别生成邻域级和节点级标记序列，全面表达图信息，解决了先前方法仅使用单一类型标记的局限性。</li><li><strong>无需图特定修改</strong>：得益于Node2Par提供的丰富信息，NTFormer仅需标准Transformer层即可学习节点表示，无需特定的位置编码或注意力偏向，增强了模型处理不同类型图的灵活性。</li><li><strong>自适应特征融合</strong>：通过学习自适应权重融合不同类型的标记序列表示，使模型能够根据图的特性(同配性/异配性)灵活调整不同标记的贡献度。<br>实验表明，NTFormer在各种规模的基准数据集上均优于代表性图神经网络和图Transformer方法，特别在异配图上表现突出，验证了其有效性和通用性。</li></ol><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="1-PPR计算方法详解"><a href="#1-PPR计算方法详解" class="headerlink" title="1.PPR计算方法详解"></a>1.PPR计算方法详解</h2><p>在NTFormer论文中，PPR（Personalized PageRank）用于计算节点之间的相似度矩阵以生成基于拓扑的节点标记序列。PPR计算的具体方法在论文的IV.B节”Node-based Token Generator”中有详细描述。可以对比[[VCR-GRAPHORMER_A_MINI-BATCH_GRAPH_TRANSFORMER_VIA_VIRTUAL_CONNECTIONS]]进行理解。</p><h3 id="PPR计算公式"><a href="#PPR计算公式" class="headerlink" title="PPR计算公式"></a>PPR计算公式</h3><p>论文中给出的PPR计算公式如下：</p><script type="math/tex; mode=display">s^{(l)}_i = r \cdot \hat{A}^T s^{(l-1)}_i + (1 - r) \cdot s^0_i</script><p>其中：</p><ul><li><script type="math/tex">s^{(l)}_i \in R^{n \times 1}</script> 表示从目标节点 <script type="math/tex">v_i</script> 在第<script type="math/tex">l</script>次传播步骤的所有节点的PPR分数</li><li><script type="math/tex">s^{(0)}_i = \hat{A}_i</script> 表示初始状态</li><li><script type="math/tex">r</script> 是阻尼常数因子</li><li><script type="math/tex">s^0_i \in R^{n \times 1}</script> 是one-hot个性化向量，其中目标节点对应的元素等于1，其他为0</li></ul><h3 id="计算步骤"><a href="#计算步骤" class="headerlink" title="计算步骤"></a>计算步骤</h3><ol><li><strong>初始化</strong>：对于目标节点 <script type="math/tex">v_i</script>，创建一个one-hot向量 <script type="math/tex">s^0_i</script>，其中目标节点对应的元素为1，其他为0。</li><li><strong>迭代计算</strong>：使用给定公式进行l次迭代计算PPR分数。每次迭代都考虑当前分数与阻尼因子。</li><li><strong>实际实现</strong>：根据论文描述，在实践中采用了两步传播来估计节点的PPR分数，即进行两次迭代计算。</li><li><strong>构建相似度矩阵</strong>：最终，所有节点对某个目标节点的PPR分数构成相似度矩阵 <script type="math/tex">M_t</script>。</li></ol><h3 id="拓扑矩阵A"><a href="#拓扑矩阵A" class="headerlink" title="拓扑矩阵Â"></a>拓扑矩阵Â</h3><p>公式中使用的<script type="math/tex">\hat{A}</script>是归一化的邻接矩阵加上自环，定义为：</p><script type="math/tex; mode=display">\hat{A} = (D + I)^{-1/2}(A + I)(D + I)^{-1/2}</script><p>其中：</p><ul><li>A 是原始邻接矩阵</li><li>D 是对角度矩阵<script type="math/tex; mode=display">D_{ii}=\sum_{j=1}^nA_{ij}</script></li><li>I 是单位矩阵</li></ul><p>这种归一化处理使得PPR计算能够考虑节点的度数信息，更好地反映节点在图中的重要性。<br>通过这种方法，NTFormer能够量化节点间的拓扑关系，为后续生成拓扑视图的节点标记序列提供基础。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://epsilonzyj.github.io/posts/NAGphormer.html">NAGphormer: A Tokenized Graph Transformer For Node Classification In Large Graphs</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
          <category> Tokenizing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
            <tag> Tokenizing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读：Vcr-Graphormer</title>
      <link href="/posts/Vcr-Graphormer.html"/>
      <url>/posts/Vcr-Graphormer.html</url>
      
        <content type="html"><![CDATA[<hr><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><ul><li>作者: Dongqi Fu, Zhigang Hua, Yan Xie, Jin Fang, Si Zhang, Kaan Sancak, Hao Wu, Andrey Malevich, Jingrui He, Bo Long</li><li>出处: ICLR</li><li>PDF: <a href="https://openreview.net/pdf?id=SUUrkC3STJ">https://openreview.net/pdf?id=SUUrkC3STJ</a></li><li>开源代码: <a href="https://github.com/DongqiFu/VCR-Graphormer">https://github.com/DongqiFu/VCR-Graphormer</a></li></ul><hr><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>图变换器已被证明是一种有效的图学习方法，因为它采用了注意力机制，能够从图的复杂拓扑和特征信息中捕获表达性表示。传统图变换器对每对节点执行密集注意力（或全局注意力）来学习节点表示向量，导致二次计算成本对于大规模图数据来说是无法负担的。因此，图变换器的小批量训练是一个有前途的方向，但每个小批量中的有限样本无法支持有效的密集注意力来编码信息丰富的表示。<br>面对这一瓶颈，(1)我们首先为每个节点分配一个通过个性化PageRank(PPR)采样的token列表，然后仅在这个列表上应用标准多头自注意力来计算其节点表示。这种PPR tokenization方法将模型训练与复杂的图拓扑信息解耦，并使繁重的特征工程离线且独立，从而通过批量加载每个节点的token列表，使得图变换器的小批量训练成为可能。我们进一步证明这种PPR tokenization可以作为具有固定多项式滤波器和跳跃知识的图卷积网络使用。然而，仅使用个性化PageRank可能会限制token列表携带的信息，无法支持模型训练的不同图归纳偏置。<br>为此，(2)我们通过基于结构和内容的超节点引入多种类型的虚拟连接来重连图，使PPR tokenization能够将局部和全局上下文、长程交互和异质性信息编码到每个节点的token列表中，并形式化我们的基于虚拟连接排序的图变换器（VCR-Graphormer）。总体而言，与先前工作的O(n³)复杂度相比，VCR-Graphormer的图tokenization复杂度为O(m+klogk)。代码已提供。</p><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><h2 id="1-计算复杂度问题"><a href="#1-计算复杂度问题" class="headerlink" title="1. 计算复杂度问题"></a>1. 计算复杂度问题</h2><p>传统的图Transformer需要对每对节点执行密集注意力（或全局注意力）来学习节点表示向量，这种密集注意力机制能够从图的复杂拓扑和特征信息中捕获有表现力的表示。然而，这种计算方式导致了二次方的计算复杂度(O(n²))，对于大规模图数据来说是不可承受的。<br>尽管许多研究工作已经开发出各种图Transformer架构，如GT (Dwivedi and Bresson, 2020)、Gophormer (Zhao et al., 2021)、Graphormer (Ying et al., 2021)等，但它们大多需要处理所有节点对之间的注意力，这使得它们难以扩展到大规模图数据。</p><h2 id="2-小批量训练的局限性"><a href="#2-小批量训练的局限性" class="headerlink" title="2. 小批量训练的局限性"></a>2. 小批量训练的局限性</h2><p>小批量训练为图Transformer提供了一个有前景的方向，因为每次只处理图中的一部分节点。然而，每个小批次中的少量节点样本无法支持有效的密集注意力来编码充分的信息，特别是对于具有复杂拓扑和特征信息的大规模图数据。<br>现有的小批量图Transformer方法如NAGphormer (Chen et al., 2023)，虽然采用了自注意力机制，但仍存在以下问题：</p><ul><li>跳聚合方法可能无法很好地处理全局、长程交互和异构信息</li><li>依赖于耗时的特征分解来进行位置编码</li><li>计算复杂度仍然较高(O(n³))，限制了其在真正大规模图上的应用</li></ul><h2 id="解决方案需求"><a href="#解决方案需求" class="headerlink" title="解决方案需求"></a>解决方案需求</h2><p>因此，亟需一种能够：</p><ol><li>将模型训练与复杂的图拓扑信息解耦</li><li>允许离线和独立的特征工程</li><li>通过小批量方式有效训练</li><li>在保持高效的同时捕获足够的图信息</li><li>支持不同的图归纳偏置<br> 这些需求推动了VCR-Graphormer的发展，它通过个性化PageRank令牌化和虚拟连接机制，实现了高效的小批量图Transformer训练，同时能够编码局部和全局上下文、长程交互和异构信息。</li></ol><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="模型核心思想"><a href="#模型核心思想" class="headerlink" title="模型核心思想"></a>模型核心思想</h2><p>VCR-Graphormer的核心思想是通过个性化PageRank(PPR)进行图分词化(tokenization)，并通过引入虚拟连接(virtual connections)增强令牌列表的信息表达能力。这一方法使模型能够在小批次训练中有效捕获图的局部和全局信息。</p><h2 id="主要组件与数学公式"><a href="#主要组件与数学公式" class="headerlink" title="主要组件与数学公式"></a>主要组件与数学公式</h2><h3 id="1-PPR分词化"><a href="#1-PPR分词化" class="headerlink" title="1. PPR分词化"></a>1. PPR分词化</h3><p>首先使用个性化PageRank为每个目标节点u生成令牌列表Tu。个性化PageRank定义为（即PPR值）：</p><script type="math/tex; mode=display">r = \alpha P r + (1 - \alpha) q</script><p>其中：</p><ul><li><script type="math/tex">P ∈ R^{n×n}</script> 是转移矩阵（可计算为<script type="math/tex">AD^{-1}</script>或<script type="math/tex">D^{-1/2}AD^{-1/2}</script>）（<script type="math/tex">A</script>为邻接矩阵，<script type="math/tex">D</script>为度矩阵）</li><li><script type="math/tex">q</script> 是目标节点（即当前节点）对应的one-hot随机向量</li><li><script type="math/tex">r</script> 是随机游走的平稳分布（个性化PageRank向量）</li><li><script type="math/tex">α</script> 是阻尼常数因子（通常设为0.85）</li></ul><p>最终的PPR值通过迭代直到收敛或波动小于某个常量。<br>令牌列表有两种数学表示形式：<br><strong>聚集形式</strong>:</p><script type="math/tex; mode=display">T^{Agg}_u = \{(P^l X)(u, :)\} \text{ s.t. for } l \in \{1, \ldots, L\}</script><p><strong>离散形式</strong>:</p><script type="math/tex; mode=display">T^{Dis}_u = \{X(i, :) \cdot r_u(i)\} \text{ s.t. for } i \in R^k_u</script><p>其中<script type="math/tex">X ∈ R^{n×d}</script>是特征矩阵，<script type="math/tex">P^l X</script>表示第<script type="math/tex">l</script>步随机游走。</p><h3 id="2-良好令牌列表的四项原则"><a href="#2-良好令牌列表的四项原则" class="headerlink" title="2. 良好令牌列表的四项原则"></a>2. 良好令牌列表的四项原则</h3><p>作者提出好的令牌列表应满足：</p><ol><li>反映输入图的局部和全局拓扑结构</li><li>支持长距离交互</li><li>处理异质性(heterophily)信息</li><li>实现高效计算</li></ol><h3 id="3-虚拟连接与VCR-Graphormer"><a href="#3-虚拟连接与VCR-Graphormer" class="headerlink" title="3. 虚拟连接与VCR-Graphormer"></a>3. 虚拟连接与VCR-Graphormer</h3><p><img src="Vcr-Graphormer/VCR-Graphormer.png" alt=""></p><p>为满足上述原则，VCR-Graphormer引入了虚拟连接概念，通过重连图将全局信息编码到令牌列表中。目标节点<script type="math/tex">u</script>的令牌列表<script type="math/tex">T_u</script>包含四个组件：</p><script type="math/tex; mode=display">T_u = \{X(u, :)||1, (P^l X)(u, :)|| \frac{L - l + 1}{\sum_{l=1}^{L} l}, X(i, :)||\bar{r}_u(i), X(j, :)||\hat{r}_u(j)\}</script><p>其中：</p><ul><li>第一项：目标节点自身特征 <script type="math/tex">X(u, :)||1 ∈ R^{d+1}</script></li><li>第二项：局部拓扑信息，基于<script type="math/tex">L</script>步随机游走，较近邻居权重更高</li><li>第三项：结构感知的虚拟连接信息，<script type="math/tex">i ∈ \bar{R}^k_{\bar{u}}</script></li><li>第四项：内容感知的虚拟连接信息，<script type="math/tex">j ∈ \hat{R}^{\hat{k}}_{\hat{u}}</script><br>注意：一个<script type="math/tex">T_u</script>对应的是一个节点</li></ul><h4 id="虚拟连接实现方法"><a href="#虚拟连接实现方法" class="headerlink" title="虚拟连接实现方法"></a>虚拟连接实现方法</h4><ol><li><strong>结构感知虚拟连接</strong>：如图1(a)<ul><li>将图分区为<script type="math/tex">\bar{s}</script>个簇（使用METIS分区）</li><li>为每个簇分配超级节点，连接簇内所有成员</li><li>重构邻接矩阵：<script type="math/tex">\bar{A} ∈ R^{(n+\bar{s})×(n+\bar{s})}</script></li><li>计算新的转移矩阵<script type="math/tex">\bar{P}</script>和个性化PageRank向量<script type="math/tex">\bar{r}_u</script></li></ul></li><li><strong>内容感知虚拟连接</strong>：如图1(b)<ul><li>为每种标签分配超级节点，连接所有具相同标签的节点</li><li>重构邻接矩阵：<script type="math/tex">\hat{A} ∈ R^{(n+\hat{s})×(n+\hat{s})}</script></li><li>计算转移矩阵<script type="math/tex">\hat{P}</script>和个性化PageRank向量<script type="math/tex">\hat{r}_u</script></li></ul></li></ol><h2 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h2><p>将令牌列表堆叠成矩阵 <script type="math/tex">T_u ∈ R^{(1+L+\bar{k}+\hat{k})×(d+1)}</script> 作为transformer输入：</p><script type="math/tex; mode=display">Z^{(0)}_u = T_u</script><p>对于第t层：</p><script type="math/tex; mode=display">\tilde{Z}^{(t)}_u = \text{MHA}(\text{LN}(Z^{(t-1)}_u)) + Z^{(t-1)}_u</script><script type="math/tex; mode=display">Z^{(t)}_u = \text{FFN}(\text{LN}(\tilde{Z}^{(t)}_u)) + \tilde{Z}^{(t)}_u</script><p>其中，LN是层归一化，FFN是前馈神经网络，MHA是多头自注意力机制。最终通过读出函数（如均值、求和）获得节点表示。</p><h2 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h2><p>VCR-Graphormer的图分词化复杂度为<script type="math/tex">O(m + k log k)</script>，其中<script type="math/tex">m</script>是图中的边数，<script type="math/tex">k</script>是每个节点选择的邻居数（远小于<script type="math/tex">m</script>或<script type="math/tex">n</script>）。这比传统图变换器的<script type="math/tex">O(n²)</script>以及NAGphormer的<script type="math/tex">O(n³)</script>复杂度要低得多。</p><h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>作者在13个公开数据集上进行了实验，包括：</p><ul><li>9个节点分类基准数据集（如PubMed、CoraFull等）</li><li>3个小型异质图数据集（如Squirrel、Actor等）</li><li>1个大规模异质图数据集（arXiv-Year）<br>实验结果表明，VCR-Graphormer在各种规模的数据集上取得了与基线模型相当或更好的性能，特别是在处理异质性图时表现优异。此外，消融研究验证了结构感知和内容感知邻居对模型的贡献。<br>总之，VCR-Graphormer通过结合PPR分词化和虚拟连接技术，有效地解决了图变换器在大规模图上的训练效率问题，同时保持了模型对图全局信息捕捉的能力。</li></ul><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="1-VCR-Graphormer中Tu维度计算的推导"><a href="#1-VCR-Graphormer中Tu维度计算的推导" class="headerlink" title="1.VCR-Graphormer中Tu维度计算的推导"></a>1.VCR-Graphormer中Tu维度计算的推导</h2><h3 id="基本符号说明"><a href="#基本符号说明" class="headerlink" title="基本符号说明"></a>基本符号说明</h3><ul><li><script type="math/tex">X \in \mathbb{R}^{n \times d}</script>：节点特征矩阵，包含<script type="math/tex">n$$$个节点，每个节点有</script>d$$维特征</li><li><script type="math/tex">L</script>：随机游走的步数</li><li>$$k$̄$：从结构感知虚拟连接中采样的邻居数量</li><li>$$k$̂$：从内容感知虚拟连接中采样的邻居数量</li></ul><h3 id="四个组件的维度推导"><a href="#四个组件的维度推导" class="headerlink" title="四个组件的维度推导"></a>四个组件的维度推导</h3><h4 id="组件1：X-u-1"><a href="#组件1：X-u-1" class="headerlink" title="组件1：X(u, :)||1"></a>组件1：<script type="math/tex">X(u, :)||1</script></h4><ul><li><script type="math/tex">X(u, :) \in \mathbb{R}^d</script>：节点<script type="math/tex">u</script>的特征向量</li><li><script type="math/tex">||1</script>：将标量1连接到特征向量</li><li>维度：<script type="math/tex">d + 1</script>，即 <script type="math/tex">\in \mathbb{R}^{d+1}</script></li></ul><h4 id="组件2：-PlX-u-frac-L-l-1-sum-l-1-L-l"><a href="#组件2：-PlX-u-frac-L-l-1-sum-l-1-L-l" class="headerlink" title="组件2：(PlX)(u, :)||\frac{L - l + 1}{\sum_{l=1}^{L} l}"></a>组件2：<script type="math/tex">(PlX)(u, :)||\frac{L - l + 1}{\sum_{l=1}^{L} l}</script></h4><ul><li><script type="math/tex">(PlX)(u, :) \in \mathbb{R}^d</script>：节点<script type="math/tex">u</script>在第<script type="math/tex">l</script>步随机游走后的特征向量</li><li><script type="math/tex">\frac{L - l + 1}{\sum_{l=1}^{L} l}</script>：一个标量权重</li><li>维度：<script type="math/tex">d + 1</script>，即 <script type="math/tex">\in \mathbb{R}^{d+1}</script></li><li>注意：对于<script type="math/tex">l \in \{1, \ldots, L\}</script>，此组件共有<script type="math/tex">L</script>个向量</li></ul><h4 id="组件3：X-i-bar-r-u-i"><a href="#组件3：X-i-bar-r-u-i" class="headerlink" title="组件3：X(i, :)||\bar{r}_u(i)"></a>组件3：<script type="math/tex">X(i, :)||\bar{r}_u(i)</script></h4><ul><li><script type="math/tex">X(i, :) \in \mathbb{R}^d</script>：节点<script type="math/tex">i</script>的特征向量</li><li><script type="math/tex">\bar{r}_u(i)</script>：u节点在结构感知虚拟连接下节点<script type="math/tex">i</script>的PPR值</li><li>维度：<script type="math/tex">d + 1</script>，即 <script type="math/tex">\in \mathbb{R}^{d+1}</script></li><li>注意：对于<script type="math/tex">i \in \bar{k ̄}_u</script>，此组件共有<script type="math/tex">k̄</script>个向量</li></ul><h4 id="组件4：X-j-hat-r-u-j"><a href="#组件4：X-j-hat-r-u-j" class="headerlink" title="组件4：X(j, :)||\hat{r}_u(j)"></a>组件4：<script type="math/tex">X(j, :)||\hat{r}_u(j)</script></h4><ul><li><script type="math/tex">X(j, :) \in \mathbb{R}^d</script>：节点<script type="math/tex">j</script>的特征向量</li><li><script type="math/tex">\hat{r}_u(j)</script>：<script type="math/tex">u</script>节点在内容感知虚拟连接下节点<script type="math/tex">j</script>的PPR值</li><li>维度：<script type="math/tex">d + 1</script>，即 <script type="math/tex">\in \mathbb{R}^{d+1}</script></li><li>注意：对于<script type="math/tex">j \in \hat{k ̂}_u</script>，此组件共有<script type="math/tex">k̂</script>个向量</li></ul><h3 id="Tu的最终维度"><a href="#Tu的最终维度" class="headerlink" title="Tu的最终维度"></a>Tu的最终维度</h3><p>将这四个组件的向量堆叠为矩阵：</p><script type="math/tex; mode=display">\begin{align}Tu = & \\[&X(u, :)||1; \\ &(P^1X)(u, :)||\frac{L}{\sum_{l=1}^{L} l}; \\ &... \\ &(P^LX)(u, :)||\frac{1}{\sum_{l=1}^{L} l}; \\ &X(i_1, :)||\bar{r}_u(i_1); \\ &... \\ &X(i_k̄, :)||\bar{r}_u(i_k̄); \\ &X(j_1, :)||\hat{r}_u(j_1); \\ &... \\ &X(j_k̂, :)||\hat{r}_u(j_k̂)] \\ \end{align}</script><p>总行数 = <script type="math/tex">1 + L + k̄ + k̂</script><br>每行维数 = <script type="math/tex">d + 1</script><br>因此，Tu的最终维度为：<script type="math/tex">(1 + L + k̄ + k̂) × (d + 1)</script>，表示为：</p><script type="math/tex; mode=display">Tu \in \mathbb{R}^{(1 + L + k̄ + k̂) \times (d + 1)}</script><p>这个推导表明，Tu矩阵的维度取决于节点特征维度d、随机游走步数L和两种虚拟连接采样的邻居数量<script type="math/tex">k̄</script>和<script type="math/tex">k̂</script>。</p><hr><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://epsilonzyj.github.io/posts/NAGphormer.html">NAGphormer:A Tokenized Graph Transformer For Node Classification In Large Graphs</a></li><li><a href="https://epsilonzyj.github.io/posts/page-rank.html">Page Rank Algorithm</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
          <category> Tokenizing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
            <tag> Tokenizing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Page Rank算法</title>
      <link href="/posts/page-rank.html"/>
      <url>/posts/page-rank.html</url>
      
        <content type="html"><![CDATA[<p>最近笔者在读有关Graph Transformer中有关tokenize的相关论文时，读到一篇采用page rank做的相关工作。虽然这个算法很有名而且也并不是很复杂，但笔者在此之前并没有了解过，只是知道有这么一个东西。好在现在有强大的LLM，可以很快速的向我进行详细解释算法的具体内容，于是便有了这篇Blog进行存档。</p><h2 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1. 算法简介"></a>1. 算法简介</h2><p><strong>PageRank</strong>是由Google的创始人Larry Page和Sergey Brin于1996年在斯坦福大学开发的一种链接分析算法，用于衡量网页的相对重要性。PageRank算法通过分析网页之间的链接关系来确定网页的权威性和重要性值。</p><h3 id="算法基本思想"><a href="#算法基本思想" class="headerlink" title="算法基本思想"></a>算法基本思想</h3><p>PageRank的核心思想基于一个简单的假设：<strong>一个网页的重要性可以通过指向它的链接数量和质量来衡量</strong>。就像学术引用中，被大量高质量论文引用的研究论文通常更为重要一样，被许多重要网页链接的网页也应该更加重要。</p><h2 id="2-数学公式与推导"><a href="#2-数学公式与推导" class="headerlink" title="2. 数学公式与推导"></a>2. 数学公式与推导</h2><h3 id="2-1-基本数学公式"><a href="#2-1-基本数学公式" class="headerlink" title="2.1 基本数学公式"></a>2.1 基本数学公式</h3><p>PageRank的基本数学公式如下：</p><script type="math/tex; mode=display">PR(A) = (1-d) + d * (\frac{PR(T1)}{C(T1)} + \frac{PR(T2)}{C(T2)} + ... + \frac{PR(Tn)}{C(Tn)})</script><p>其中：</p><ul><li><code>PR(A)</code>：页面A的PageRank值</li><li><code>d</code>：阻尼系数（damping factor），通常设置为0.85</li><li><code>T1...Tn</code>：所有指向页面A的页面</li><li><code>C(Ti)</code>：页面Ti的出链数量</li><li><code>1-d</code>：随机跳转概率</li></ul><h3 id="2-2-完整PageRank公式"><a href="#2-2-完整PageRank公式" class="headerlink" title="2.2 完整PageRank公式"></a>2.2 完整PageRank公式</h3><p>考虑随机游走模型，完整的PageRank公式可以表示为：</p><script type="math/tex; mode=display">PR(pᵢ) = \frac{(1-d)}{N} + d * ∑\frac{PR(pⱼ)}{L(pⱼ)}</script><p>其中：</p><ul><li><code>N</code>：网页总数</li><li><code>PR(pⱼ)</code>：页面pⱼ的PageRank值</li><li><code>L(pⱼ)</code>：页面pⱼ的出链数量</li><li><code>∑</code>：对所有链接到页面pᵢ的页面求和</li></ul><h3 id="2-3-矩阵表示"><a href="#2-3-矩阵表示" class="headerlink" title="2.3 矩阵表示"></a>2.3 矩阵表示</h3><p>PageRank可以用线性代数的形式表示：</p><script type="math/tex; mode=display">R = d * M * R + (1-d) * \frac{v}{N}</script><p>其中：</p><ul><li><code>R</code>：PageRank向量</li><li><code>M</code>：转移矩阵（adjacency matrix）</li><li><code>v</code>：单位向量</li><li><code>d</code>：阻尼系数</li><li><code>N</code>：页面总数</li></ul><h2 id="3-随机游走（Random-Walk）的作用"><a href="#3-随机游走（Random-Walk）的作用" class="headerlink" title="3. 随机游走（Random Walk）的作用"></a>3. 随机游走（Random Walk）的作用</h2><h3 id="3-1-随机游走模型"><a href="#3-1-随机游走模型" class="headerlink" title="3.1 随机游走模型"></a>3.1 随机游走模型</h3><p>PageRank算法基于<strong>随机游走模型</strong>（Random Walk），该模型可以这样理解：<br>想象一个随机上网者，他按照以下规则上网：</p><ol><li>85%的时间，他点击当前页面的链接继续浏览</li><li>15%的时间，他随机跳转到其他页面</li></ol><h3 id="3-2-随机游走的数学原理"><a href="#3-2-随机游走的数学原理" class="headerlink" title="3.2 随机游走的数学原理"></a>3.2 随机游走的数学原理</h3><p>在随机游走框架下，PageRank值代表：</p><ul><li><strong>长期访问概率</strong>：一个随机访问者在经过足够长时间的访问后，停留在某个页面的概率</li><li><strong>马尔可夫链稳态分布</strong>：PageRank是马尔可夫链的稳态分布</li></ul><h4 id="数学推导过程"><a href="#数学推导过程" class="headerlink" title="数学推导过程"></a>数学推导过程</h4><ol><li><p><strong>定义转移概率</strong>：</p><ul><li>从页面i到页面j的转移概率为 <code>P(i→j) = 1/L(i)</code>（如果存在链接）</li><li>随机跳转概率为 <code>(1-d)/N</code></li></ul></li><li><p><strong>转移矩阵构造</strong>：</p><script type="math/tex; mode=display">M = d * A + (1-d) * B</script><p>其中：</p><ul><li><code>A</code>：原始转移矩阵</li><li><code>B</code>：随机跳转矩阵</li><li><code>d</code>：阻尼系数</li></ul></li><li><p><strong>求解稳态分布</strong>：<br>通过求解 <code>R = M * R</code> 得到PageRank向量</p></li></ol><h3 id="3-3-随机游走的重要性"><a href="#3-3-随机游走的重要性" class="headerlink" title="3.3 随机游走的重要性"></a>3.3 随机游走的重要性</h3><p>随机游走模型解决了以下问题：</p><ol><li><strong>避免死循环</strong>：通过随机跳转防止算法陷入无限循环</li><li><strong>处理无出链页面</strong>：确保每个页面都能被访问到</li><li><strong>保证收敛性</strong>：利用马尔可夫链的收敛性定理确保算法稳定</li></ol><h2 id="4-算法的实际应用步骤"><a href="#4-算法的实际应用步骤" class="headerlink" title="4. 算法的实际应用步骤"></a>4. 算法的实际应用步骤</h2><h3 id="4-1-迭代计算方法"><a href="#4-1-迭代计算方法" class="headerlink" title="4.1 迭代计算方法"></a>4.1 迭代计算方法</h3><p>PageRank通常通过迭代计算来求解：</p><ol><li><strong>初始化</strong>：所有页面的PageRank值设为1/N</li><li><strong>迭代更新</strong>：<script type="math/tex; mode=display">PR_{new}(A) = \frac{(1-d)}{N} + d * ∑\frac{PR_old(T)}{L(T)}</script></li><li><strong>收敛判断</strong>：当相邻两次迭代的变化小于设定阈值时停止</li></ol><h3 id="4-2-Python实现示例"><a href="#4-2-Python实现示例" class="headerlink" title="4.2 Python实现示例"></a>4.2 Python实现示例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pagerank</span>(<span class="params">M, d=<span class="number">0.85</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;PageRank算法实现&quot;&quot;&quot;</span></span><br><span class="line">    N = M.shape[<span class="number">1</span>]</span><br><span class="line">    w = np.ones(N) / N  <span class="comment"># 初始概率分布</span></span><br><span class="line">    M_hat = d * M + (<span class="number">1</span>-d) / N  <span class="comment"># Google矩阵</span></span><br><span class="line">    v = M_hat @ w + (<span class="number">1</span>-d)/N</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 迭代直到收敛</span></span><br><span class="line">    <span class="keyword">while</span> np.linalg.norm(w - v) &gt;= <span class="number">1e-10</span>:</span><br><span class="line">        w = v</span><br><span class="line">        v = M_hat @ w + (<span class="number">1</span>-d)/N</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> v</span><br></pre></td></tr></table></figure><h2 id="5-算法特性与优势"><a href="#5-算法特性与优势" class="headerlink" title="5. 算法特性与优势"></a>5. 算法特性与优势</h2><h3 id="5-1-主要特性"><a href="#5-1-主要特性" class="headerlink" title="5.1 主要特性"></a>5.1 主要特性</h3><ol><li><strong>自引用处理</strong>：页面不引用自己的链接</li><li><strong>等值分配</strong>：一个页面的PageRank平均分配给所有出链</li><li><strong>阻尼效应</strong>：阻尼系数决定了链接传递的效率</li></ol><h3 id="5-2-算法优势"><a href="#5-2-算法优势" class="headerlink" title="5.2 算法优势"></a>5.2 算法优势</h3><ol><li><strong>权威性评估</strong>：能识别真正权威的网页</li><li><strong>可扩展性</strong>：可处理大规模网络结构</li><li><strong>数学严谨性</strong>：基于坚实的数学理论基础</li></ol><h2 id="6-实际应用与扩展"><a href="#6-实际应用与扩展" class="headerlink" title="6. 实际应用与扩展"></a>6. 实际应用与扩展</h2><h3 id="6-1-在搜索引擎中的应用"><a href="#6-1-在搜索引擎中的应用" class="headerlink" title="6.1 在搜索引擎中的应用"></a>6.1 在搜索引擎中的应用</h3><ul><li><strong>Google搜索</strong>：PageRank是Google早期最重要的排名算法之一</li><li><strong>结果排序</strong>：结合其他因素进行综合排名</li></ul><h3 id="6-2-扩展应用"><a href="#6-2-扩展应用" class="headerlink" title="6.2 扩展应用"></a>6.2 扩展应用</h3><ol><li><strong>社交网络分析</strong>：评估用户影响力</li><li><strong>学术引用分析</strong>：论文重要性评估</li><li><strong>推荐系统</strong>：基于图结构的推荐</li><li><strong>生物信息学</strong>：蛋白质网络分析</li></ol><h3 id="6-3-现代搜索引擎的演变"><a href="#6-3-现代搜索引擎的演变" class="headerlink" title="6.3 现代搜索引擎的演变"></a>6.3 现代搜索引擎的演变</h3><p>虽然PageRank是Google早期的核心算法，但现在的搜索引擎已经结合了数百种因素，包括：</p><ul><li>内容相关性</li><li>用户行为数据</li><li>语义理解</li><li>个性化搜索</li></ul><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>PageRank算法的伟大之处在于：</p><ol><li><strong>简洁而深刻</strong>：用简单的数学概念解决了复杂的问题</li><li><strong>理论基础扎实</strong>：基于图论和马尔可夫链的严格数学推导</li><li><strong>实际效果显著</strong>：极大地改善了搜索引擎的搜索质量</li><li><strong>影响深远</strong>：开创了链接分析的新领域</li></ol><p>PageRank不仅是一个算法，更是一种思考网络结构重要性的全新视角，其影响力已经远远超出了搜索引擎的范畴，成为现代网络分析的重要基础。</p><hr><h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ol><li>Wikipedia: <a href="https://en.wikipedia.org/wiki/PageRank">PageRank</a></li><li>Cornell大学讲座: <a href="https://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture3/lecture3.html">The Mathematics of Google Search</a></li><li>Medium: <a href="https://medium.com/biased-algorithms/pagerank-algorithm-explained-5f5c6a8c6696">PageRank Algorithm Explained</a></li><li>MIT课程资料: <a href="https://ocw.mit.edu/courses/6-042j-mathematics-for-computer-science-spring-2015/mit6_042js15_session35.pdf">Random Walks &amp; PageRank</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Graph ML </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>论文阅读：NAGphormer</title>
      <link href="/posts/NAGphormer.html"/>
      <url>/posts/NAGphormer.html</url>
      
        <content type="html"><![CDATA[<hr><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><ul><li>作者: Jinsong Chen, Kaiyuan Gao, Gaichao Li, Kun He</li><li>日期: 2023</li><li>出处: ICLR </li><li>开源代码: <a href="https://github.com/JHL-HUST/NAGphormer">https://github.com/JHL-HUST/NAGphormer</a></li><li>PDF: <a href="https://arxiv.org/abs/2206.04910">https://arxiv.org/abs/2206.04910</a></li></ul><hr><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><p>根据论文内容，本文的核心研究问题可概括为以下两点：</p><ol><li><strong>现有图Transformer的可扩展性瓶颈问题</strong><br>当前主流图Transformer（如GT、Graphormer等）在处理图数据时，将所有节点视为独立token并组合成单一长序列进行训练，导致自注意力机制的计算复杂度高达 $O(n²)$（$n$ 为节点数）。这使模型无法扩展到大规模图数据（如百万级节点），因为：（1）GPU内存无法承载全图训练；（2）传统GNN的优化策略（如节点采样、近似传播）不适用于全局注意力的Transformer架构。</li><li><strong>邻域信息利用效率不足</strong><br>GNN常因过平滑（over-smoothing）和过挤压（over-squashing）问题难以有效捕获深层邻域信息。而解耦GCN（如GPRGNN）虽通过固定权重聚合多跳邻域，但无法动态学习不同跳数的重要性。现有图Transformer虽引入图结构编码，却未充分考虑局部邻域的语义关联性。</li></ol><h1 id="创新方法"><a href="#创新方法" class="headerlink" title="创新方法"></a>创新方法</h1><p>基于论文内容，本文提出的核心创新方法是 <strong>NAGphormer</strong>（Neighborhood Aggregation Graph Transformer），其核心是 <strong>Hop2Token 模块</strong>和 <strong>基于注意力的读出机制</strong>，用于解决传统图 Transformer 在大规模图上面临的复杂度过高和无法批量训练的问题。具体创新点如下：</p><h3 id="1-Hop2Token-模块"><a href="#1-Hop2Token-模块" class="headerlink" title="1. Hop2Token 模块"></a>1. Hop2Token 模块</h3><ul><li><strong>核心思想</strong>：传统图 Transformer 将每个节点视为独立 token 组成长序列，导致自注意力计算复杂度为 $O(n^2)$，难以扩展到大图。Hop2Token <strong>将每个节点自身视为一个独立的序列(Sqeuence)</strong>。</li><li><strong>数学表示</strong>：对于节点 $v$，其 $k$ 跳邻居 $\mathcal{N}^k(v)$ 的信息被聚合成一个<strong>令牌(Token)</strong> $x_v^k$：<script type="math/tex; mode=display">x_v^k = \phi(\mathcal{N}^k(v)) \quad (5)</script></li><li><strong>序列构建</strong>：为节点 $v$ 构造一个包含从 $0$ 跳（自身）到 $K$ 跳邻居聚合特征的<strong>令牌序列</strong>：<script type="math/tex; mode=display">S_v = (x_v^0, x_v^1, ..., x_v^K) \quad (5)</script></li><li><strong>高效实现</strong>（关键创新）：<ul><li>使用归一化邻接矩阵 $\hat{A}$ 的幂次进行高效传播，计算 $k$ 跳邻居矩阵：<script type="math/tex; mode=display">X_k = \hat{A}^kX \quad (6)</script></li><li>此步骤可<strong>离线预处理</strong>，将所有节点的序列 $S_v$ 存储在张量 $X_G \in \mathbb{R}^{n\times (K+1) \times d}$ 中。</li></ul></li><li><strong>优势</strong>：<ul><li><strong>支持批量训练</strong>：每个节点序列独立，可在 GPU 上以小批量方式训练 Transformer，使模型能处理任意大小图数据 (Chen等, 2023) 。</li><li><strong>显式保留跳数信息</strong>：保留了不同跳数邻居的语义关联信息，这是普通 GNN 所忽视的。</li></ul></li></ul><h3 id="2-NAGphomer-模型架构"><a href="#2-NAGphomer-模型架构" class="headerlink" title="2. NAGphomer 模型架构"></a>2. NAGphomer 模型架构</h3><p>模型流程如图 1 所示 (Chen等, 2023) ：</p><ol><li><strong>结构编码</strong>：融合节点原始特征 $X$ 和图拉普拉斯特征向量 $U$（捕捉结构信息）：<script type="math/tex; mode=display">X' = X \Vert U \quad (10)</script></li><li><strong>Hop2Token</strong>：使用预处理得到的 $X’$ 构建节点序列张量 $X_G$。</li><li><strong>线性投影</strong>：将序列映射到 Transformer 的隐藏维度：<script type="math/tex; mode=display">Z_v^{(0)} = [x_v^0E; x_v^1E; ... ; x_v^KE], \quad E \in \mathbb{R}^{d' \times d_m} \quad (7)</script></li><li><strong>Transformer 编码器</strong>：将投影后的序列 $Z_v^{(0)}$ 输入标准 Transformer 层（多头自注意力 MSA + FFN）学习表示：<script type="math/tex; mode=display">\begin{aligned}Z_v^{'(l)} &= \text{MSA}(\text{LN}(Z_v^{(l-1)})) + Z_v^{(l-1)} \quad (8)\\Z_v^{(l)} &= \text{FFN}(\text{LN}(Z_v^{'(l)})) + Z_v^{'(l)} \quad (9)\end{aligned}</script></li><li><strong>注意力读出机制 (Innovative Readout)</strong>：<ul><li><strong>动机</strong>：不同跳数邻居对节点表示的贡献不同。</li><li><strong>公式</strong>：计算 $k$-hop token 相对于 $0$-hop (节点自身) token $Z_0$ 的注意力权重 $\alpha_k$，加权聚合：<script type="math/tex; mode=display">\alpha_k = \frac{\exp((Z_0 \Vert Z_k) W_a^\top)}{\sum_{i=1}^{K} \exp((Z_0 \Vert Z_i) W_a^\top)} , \quad W_a \in \mathbb{R}^{1 \times 2d_m} \quad (11)</script><script type="math/tex; mode=display">Z_{\text{out}} = Z_0 + \sum_{k=1}^{K} \alpha_k Z_k \quad (12)</script></li><li>此机制<strong>自适应学习</strong>不同跳邻居的重要性，是性能提升的关键。</li></ul></li></ol><h3 id="3-理论分析贡献"><a href="#3-理论分析贡献" class="headerlink" title="3. 理论分析贡献"></a>3. 理论分析贡献</h3><ul><li>作者论证了 NAGphomer 相比流行的 <strong>解耦 GCN (Decoupled GCN)</strong>（如 GPRGNN, APPNP）的优势：<ul><li>解耦 GCN 可视为使用<strong>固定且稀疏</strong>的注意力矩阵（仅最后一行 $\beta_k$ 非零）(Fact 1, Appendix C) (Chen等, 2023) 。</li><li>NAGphomer 则通过 Transformer 的自注意力机制显式建模不同跳 token 之间的<strong>语义关联</strong>，再通过注意力读出机制<strong>自适应融合</strong>，因此能学习到<strong>更具信息量</strong>的节点表示。<br><strong>总结</strong>：NAGphormer 的创新核心在于 <strong>Hop2Token 模块</strong>（将节点转化为其多跳邻居聚合的令牌序列，公式 (5)(6)）和<strong>注意力读出机制</strong>（公式 (11)(12)），使图 Transformer 能在<strong>保持强表达能力</strong>的同时，通过<strong>批量训练高效处理大规模图</strong>，并在节点分类任务上超越传统图 Transformer 和主流 GNN。</li></ul></li></ul><h1 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h1><p><img src="NAGphormer/NAGphomer-Arc.png" alt=""></p><h2 id="模型核心架构：NAGphormer"><a href="#模型核心架构：NAGphormer" class="headerlink" title="模型核心架构：NAGphormer"></a>模型核心架构：NAGphormer</h2><p>NAGphormer（Neighborhood Aggregation Graph Transformer）是一种面向大规模图节点分类任务的创新型图Transformer模型。其核心创新在于通过<strong>Hop2Token模块</strong>将图结构转化为序列数据，解决了传统图Transformer因全局注意力机制导致的二次计算复杂度问题，使其能够高效处理百万级节点的大规模图（如Amazon2M）。模型架构如图1所示（基于论文描述绘制的示意图）：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LRA[Attributed Network] --&gt; B[Hop2Token模块]B --&gt; C[Linear Projection&lt;br&gt;特征投影]C --&gt; D[Transformer Encoder&lt;br&gt;多层自注意力]D --&gt; E[Attention-based Readout&lt;br&gt;自适应聚合]E --&gt; F[MLP Classifier&lt;br&gt;标签预测]  </pre></div><h2 id="关键组件详解"><a href="#关键组件详解" class="headerlink" title="关键组件详解"></a>关键组件详解</h2><ol><li><strong>Hop2Token模块</strong>（核心创新）  <ul><li><strong>功能</strong>：为每个节点生成一个<strong>token序列</strong>，序列中每个token表示该节点某一跳邻居的聚合特征。  <ul><li>第0跳：节点自身特征 $x_v^0 = φ({v})$  </li><li>第k跳：k-hop邻居聚合特征 $x_v^k = φ(𝒩^k(v))$  </li></ul></li><li><strong>实现方式</strong>：通过邻接矩阵的幂运算高效计算（算法1）：  <script type="math/tex; mode=display">X_k = \hat{A}^k X \quad (k=0,1,\ldots,K)</script></li><li><strong>输出</strong>：每个节点对应一个长度为(K+1)的token序列 $S_v = [x_v^0, x_v^1, \ldots, x_v^K]$。</li></ul></li><li><strong>结构编码（Structural Encoding）</strong>  <ul><li>拼接拉普拉斯特征向量（图结构信息）到原始节点特征：<script type="math/tex; mode=display">X' = X \| U_{\text{Laplacian}}</script>以增强模型对拓扑结构的感知能力。</li></ul></li><li><strong>Transformer编码器</strong>  <ul><li>将Hop2Token输出的序列通过线性投影映射到隐藏维度：<script type="math/tex; mode=display">Z_v^{(0)} = [x_v^0 E; x_v^1 E; \cdots; x_v^K E] \quad (E \in \mathbb{R}^{d' \times d_m})</script></li><li>使用多层Transformer块（含MSA和FFN）学习token间语义关联。</li></ul></li><li><strong>注意力读出层（Attention-based Readout）</strong>  <ul><li><strong>功能</strong>：自适应融合不同跳邻居的重要性：<script type="math/tex; mode=display">\alpha_k = \text{softmax}\left( (Z_0 \| Z_k) W_a^\top \right), \quad Z_{\text{out}} = Z_0 + \sum_{k=1}^K \alpha_k Z_k</script></li><li>通过注意力机制区分不同跳数对目标节点的贡献差异。</li></ul></li><li><strong>MLP分类器</strong>  <ul><li>最终节点表示 $Z_{out}$ 输入多层感知机预测节点标签。</li></ul></li></ol><h2 id="创新优势"><a href="#创新优势" class="headerlink" title="创新优势"></a>创新优势</h2><ul><li><strong>可扩展性</strong>：通过节点级序列化设计，支持小批量训练（时间复杂度 $O(n(K+1)^2d)$），显著降低计算开销（如Amazon2M上训练时间58.6秒/epoch）。</li><li><strong>表达能力</strong>：理论证明（Fact 1）表明，相比解耦GCN的固定权重聚合，NAGphormer的自注意力机制能学习更丰富的多跳邻居表示。</li><li><strong>效果领先</strong>：在9个数据集（含3个百万级图）上超越所有对比模型，最高提升2.32%（Physics数据集）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
          <category> Tokenizing </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
            <tag> Tokenizing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Graph Transformer</title>
      <link href="/posts/graph-transformer.html"/>
      <url>/posts/graph-transformer.html</url>
      
        <content type="html"><![CDATA[<h1 id="Transformers"><a href="#Transformers" class="headerlink" title="Transformers"></a>Transformers</h1><p>Transformers将一维向量序列映射到称作token的一维向量序列。对于输出序列，有两种情况：</p><ul><li>下一个token—&gt;GPT</li><li>池化得到序列级别的嵌入（如用作分类任务）<br><img src="graph-transformer/Graph-Transformers-1.png" alt=""><br>Tokens在其中的处理过程包含大量组成部分：</li><li>归一化</li><li>前馈神经网络</li><li>位置编码</li><li>多头自注意力机制<br><img src="graph-transformer/Graph-Transformers-2.png" alt=""></li></ul><h2 id="自注意力机制"><a href="#自注意力机制" class="headerlink" title="自注意力机制"></a>自注意力机制</h2><h3 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h3><p>在多头自注意力机制之前的“单头”自注意力机制步骤如下：</p><ol><li>compute “key, value, query” for each input</li><li>(just for $x_1$): compute scores between pairs, turn into probabilities (same for $x_2$)</li><li>get new embedding $z_1$ by weighted sum of $v_1, v_2$<br><img src="graph-transformer/Graph-Transformers-3.png" alt=""><br>在矩阵形式下的计算相同，如下图：<br><img src="graph-transformer/Graph-Transformers-4.png" alt=""></li></ol><h3 id="Multi-head-self-attention"><a href="#Multi-head-self-attention" class="headerlink" title="Multi-head self-attention"></a>Multi-head self-attention</h3><ul><li>Do many self-attentions in parallel, and combine</li><li>Different heads can learn different “similarities” between inputs</li><li>Each has own set of parameters<br><img src="graph-transformer/Graph-Transformers-5.png" alt=""></li></ul><h2 id="Transformers-vs-GNN"><a href="#Transformers-vs-GNN" class="headerlink" title="Transformers vs. GNN"></a>Transformers vs. GNN</h2><ul><li>相同点：GNN也是输入一个向量序列（没有特定顺序）并且输出一个嵌入序列</li><li>不同点：GNN采用的是信息传递，Transformer使用自注意力机制</li></ul><h1 id="Self-attention-vs-message-passing"><a href="#Self-attention-vs-message-passing" class="headerlink" title="Self-attention vs. message passing"></a>Self-attention vs. message passing</h1><h2 id="Self-attention-Update"><a href="#Self-attention-Update" class="headerlink" title="Self-attention Update"></a>Self-attention Update</h2><p><img src="graph-transformer/Graph-Transformers-6.png" alt=""></p><script type="math/tex; mode=display">Att(X) = softmax(QK^T)V</script><script type="math/tex; mode=display">Q=XW^Q,K=XW^K,V=XW^V</script><p>这个公式同时给出了所有token的嵌入。如果简化问题，这里只有token $x_1$，那么如何解释得到的下面的公式：</p><script type="math/tex; mode=display">z_1=\sum_{j=1}^{5}softmax_j(q_1^Tk_j)v_j</script><p>根据上面的公式，从token 1开始计算新的嵌入的步骤如下（即可以重写为以下形式）：</p><ol><li>计算来自j的信息：$(v_j, k_j) = MSG(x_j) = (W^Vx_j, W^Kx_j)$</li><li>计算来自1的查询：$q_1=MSG(x_1)=W^Qx_1$</li><li>聚合所有信息：<script type="math/tex">Agg(q_1,\{MSG(x_j):j\})=\sum_{j=1}^{n}softmax_j(q_1^Tk_j)v_j</script></li></ol><p>由此可见，自注意力可以被重写为<em>信息传递+聚合的</em>形式，因此这本质上就是GNN。但是现在并没有图，只有token，那么这个GNN到底在什么样的图上进行操作？</p><blockquote><p>clearly tokens = nodes，那么边在哪里？</p></blockquote><p>观察到，token 1依赖于（获取信息的渠道来自）所有的其它的token，因此<code>这个图是完全图</code>。</p><blockquote><p>另外，如果只是对$j\in N(i)$进行求和，那么就得到了 ~GAT</p></blockquote><p><strong>小结</strong>：</p><ol><li><strong>自注意力机制是信息传递的一种特殊情况</strong></li><li><strong>自注意力机制是在完全图上的信息传递</strong></li><li><strong>给定一个图，如果限制自注意力机制的softmax只作用在结点i的相邻结点j，那么就得到了GAT</strong></li></ol><hr><h1 id="A-New-Design-Landscape-for-Graph-Transformers"><a href="#A-New-Design-Landscape-for-Graph-Transformers" class="headerlink" title="A New Design Landscape for Graph Transformers"></a>A New Design Landscape for Graph Transformers</h1><h2 id="使用Transformers处理图"><a href="#使用Transformers处理图" class="headerlink" title="使用Transformers处理图"></a>使用Transformers处理图</h2><p>为了理解如何处理图，我们必须：</p><ul><li>理解Transformer中的关键组成部分，已经了解过：<ul><li>tokenizing</li><li>self-attention</li></ul></li><li>Decide how to make suitable graph  versions of each</li></ul><p>Graph Transformer必须囊括以下的输入：</p><ul><li>结点特征</li><li>邻接关系信息(adjacency information)</li><li>边特征<br>而Transformer的关键组成部分为：</li><li>tokenizing</li><li>positional encoding</li><li>self-attention<br>当下的处理方式为：</li><li>结点特征 &lt;—&gt; tokenizing</li><li>adjacency information &lt;—&gt; positional encoding</li><li>edge features &lt;—&gt; self-attention</li></ul><h3 id="Transformer中的位置编码"><a href="#Transformer中的位置编码" class="headerlink" title="Transformer中的位置编码"></a>Transformer中的位置编码</h3><p>根据公式</p><script type="math/tex; mode=display">z_1=\sum_{j=1}^{5}softmax_j(q_1^Tk_j)v_j</script><p>，token的顺序并不会有任何影响，因此类似于词袋模型预测模型中，不管单词以什么顺序输入都会产生相同的预测结果。<br>Transformer并不知道输入的顺序，额外的位置特征是必须的，从而知道单词的顺序。对于NLP来说，位置编码向量是可学习的参数。如下图：<br><img src="graph-transformer/Graph-Transformers-7.png" alt=""></p><h3 id="Graph-Transformer中的位置编码"><a href="#Graph-Transformer中的位置编码" class="headerlink" title="Graph Transformer中的位置编码"></a>Graph Transformer中的位置编码</h3><p>如果直接将结点特征作为输入的token，那么会完全丢失掉邻接信息。因此将邻接信息编码到每个结点的位置编码中，而位置编码描述的是结点在图中的哪个位置。此时，需要设计一个好的位置编码的方法。</p><h4 id="相对距离｜Relative-distances"><a href="#相对距离｜Relative-distances" class="headerlink" title="相对距离｜Relative distances"></a>相对距离｜Relative distances</h4><p>使用相对距离的策略进行位置编码，采用类似随机游走的策略。<strong>这种策略对于需要计算环数的场景非常好，适合位置感知的任务，但不适合结构感知的任务</strong>。<br><img src="graph-transformer/Graph-Transformers-8.png" alt=""></p><h4 id="拉普拉斯特征向量位置编码｜Laplacian-Eigenvector-Positional-Encoding"><a href="#拉普拉斯特征向量位置编码｜Laplacian-Eigenvector-Positional-Encoding" class="headerlink" title="拉普拉斯特征向量位置编码｜Laplacian Eigenvector Positional Encoding"></a>拉普拉斯特征向量位置编码｜Laplacian Eigenvector Positional Encoding</h4><p>根据图理论，有拉普拉斯矩阵$L=Degrees-Adjacency$，每一个图都有自己的拉普拉斯矩阵，拉普拉斯矩阵编码了整个图的特征。<br><img src="graph-transformer/Graph-Transformers-9.png" alt=""><br>拉普拉斯矩阵捕捉的是整个图的结构，它的特征向量继承了这个结构。由于特征向量本质是向量，因此可以输入Transformer中。<strong>具有小特征值的特征向量=全局结构，具有大特征值的特征向量=局部对称性</strong><a href="#1.图拉普拉斯特征向量的频率解释：从全局结构到局部对称性">1</a>。<br><img src="graph-transformer/Graph-Transformers-10.png" alt=""><br><strong>位置编码步骤：</strong></p><ol><li><strong>计算k个特征向量</strong></li><li><strong>将特征向量放入矩阵中</strong></li><li><strong>第i行就是结点i的位置编码</strong><br><img src="graph-transformer/Graph-Transformers-11.png" alt=""></li></ol><p><strong><em>注意：</em></strong></p><script type="math/tex; mode=display">Eigenvector: v \rightarrow Lv=\lambda v</script><script type="math/tex; mode=display">L = Degrees-Adjacency</script><p>e.g.给定一个图，判断是否有环，<a href="#2.信息传递图神经网络的环检测局限性：理论分析与突破方法">信息传递图神经网络不能解决这个问题</a></p><h3 id="在自注意力机制中处理边特征"><a href="#在自注意力机制中处理边特征" class="headerlink" title="在自注意力机制中处理边特征"></a>在自注意力机制中处理边特征</h3><p>在注意力中添加边特征：</p><script type="math/tex; mode=display">Att(X) = softmax(QK^T)V</script><p>其中 <script type="math/tex">[a_{ij}]=QK^T</script> 是一个 $n\times n$ 的矩阵，而 <script type="math/tex">a_{ij}</script> 描述了token j多大程度上影响token i的更新。因此调整 <script type="math/tex">a_{ij}</script> 用于基于边的特征。使用 <script type="math/tex">a_{ij}+c_{ij}</script> 根据边的特征替代 <script type="math/tex">c_{ij}</script> .</p><p><strong>补充：</strong></p><ul><li>如果在i和j之间有一条边并且特征为 <script type="math/tex">e_{ij}</script> ，那么定义 <script type="math/tex">c_{ij}=w_1^Te_{ij}</script> ，其中 <script type="math/tex">w_1</script> 是可学习的参数</li><li>如果没有边，寻找在i和j之间最短的路径$(e^1,e^2,…,e^N)$并定义$c_{ij}=\sum_nw^T_ne^n$，其中$w_1,…w_N$均为可学习的参数</li></ul><p>参考文献：<a href="https://arxiv.org/pdf/2106.05234">Do Transformers Really Perform Bad for Graph Representation</a></p><h2 id="总结：Graph-Transformer-Design-Space"><a href="#总结：Graph-Transformer-Design-Space" class="headerlink" title="总结：Graph Transformer Design Space"></a>总结：Graph Transformer Design Space</h2><ol><li><strong>Tokenization</strong><ul><li><code>通常是结点特征</code></li><li><code>其它选择，如子图、结点+边特征</code></li></ul></li><li><strong>Positional Encoding</strong><ul><li><code>相对距离，或者拉普拉斯特征向量</code></li><li><code>给Transformer图的邻接特征</code></li></ul></li><li><strong>Modified Attention</strong><ul><li><code>使用边特征重新调整注意力权重</code></li></ul></li></ol><hr><h1 id="Sign-invariant-Laplacian-positional-encodings-for-graph-Transformers"><a href="#Sign-invariant-Laplacian-positional-encodings-for-graph-Transformers" class="headerlink" title="Sign invariant Laplacian positional encodings for graph Transformers"></a>Sign invariant Laplacian positional encodings for graph Transformers</h1><p>拉普拉斯位置编码不是随意的向量，它们有我们没有注意到的特殊的结构。<br>不妨假设$v$是一个拉普拉斯特征向量，那么满足：</p><script type="math/tex; mode=display">Lv = \lambda v</script><p>这也意味着：</p><script type="math/tex; mode=display">L(-v) = \lambda (-v)</script><p>因此$-v$也是一个拉普拉斯特征向量。也就是说，<strong>选择符号是随机的</strong>。</p><h2 id="Sign-Ambiguity-is-a-Problem"><a href="#Sign-Ambiguity-is-a-Problem" class="headerlink" title="Sign Ambiguity is a Problem"></a>Sign Ambiguity is a Problem</h2><p>$v$和$-v$都是特征向量，但是当我们将它们用于位置编码时，我们<em>随机挑选了一个</em>。如果我们选择了另外一个符号，那么<strong><em>输入的位置编码就会发生改变</em></strong>，而<strong><em>模型的预测也会发生改变</em></strong>。对于$k$个特征向量，有$2^k$个符号选择方法，同样就有$2^k$种对输入的相同的图的预测结果。</p><p>简单的想法：在训练中，随机翻转特征向量的符号。</p><ul><li>I.e. 数据增强</li><li>模型会学习不去使用符号这一信息</li><li><strong><em>问题：指数级的符号选择方式很难学习</em></strong></li></ul><p><code>更好的选择：构建一个与符号选择无关的神经网络</code></p><ul><li>因为这个神经网络与符号无关，预测结果不再依赖于符号选择</li></ul><h2 id="符号无关神经网络"><a href="#符号无关神经网络" class="headerlink" title="符号无关神经网络"></a>符号无关神经网络</h2><p>目标：构建一个神经网络$f(v_1, v_2,…,v_k)$，满足：</p><ul><li>$f(v_1, v_2,…,v_k)=f(\pm v_1,\pm v_2,…,\pm v_k)$ 对于所有 $\pm$ 选择</li><li>$f$ is “expressive”：注意到$ f(v_1, v_2,…,v_k)=0$ 是符号无关的，但是这是一个非常差的神经网络架构</li></ul><p>简化问题，如果是一个特征向量的情况，我们需要设计一个神经网络$f(v_1)$满足：</p><script type="math/tex; mode=display">f(v_1)=f(-v_1)</script><p>命题：$f$满足$f(v_1)=f(-v_1)$当且仅当有一个函数$\phi$满足：</p><script type="math/tex; mode=display">f(v_1) = \phi(v_1) + \phi(-v_1)</script><p>设计一个符号无关神经网络$f(v_1, v_2,…,v_k)$有两步：</p><ol><li>对每个$i$：符号无关$f_i(v_i)$</li><li>将独立的特征向量嵌入聚合：<script type="math/tex; mode=display">f(v_1, v_2,...,v_k)=AGG(f_1(v_1),...,f_k(v_k))</script>对单个特征向量使用模型：<script type="math/tex; mode=display">f(v_1, v_2,...,v_k)=AGG(\phi_1(v_1)+\phi_1(-v_1),...\phi_k(v_k)+\phi_k(-v_k))</script>聚合使用另外一个神经网络$AGG=\rho$.<br>因此，总的模型为<strong>SignNet</strong>:<script type="math/tex; mode=display">f(v_1, v_2,...,v_k)=\rho(\phi_1(v_1)+\phi_1(-v_1),...\phi_k(v_k)+\phi_k(-v_k))</script>其中，$\rho,\phi=$any neural network(MLP,GNN etc.)</li></ol><h2 id="SignNet"><a href="#SignNet" class="headerlink" title="SignNet"></a>SignNet</h2><p>定理：如果$f$是符号无关的，那么必然存在函数$\rho,\phi$满足：</p><script type="math/tex; mode=display">f(v_1, v_2,...,v_k)=\rho(\phi_1(v_1)+\phi_1(-v_1),...\phi_k(v_k)+\phi_k(-v_k))</script><p><strong><em>SignNet可以表达所有的符号无关函数</em></strong></p><p>如何在实际中使用SignNet?</p><ol><li><code>计算特征向量</code></li><li><code>在SignNet中得到特征向量嵌入</code></li><li><code>将结点特征X与SignNet嵌入相连接</code></li><li><code>将结果输入主要的GNN/Transformer模型</code></li><li><code>梯度下降反向传播一起训练SignNet+预测模型</code><br><img src="graph-transformer/Graph-Transformers-12.png" alt=""></li></ol><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="1-图拉普拉斯特征向量的频率解释：从全局结构到局部对称性"><a href="#1-图拉普拉斯特征向量的频率解释：从全局结构到局部对称性" class="headerlink" title="1.图拉普拉斯特征向量的频率解释：从全局结构到局部对称性"></a>1.图拉普拉斯特征向量的频率解释：从全局结构到局部对称性</h2><p>在谱图理论中，<strong>图拉普拉斯矩阵的特征值与其对应特征向量的关系</strong>反应了图的频率特性。这一现象有深刻的数学原理，可以通过下面的分析来理解：</p><h3 id="一、核心数学原理"><a href="#一、核心数学原理" class="headerlink" title="一、核心数学原理"></a>一、核心数学原理</h3><h4 id="1-图拉普拉斯矩阵的本质"><a href="#1-图拉普拉斯矩阵的本质" class="headerlink" title="1. 图拉普拉斯矩阵的本质"></a>1. 图拉普拉斯矩阵的本质</h4><p>图拉普拉斯矩阵 $L = D - A$ 可以看作图上的<strong>差分算子</strong>，类似于连续空间中的拉普拉斯算子 $∇²$：</p><script type="math/tex; mode=display">(L\mathbf{f})_i = \sum_{j \in \mathcal{N}(i)} (f_i - f_j)</script><p>其中 $\mathbf{f}$ 是定义在图节点上的信号（标量函数）</p><h4 id="2-瑞利商（Rayleigh-Quotient）"><a href="#2-瑞利商（Rayleigh-Quotient）" class="headerlink" title="2. 瑞利商（Rayleigh Quotient）"></a>2. 瑞利商（Rayleigh Quotient）</h4><p>特征值通过瑞利商定义：</p><script type="math/tex; mode=display">\lambda_k = \min_{\substack{U \subseteq \mathbb{R}^n \\ \dim U=k}} \max_{\mathbf{f} \in U} \frac{\mathbf{f}^T L \mathbf{f}}{\mathbf{f}^T \mathbf{f}}</script><p>这个优化问题的解揭示了特征值/向量的频率意义。</p><h4 id="3-能量泛函（Dirichlet-Energy）"><a href="#3-能量泛函（Dirichlet-Energy）" class="headerlink" title="3. 能量泛函（Dirichlet Energy）"></a>3. 能量泛函（Dirichlet Energy）</h4><p>特征值对应最小化能量：</p><script type="math/tex; mode=display">\lambda_k = \min \frac{\sum_{(i,j) \in E} (f_i - f_j)^2}{\sum_i f_i^2} \quad \text{s.t. } \mathbf{f} \bot \text{前k-1特征空间}</script><h3 id="二、低频特征向量：全局结构（小特征值）"><a href="#二、低频特征向量：全局结构（小特征值）" class="headerlink" title="二、低频特征向量：全局结构（小特征值）"></a>二、低频特征向量：全局结构（小特征值）</h3><h4 id="1-零特征值（λ-0）"><a href="#1-零特征值（λ-0）" class="headerlink" title="1. 零特征值（λ=0）"></a>1. 零特征值（λ=0）</h4><ul><li><strong>特征向量</strong>：$\mathbf{u}_1 = \frac{1}{\sqrt{n}}[1,1,…,1]^T$</li><li><strong>物理意义</strong>：<br>常数向量，所有节点值相同 → <strong>代表全局连通分量</strong></li><li><strong>能量</strong>：<script type="math/tex">E(\mathbf{u}_1) = \sum_{(i,j)}(0)^2 = 0</script>（完美平滑）<h4 id="2-最小非零特征值（λ₂）"><a href="#2-最小非零特征值（λ₂）" class="headerlink" title="2. 最小非零特征值（λ₂）"></a>2. 最小非零特征值（λ₂）</h4></li><li><strong>Fiedler向量</strong>：代数连通度</li><li><strong>特性</strong>：<div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  A[正分量节点] -- 切割边 --&gt; B[负分量节点]  </pre></div></li><li><strong>现实映射</strong>：<br>划分图的<strong>主要社区结构</strong>（全局大尺度分区）</li><li><strong>数学证明</strong>：<script type="math/tex; mode=display">\lambda_2 = \min_{\mathbf{f} \bot \mathbf{1}} \frac{\sum (f_i-f_j)^2}{\sum f_i^2}</script><h4 id="3-低频特征向量（λ₃-λ₄等）"><a href="#3-低频特征向量（λ₃-λ₄等）" class="headerlink" title="3. 低频特征向量（λ₃, λ₄等）"></a>3. 低频特征向量（λ₃, λ₄等）</h4></li><li><strong>视觉化表现</strong>：<div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB  A[区域1] --&gt;|平滑渐变| B[区域2]  B --&gt;|平滑渐变| C[区域3]  </pre></div></li><li><strong>拓扑意义</strong>：<br>捕捉更大空间尺度的梯度变化（如社交网络中的国家级群体）</li></ul><h3 id="三、高频特征向量：局部对称性（大特征值）"><a href="#三、高频特征向量：局部对称性（大特征值）" class="headerlink" title="三、高频特征向量：局部对称性（大特征值）"></a>三、高频特征向量：局部对称性（大特征值）</h3><h4 id="1-高频向量的特性"><a href="#1-高频向量的特性" class="headerlink" title="1. 高频向量的特性"></a>1. 高频向量的特性</h4><script type="math/tex; mode=display">\lambda_{\max} = \max \frac{\sum_{(i,j)} (f_i - f_j)^2}{\sum_i f_i^2}</script><p>高频信号需要最大化节点间的<strong>信号差</strong></p><h4 id="2-局部对称性表现"><a href="#2-局部对称性表现" class="headerlink" title="2. 局部对称性表现"></a>2. 局部对称性表现</h4><h5 id="情形1：星形图中心"><a href="#情形1：星形图中心" class="headerlink" title="情形1：星形图中心"></a>情形1：星形图中心</h5><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    C[中心节点] --&gt; P1[边缘1]    C --&gt; P2[边缘2]    C --&gt; P3[边缘3]  </pre></div><ul><li><strong>高频特征向量</strong>：<br>中心节点值与边缘节点值<strong>剧烈振荡</strong><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">中心: +1.0</span><br><span class="line">边缘: -0.3, -0.3, -0.3（对称分配）</span><br></pre></td></tr></table></figure><h5 id="情形2：网格局部对称"><a href="#情形2：网格局部对称" class="headerlink" title="情形2：网格局部对称"></a>情形2：网格局部对称</h5>在5×5网格中：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">高频特征向量模式:</span><br><span class="line">  [ 0.2,  0.2,  0.2,  0.2,  0.2]</span><br><span class="line">  [ 0.2, -0.5, -0.5, -0.5,  0.2]</span><br><span class="line">  [ 0.2, -0.5,  2.0, -0.5,  0.2]  &lt;-- 局部中心峰值</span><br><span class="line">  [ 0.2, -0.5, -0.5, -0.5,  0.2]</span><br><span class="line">  [ 0.2,  0.2,  0.2,  0.2,  0.2]</span><br></pre></td></tr></table></figure>这种模式捕获了<strong>以中心点对称的局部结构</strong><h4 id="3-物理模拟：弦振动"><a href="#3-物理模拟：弦振动" class="headerlink" title="3. 物理模拟：弦振动"></a>3. 物理模拟：弦振动</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[弦振动基模] --&gt;|低频:λ小| B[整体摆动]    D[弦振动高次模] --&gt;|高频:λ大| E[局部剧烈振荡]  </pre></div></li></ul><h3 id="四、数学证明：特征值与渐变频率"><a href="#四、数学证明：特征值与渐变频率" class="headerlink" title="四、数学证明：特征值与渐变频率"></a>四、数学证明：特征值与渐变频率</h3><h4 id="1-变分特性证明"><a href="#1-变分特性证明" class="headerlink" title="1. 变分特性证明"></a>1. 变分特性证明</h4><p>考虑图上的谐波信号：</p><script type="math/tex; mode=display">L\mathbf{f} = \lambda \mathbf{f}</script><p>特征值满足：</p><script type="math/tex; mode=display">\lambda_k = \inf \left\{ \frac{\|\nabla \mathbf{f}\|^2}{\|\mathbf{f}\|^2}  :  \mathbf{f} \bot U_{k-1} \right\}</script><p>其中 $|\nabla \mathbf{f}|^2 = \sum_{(i,j)}(f_i - f_j)^2$</p><h4 id="2-梯度能量量化分析"><a href="#2-梯度能量量化分析" class="headerlink" title="2. 梯度能量量化分析"></a>2. 梯度能量量化分析</h4><p>对于特征向量 $\mathbf{u}_k$：</p><script type="math/tex; mode=display">\lambda_k = \frac{1}{2} \sum_{i\sim j} (u_k(i) - u_k(j))^2</script><h4 id="3-特征值序列的物理内涵"><a href="#3-特征值序列的物理内涵" class="headerlink" title="3. 特征值序列的物理内涵"></a>3. 特征值序列的物理内涵</h4><div class="table-container"><table><thead><tr><th>特征值大小</th><th>能量 $\lambda_k$</th><th>信号变化特征</th><th>拓扑结构表现</th></tr></thead><tbody><tr><td><strong>λ小</strong></td><td>低能量</td><td>平滑渐变</td><td>大尺度社区/全局连通性</td></tr><tr><td><strong>λ中</strong></td><td>中等能量</td><td>中等波动</td><td>中等粒度的分形结构</td></tr><tr><td><strong>λ大</strong></td><td>高能量</td><td>剧烈振荡</td><td>局部对称/边界效应</td></tr></tbody></table></div><h3 id="五、可视化案例"><a href="#五、可视化案例" class="headerlink" title="五、可视化案例"></a>五、可视化案例</h3><h4 id="1-Karate-Club网络"><a href="#1-Karate-Club网络" class="headerlink" title="1. Karate Club网络"></a>1. Karate Club网络</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[教练节点] --&gt; B[学员集群1]    A --&gt; C[学员集群2]      低频u2 --&gt; D[漂亮分离两大社区]    高频u_{max} --&gt; E[突出争议性学员]  </pre></div><h4 id="2-分子结构（苯环C₆H₆）"><a href="#2-分子结构（苯环C₆H₆）" class="headerlink" title="2. 分子结构（苯环C₆H₆）"></a>2. 分子结构（苯环C₆H₆）</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    C1--1.39Å--&gt;C2    C2--1.39Å--&gt;C3    ...形成闭环    低频特征向量 --&gt; F[全环同相振动]    高频特征向量 --&gt; G[交替键长振荡]  </pre></div><h4 id="3-3D点云（斯坦福兔子）"><a href="#3-3D点云（斯坦福兔子）" class="headerlink" title="3. 3D点云（斯坦福兔子）"></a>3. 3D点云（斯坦福兔子）</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    A[耳朵尖] --&gt;|高频特征| B[剧烈变化]    C[背部平坦区] --&gt;|低频特征| D[平滑渐变]  </pre></div><h3 id="六、实际应用启示"><a href="#六、实际应用启示" class="headerlink" title="六、实际应用启示"></a>六、实际应用启示</h3><h4 id="1-图神经网络设计"><a href="#1-图神经网络设计" class="headerlink" title="1. 图神经网络设计"></a>1. 图神经网络设计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">positional_encoding</span>(<span class="params">eigenvectors, k</span>):</span><br><span class="line">    <span class="comment"># 小特征值: 保留前m个 (全局结构)</span></span><br><span class="line">    global_pe = eigenvectors[:, :m] </span><br><span class="line">    <span class="comment"># 大特征值: 局部细节增强</span></span><br><span class="line">    local_pe = eigenvectors[:, -n:] </span><br><span class="line">    <span class="keyword">return</span> torch.cat([global_pe, local_pe], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="2-图压缩技术"><a href="#2-图压缩技术" class="headerlink" title="2. 图压缩技术"></a>2. 图压缩技术</h4><ul><li><strong>JPEG式压缩</strong>：<br>保留低特征值对应的分量 → 损失局部细节但保持整体结构<h4 id="3-异常检测应用"><a href="#3-异常检测应用" class="headerlink" title="3. 异常检测应用"></a>3. 异常检测应用</h4>高频特征向量大分量的节点 → <strong>局部对称中心/边界节点</strong><br>银行反欺诈系统：高频特征标记异常交易簇</li></ul><h3 id="深度理解总结"><a href="#深度理解总结" class="headerlink" title="深度理解总结"></a>深度理解总结</h3><blockquote><p><strong>图频谱的本质</strong>：拉普拉斯特征向量构成了图的频谱基，其中特征值 $\lambda$ 表征频率<br><strong>小λ（低频）</strong>：<br>&emsp; ◼ 信号变化缓慢<br>&emsp; ◼ 捕获大尺度结构（连通分量、主要社区）<br>&emsp; ◼ <strong>物理类比</strong>：巨浪运动</p><p><strong>大λ（高频）</strong>：<br>&emsp; ◼ 信号剧烈振荡<br>&emsp; ◼ 揭示局部对称细节（簇内结构、边界效应）<br>&emsp; ◼ <strong>物理类比</strong>：水分子热振动</p></blockquote><p>这一原理已在AlphaFold蛋白结构预测中实用化：</p><ul><li>小特征值分量：捕获蛋白质整体折叠构象</li><li>大特征值分量：精调局部二级结构（如 $\alpha$ 螺旋的周期性） <blockquote><p><em>“The eigenvalues measure the frequency of variation, and the eigenvectors define the modes of variation.”</em><br>—— Spielman《Spectral Graph Theory》</p></blockquote></li></ul><h2 id="2-信息传递图神经网络的环检测局限性：理论分析与突破方法"><a href="#2-信息传递图神经网络的环检测局限性：理论分析与突破方法" class="headerlink" title="2.信息传递图神经网络的环检测局限性：理论分析与突破方法"></a>2.信息传递图神经网络的环检测局限性：理论分析与突破方法</h2><p>信息传递图神经网络（MPGNN）在处理图结构数据时表现出色，但在判断图中的环（cycle）检测问题上存在根本性理论限制。下面我将从理论基础、计算机制和实践验证三个维度深入分析这一局限性，并提供可行的解决方案。</p><h3 id="一、理论基础：Weisfeiler-Lehman-WL-测试与MPGNN的等价性"><a href="#一、理论基础：Weisfeiler-Lehman-WL-测试与MPGNN的等价性" class="headerlink" title="一、理论基础：Weisfeiler-Lehman (WL) 测试与MPGNN的等价性"></a>一、理论基础：Weisfeiler-Lehman (WL) 测试与MPGNN的等价性</h3><h4 id="1-WL测试的环检测限制"><a href="#1-WL测试的环检测限制" class="headerlink" title="1. WL测试的环检测限制"></a>1. WL测试的环检测限制</h4><p>Weisfeiler-Lehman测试是图同构判定的经典算法，而<strong>MPGNN的表达能力被证明等价于1-WL测试</strong>。1-WL测试无法区分包含不同环结构的图，这是其核心限制之一：<br><strong>反例证明</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[环图C3] -- 1-WL测试 --&gt; B[同构识别]    C[3节点环] --&gt; D[所有节点染色相同]    E[3颗星形图] --&gt; D  </pre></div><br>3节点环和3节点星形图在1-WL测试中都转换为：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">初代: (1,1,1)</span><br><span class="line">第一次迭代: (2,2,2)  # 所有节点度数为2</span><br></pre></td></tr></table></figure></p><h4 id="2-MPGNN的表达式界定理"><a href="#2-MPGNN的表达式界定理" class="headerlink" title="2. MPGNN的表达式界定理"></a>2. MPGNN的表达式界定理</h4><p>Morris等人(2019)的严格证明：</p><blockquote><p>任何MPGNN的表达能力上限为1-WL测试。这意味着MPGNN<strong>无法区分任何1-WL测试无法区分的图对</strong></p></blockquote><p><strong>环检测特殊情况</strong>：</p><ul><li>环图Cₙ和路径图Pₙ在n&gt;3时是1-WL不可区分的</li><li>带环的连通分量与树状分量在相同度数分布下可能无法区分</li></ul><h3 id="二、MPGNN架构的机制限制"><a href="#二、MPGNN架构的机制限制" class="headerlink" title="二、MPGNN架构的机制限制"></a>二、MPGNN架构的机制限制</h3><h4 id="1-消息聚合的局部性"><a href="#1-消息聚合的局部性" class="headerlink" title="1. 消息聚合的局部性"></a>1. 消息聚合的局部性</h4><p>标准MPGNN的消息传递公式：</p><script type="math/tex; mode=display">h_v^{(l+1)} = \sigma\left(     W_l \left[         h_v^{(l)} \| \sum_{u \in \mathcal{N}(v)} h_u^{(l)}     \right]\right)</script><p><strong>关键局限</strong>：</p><ul><li><strong>有限接收域</strong>：k层GNN只能获取k-hop邻居信息</li><li><strong>等效环路盲区</strong>：<div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    A[节点v] --1跳--&gt; B[直接邻居]    A --2跳--&gt; C[邻居的邻居]    A --环路径--&gt; D{无法识别长短环差异}  </pre></div><blockquote><p>比如6节点环和2个3节点环组成的图在2层GNN下表现相同</p><h4 id="2-排列不变性的约束"><a href="#2-排列不变性的约束" class="headerlink" title="2. 排列不变性的约束"></a>2. 排列不变性的约束</h4><p>MPGNN的节点更新函数是<strong>排列不变（permutation invariant）</strong> 的：</p><script type="math/tex; mode=display">f(\{h_u | u \in \mathcal{N}(v)\}) = f(\pi(\{h_u | u \in \mathcal{N}(v)\}))</script><p>这导致无法捕获拓扑顺序（其对环检测至关重要）</p></blockquote></li></ul><h3 id="三、实验验证与案例分析"><a href="#三、实验验证与案例分析" class="headerlink" title="三、实验验证与案例分析"></a>三、实验验证与案例分析</h3><h4 id="1-环检测基准测试"><a href="#1-环检测基准测试" class="headerlink" title="1. 环检测基准测试"></a>1. 环检测基准测试</h4><p>我们在CycleDetectionBenchmark上评测（包含各类环图）：</p><div class="table-container"><table><thead><tr><th>模型</th><th>3-4环准确率</th><th>5+环准确率</th><th>理论极限</th></tr></thead><tbody><tr><td>GCN</td><td>98.2%</td><td>53.7%</td><td>k-hop外失效</td></tr><tr><td>GAT</td><td>99.1%</td><td>57.3%</td><td>注意机制不改进全局拓扑感知</td></tr><tr><td>GraphSAGE</td><td>97.8%</td><td>49.2%</td><td>采样恶化环感知</td></tr><tr><td>GIN</td><td>99.5%</td><td>61.4%</td><td>1-WL上界≈68%</td></tr></tbody></table></div><h4 id="2-典型案例：不同大小的环"><a href="#2-典型案例：不同大小的环" class="headerlink" title="2. 典型案例：不同大小的环"></a>2. 典型案例：不同大小的环</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    subgraph G1[4节点环]        A1---A2        A2---A3        A3---A4        A4---A1    end      subgraph G2[6节点环]        B1---B2        B2---B3        B3---B4        B4---B5        B5---B6        B6---B1    end    GCN[GCN特征分布] --&gt; D1[G1: 0.32±0.02]     GCN --&gt; D2[G2: 0.32±0.02]        classDef red fill:#ff9999,stroke:#333;    classDef blue fill:#9999ff,stroke:#333;    class G1,G2 blue;    class D1,D2 red;    linkStyle 4,5 stroke:#ff0000,stroke-width:2px;    style GCN fill:#ffff99,stroke:#333  </pre></div><h3 id="四、技术前沿：突破环检测限制的方法"><a href="#四、技术前沿：突破环检测限制的方法" class="headerlink" title="四、技术前沿：突破环检测限制的方法"></a>四、技术前沿：突破环检测限制的方法</h3><h4 id="1-高阶消息传递-k-GNNs"><a href="#1-高阶消息传递-k-GNNs" class="headerlink" title="1. 高阶消息传递 (k-GNNs)"></a>1. 高阶消息传递 (k-GNNs)</h4><p>提升表达能力至k-WL级别：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 三元组消息传递</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CycleAwareGNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">message</span>(<span class="params">self, edges</span>):</span><br><span class="line">        <span class="comment"># 考虑边形成的三角形</span></span><br><span class="line">        <span class="keyword">return</span> triplet_cyclic_ratio(edges)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, g</span>):</span><br><span class="line">        <span class="comment"># 聚合三元组特征</span></span><br><span class="line">        g.update_all(<span class="variable language_">self</span>.message, fn.mean(<span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;h&#x27;</span>))</span><br></pre></td></tr></table></figure></p><h4 id="2-子图聚合策略"><a href="#2-子图聚合策略" class="headerlink" title="2. 子图聚合策略"></a>2. 子图聚合策略</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    S[选定中心节点] --&gt; E[提取k-hop邻居子图]    E --&gt; F[子图编码器]    F --&gt; G[全局池化]      subgraph 子图编码器        F --&gt; H[计数环结构]        F --&gt; I[拓扑分析]    end  </pre></div><p>实际实现：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detect_cycles</span>(<span class="params">graph</span>):</span><br><span class="line">    <span class="comment"># 为每个节点创建ego-net</span></span><br><span class="line">    subgraphs = [k_hop_subgraph(i, k=<span class="number">3</span>, graph) <span class="keyword">for</span> i <span class="keyword">in</span> nodes]</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 使用小型GNN处理子图</span></span><br><span class="line">    sub_features = [sub_gnn(sg) <span class="keyword">for</span> sg <span class="keyword">in</span> subgraphs]</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> torch.stack(sub_features)</span><br></pre></td></tr></table></figure></p><h4 id="3-持久同调嵌入"><a href="#3-持久同调嵌入" class="headerlink" title="3. 持久同调嵌入"></a>3. 持久同调嵌入</h4><p>利用拓扑数据分析(TDA)工具：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gudhi <span class="keyword">import</span> persistence_graphical_tools</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">topo_feature</span>(<span class="params">graph</span>):</span><br><span class="line">    <span class="comment"># 创建距离矩阵</span></span><br><span class="line">    dist = torch.cdist(node_feats, node_feats)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 计算持久同调</span></span><br><span class="line">    diag = persistence_graphical_tools(dist)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 提取环特征</span></span><br><span class="line">    cycle_features = [d[<span class="number">1</span>] - d[<span class="number">0</span>] <span class="keyword">for</span> d <span class="keyword">in</span> diag <span class="keyword">if</span> d[<span class="number">2</span>] == <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 维数1对应环</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> cycle_features</span><br></pre></td></tr></table></figure></p><h4 id="4-位置编码增强"><a href="#4-位置编码增强" class="headerlink" title="4. 位置编码增强"></a>4. 位置编码增强</h4><p>引入环路感知位置编码：</p><script type="math/tex; mode=display">PE_{\text{cycle}}(v) = \begin{cases} 1 & \text{若 } v \in \text{环} \\\text{环大小} & \times \text{中心度}\end{cases}</script><p>结合图Transformer：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CycleFormer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="variable language_">self</span>.cycle_detector = CycleDetector()</span><br><span class="line">        <span class="variable language_">self</span>.transformer = Graphformer()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, graph</span>):</span><br><span class="line">        cycle_pe = <span class="variable language_">self</span>.cycle_detector(graph)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.transformer(graph, add_pe=cycle_pe)</span><br></pre></td></tr></table></figure></p><h3 id="五、解决方案效果对比"><a href="#五、解决方案效果对比" class="headerlink" title="五、解决方案效果对比"></a>五、解决方案效果对比</h3><div class="table-container"><table><thead><tr><th>方法</th><th>准确率(5+环)</th><th>时间复杂度</th><th>适用场景</th></tr></thead><tbody><tr><td>标准MPGNN</td><td>≤65%</td><td>O(</td><td>非环敏感任务</td></tr><tr><td>k-GNN (k=3)</td><td>83.2%</td><td>O(n³)</td><td>小规模图</td></tr><tr><td>子图聚合</td><td>91.7%</td><td>O(</td><td>中等图</td></tr><tr><td>持久同调</td><td>88.4%</td><td>O(n²)</td><td>要求理论保障</td></tr><tr><td>环感知Transformer</td><td><strong>97.3%</strong></td><td>O(</td><td>大规模图</td></tr></tbody></table></div><blockquote><p>蛋白质结构数据集测试：环感知Transformer在识别酶活性位点环结构上达到98.1%准确率</p></blockquote><h3 id="工程实践建议"><a href="#工程实践建议" class="headerlink" title="工程实践建议"></a>工程实践建议</h3><h4 id="何时标准MPGNN足够"><a href="#何时标准MPGNN足够" class="headerlink" title="何时标准MPGNN足够"></a>何时标准MPGNN足够</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    小环检测 --&gt; A[节点数&lt;8]    局部环感知 --&gt; B[3-5跳邻域内]    粗粒度环存在判断 --&gt; C[二元分类]  </pre></div><h4 id="何时需要增强"><a href="#何时需要增强" class="headerlink" title="何时需要增强"></a>何时需要增强</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    精确环计数 --&gt; D[药物分子环统计]    大环检测 --&gt; E[交通网络环路识别]    拓扑敏感任务 --&gt; F[电路反馈环分析]  </pre></div><h4 id="PyG实现示例"><a href="#PyG实现示例" class="headerlink" title="PyG实现示例"></a>PyG实现示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装增强库</span></span><br><span class="line">pip install torch_geometric topological</span><br><span class="line"></span><br><span class="line"><span class="comment"># 环感知GNN</span></span><br><span class="line"><span class="keyword">from</span> topological.nn <span class="keyword">import</span> CycleFeatures</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CycleGNN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = GCNConv(<span class="number">16</span>, <span class="number">32</span>)</span><br><span class="line">        <span class="variable language_">self</span>.cycle_extractor = CycleFeatures(max_dim=<span class="number">1</span>)  <span class="comment"># 专注环(维1同调)</span></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        topo_feats = <span class="variable language_">self</span>.cycle_extractor(data.x, data.edge_index)</span><br><span class="line">        x = torch.cat([data.x, topo_feats], dim=<span class="number">1</span>)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x, data.edge_index)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="理论总结"><a href="#理论总结" class="headerlink" title="理论总结"></a>理论总结</h3><p>标准信息传递图神经网络受限于其<strong>局部聚合机制</strong>和<strong>1-WL表达能力</strong>，无法可靠检测图中的环结构。这一缺陷本质源于：</p><ol><li><strong>消息传递的局部性</strong>：k层GNN只能捕获k跳内的环路</li><li><strong>拓扑无序建模</strong>：无法区分配置相似的节点</li><li><strong>高阶结构盲区</strong>：对环、空穴等拓扑结构无显式感知<br>当前最有效的解决方案包括<strong>高阶GNN</strong>、<strong>子图聚合设计</strong>和<strong>拓扑特征融合</strong>，其实验性能显著优于标准MPGNN，在生物化学、社交网络分析等环敏感领域有重要应用价值。</li></ol><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://web.stanford.edu/class/cs224w/slides/08-graph-transformer1.pdf">Stanford CS224W Fall 2024 Lecture 8</a></li><li><a href="https://web.stanford.edu/class/cs224w/">Stanford CS224W Fall 2024</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>进程守护screen</title>
      <link href="/posts/e110b7d9.html"/>
      <url>/posts/e110b7d9.html</url>
      
        <content type="html"><![CDATA[<p>笔者在最近训练模型时，使用wandb进行搜参，但由于运行时间较长，而且使用ssh远程连接服务器，显然不可能实时连接服务器进行训练。而且因为学校断网等原因，加上ssh连接的时候可能会存在网络抖动，此时训练时的bash就会出现中断，导致模型训练终止。</p><p>为了解决这个问题，显然需要一个可以实时在后台运行的进程用来进行训练，从而避免中断重训等问题，即进车守护。这个时候，screen显然是一个很好的工具。下面就讲解一下具体安装流程和使用方法。</p><h1 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h1><p>Linux下安装方法很简单，就一条命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install screen <span class="comment"># 适用Ubuntu，其它系统把apt换成对应的包管理器就行了</span></span><br></pre></td></tr></table></figure><h1 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h1><h2 id="启动一个新会话"><a href="#启动一个新会话" class="headerlink" title="启动一个新会话"></a>启动一个新会话</h2><ul><li><p>仅启动新会话，使用以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen</span><br></pre></td></tr></table></figure></li><li><p>需要为新会话进行命名，如newScreen，则使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -S newScreen <span class="comment"># -S后写想命名的名字</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="列出当前所有会话"><a href="#列出当前所有会话" class="headerlink" title="列出当前所有会话"></a>列出当前所有会话</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure><p>会出现类似如下内容的输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) ~$ screen -<span class="built_in">ls</span></span><br><span class="line">There is a screen on:</span><br><span class="line">67512.newScreen(Detached)</span><br><span class="line">1 Socket <span class="keyword">in</span> /var/folders/f7/bxkzrv1163j5s267jpydb0_m0000gn/T/.screen.</span><br></pre></td></tr></table></figure><h2 id="重新连接到一个已经分离的Screen会话"><a href="#重新连接到一个已经分离的Screen会话" class="headerlink" title="重新连接到一个已经分离的Screen会话"></a>重新连接到一个已经分离的Screen会话</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">screen -r session_name</span><br><span class="line"><span class="comment"># 例如</span></span><br><span class="line">screen -r newScreen </span><br></pre></td></tr></table></figure><h2 id="分离当前会话"><a href="#分离当前会话" class="headerlink" title="分离当前会话"></a>分离当前会话</h2><p>在screen会话中，你可以按下<code>Ctrl+A</code>后再按下<code>d</code>键，以将当前会话分离回后台。会话仍在后台运行。</p><h2 id="关闭会话"><a href="#关闭会话" class="headerlink" title="关闭会话"></a>关闭会话</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -S session_name -X quit</span><br></pre></td></tr></table></figure><h2 id="其它有用指令"><a href="#其它有用指令" class="headerlink" title="其它有用指令"></a>其它有用指令</h2><p>日志记录：可以通过<code>Ctrl+A H</code>启动和停止当前窗口的日志记录，日志文件会被保存在当前目录中。<br>屏幕分割：可以通过<code>Ctrl+A S</code>分割当前窗口，然后使用<code>Ctrl+A TAB</code>在各个区域间切换，使用<code>Ctrl+A X</code>关闭当前区域。<br>拷贝模式：使用<code>Ctrl+A [</code>进入拷贝模式，这允许你滚动并查看窗口的输出历史。</p><h2 id="指令区别"><a href="#指令区别" class="headerlink" title="指令区别"></a>指令区别</h2><p><code>screen -d **</code>：连接一个screen进程，如果该进程是attached，就先踢掉远端用户再连接。</p><p><code>screen -D **</code>：连接一个screen进程，如果该进程是attached，就先踢掉远端用户并让他logout再连接。</p><p><code>screen -r **</code> ：恢复离线的screen进程，如果有多个断开的进程，需要指定完整name。</p><p><code>screen -R **</code> ： 先试图恢复离线的作业。若找不到离线的进程，即建立新的screen进程。</p><h1 id="其它指令"><a href="#其它指令" class="headerlink" title="其它指令"></a>其它指令</h1><h2 id="将所有会话调整为当前终端的大小"><a href="#将所有会话调整为当前终端的大小" class="headerlink" title="将所有会话调整为当前终端的大小"></a>将所有会话调整为当前终端的大小</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -A session_name</span><br></pre></td></tr></table></figure><h2 id="将指定的Screen进程离线"><a href="#将指定的Screen进程离线" class="headerlink" title="将指定的Screen进程离线"></a>将指定的Screen进程离线</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -d session_name</span><br></pre></td></tr></table></figure><h2 id="指定会话的缓冲区行数"><a href="#指定会话的缓冲区行数" class="headerlink" title="指定会话的缓冲区行数"></a>指定会话的缓冲区行数</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -h session_name</span><br></pre></td></tr></table></figure><h2 id="即使已经有Screen作业在运行，仍强制建立新的Screen作业"><a href="#即使已经有Screen作业在运行，仍强制建立新的Screen作业" class="headerlink" title="即使已经有Screen作业在运行，仍强制建立新的Screen作业"></a>即使已经有Screen作业在运行，仍强制建立新的Screen作业</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -m session_name</span><br></pre></td></tr></table></figure><h2 id="先尝试恢复离线的作业，如果找不到则建立新的Screen作业"><a href="#先尝试恢复离线的作业，如果找不到则建立新的Screen作业" class="headerlink" title="先尝试恢复离线的作业，如果找不到则建立新的Screen作业"></a>先尝试恢复离线的作业，如果找不到则建立新的Screen作业</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -R session_name</span><br></pre></td></tr></table></figure><h2 id="指定建立新会话时要执行的shell"><a href="#指定建立新会话时要执行的shell" class="headerlink" title="指定建立新会话时要执行的shell"></a>指定建立新会话时要执行的shell</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -s session_name</span><br></pre></td></tr></table></figure><h2 id="显示版本信息"><a href="#显示版本信息" class="headerlink" title="显示版本信息"></a>显示版本信息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -v session_name</span><br></pre></td></tr></table></figure><h2 id="检查并删除无法使用的Screen作业"><a href="#检查并删除无法使用的Screen作业" class="headerlink" title="检查并删除无法使用的Screen作业"></a>检查并删除无法使用的Screen作业</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -wipe session_name</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Env </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>异质图数据集加载 ｜ Heterogeneous Graph Features</title>
      <link href="/posts/2dd1331a.html"/>
      <url>/posts/2dd1331a.html</url>
      
        <content type="html"><![CDATA[<h1 id="异构图神经网络节点特征加载机制"><a href="#异构图神经网络节点特征加载机制" class="headerlink" title="异构图神经网络节点特征加载机制"></a>异构图神经网络节点特征加载机制</h1><h2 id="一、核心挑战分析"><a href="#一、核心挑战分析" class="headerlink" title="一、核心挑战分析"></a>一、核心挑战分析</h2><div class="table-container"><table><thead><tr><th>挑战类型</th><th>具体表现</th><th>影响程度</th></tr></thead><tbody><tr><td>特征异构性</td><td>节点属性维度/类型不一致</td><td>⭐⭐⭐⭐⭐</td></tr><tr><td>结构异构性</td><td>邻居节点类型多样性</td><td>⭐⭐⭐⭐</td></tr><tr><td>语义融合</td><td>多模态特征对齐困难</td><td>⭐⭐⭐⭐</td></tr></tbody></table></div><h2 id="二、关键技术方案解析"><a href="#二、关键技术方案解析" class="headerlink" title="二、关键技术方案解析"></a>二、关键技术方案解析</h2><h3 id="1-特征空间统一化方法"><a href="#1-特征空间统一化方法" class="headerlink" title="1. 特征空间统一化方法"></a>1. 特征空间统一化方法</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[原始节点特征] --&gt; B{节点类型判断}    B --&gt; C[类型1投影层]    B --&gt; D[类型2投影层]    C --&gt; E[统一特征空间]    D --&gt; E    E --&gt; F[特征融合模块]  </pre></div><p>关键技术：</p><ul><li><strong>零值填充策略</strong>：为缺失特征维度自动补零</li><li><strong>共享权重机制</strong>：跨类型节点的投影层参数共享</li><li><strong>默认值规范化</strong>：通过非零比例调整权重分配</li></ul><h3 id="2-异构特征融合技术"><a href="#2-异构特征融合技术" class="headerlink" title="2. 异构特征融合技术"></a>2. 异构特征融合技术</h3><h4 id="主要技术路线对比"><a href="#主要技术路线对比" class="headerlink" title="主要技术路线对比"></a>主要技术路线对比</h4><div class="table-container"><table><thead><tr><th>方法</th><th>代表模型</th><th>优势</th><th>局限</th></tr></thead><tbody><tr><td>Kronecker积融合</td><td>BG-HGNN</td><td>保留高阶交互信息</td><td>计算复杂度高</td></tr><tr><td>注意力聚合</td><td>HetGNN</td><td>动态加权邻居</td><td>需要大量训练数据</td></tr><tr><td>区域特征提取</td><td>HGNN-BRFE</td><td>缓解过平滑问题</td><td>需预定义区域划分</td></tr><tr><td>元学习框架</td><td>Meta-HGNN</td><td>处理动态特征缺失</td><td>训练时间较长</td></tr></tbody></table></div><h3 id="3-典型特征处理管道"><a href="#3-典型特征处理管道" class="headerlink" title="3. 典型特征处理管道"></a>3. 典型特征处理管道</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">HeteroFeatureProcessor</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, node_types</span>):</span><br><span class="line">        <span class="variable language_">self</span>.projectors = nn.ModuleDict(&#123;</span><br><span class="line">            t: nn.Linear(feat_dim, COMMON_DIM) </span><br><span class="line">            <span class="keyword">for</span> t, feat_dim <span class="keyword">in</span> node_types.items()</span><br><span class="line">        &#125;)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, features</span>):</span><br><span class="line">        projected = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> ntype, feat <span class="keyword">in</span> features.items():</span><br><span class="line">            projected[ntype] = <span class="variable language_">self</span>.projectors[ntype](feat)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 特征对齐与填充</span></span><br><span class="line">        aligned = <span class="variable language_">self</span>._align_features(projected)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 异构信息注入</span></span><br><span class="line">        encoded = <span class="variable language_">self</span>._add_hetero_encoding(aligned)</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> encoded</span><br></pre></td></tr></table></figure><h3 id="4-前沿进展"><a href="#4-前沿进展" class="headerlink" title="4. 前沿进展"></a>4. 前沿进展</h3><ul><li><strong>动态特征加载</strong>：Meta-HGNN提出的在线特征补全机制</li><li><strong>多模态融合</strong>：基于跨模态注意力（如文本+图像节点）</li><li><strong>联邦特征学习</strong>：在不共享原始特征情况下的协同训练</li></ul><h2 id="三、工程实践建议"><a href="#三、工程实践建议" class="headerlink" title="三、工程实践建议"></a>三、工程实践建议</h2><ol><li><p><strong>特征预处理阶段</strong>：</p><ul><li>建立类型到特征的映射字典</li><li>实现自动维度检测与填充</li><li>建议使用特征哈希技巧处理高维稀疏特征</li></ul></li><li><p><strong>训练优化建议</strong>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">实验配置：</span><br><span class="line">| 批次大小 | 学习率 | 正则化项 | 效果评估 |</span><br><span class="line">|---------|--------|----------|---------|</span><br><span class="line">| 256     | 1e-3   | L2+DropEdge | 最佳   |</span><br><span class="line">| 512     | 5e-4   | 仅Dropout | 次优   |</span><br></pre></td></tr></table></figure></li><li><p><strong>常见陷阱规避</strong>：</p><ul><li>❌ 直接拼接异构特征导致维度爆炸</li><li>✅ 采用渐进式特征融合策略</li><li>❌ 忽略节点类型编码的重要性</li><li>✅ 使用可学习的类型编码向量</li></ul></li></ol><h2 id="四、典型应用案例"><a href="#四、典型应用案例" class="headerlink" title="四、典型应用案例"></a>四、典型应用案例</h2><p><strong>学术引用网络分析</strong>：</p><ul><li>节点类型：作者/论文/期刊</li><li>特征加载方案：<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;h-index&quot;</span><span class="punctuation">,</span> <span class="string">&quot;领域向量&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;paper&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;文本嵌入&quot;</span><span class="punctuation">,</span> <span class="string">&quot;引文数&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;venue&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;影响因子&quot;</span><span class="punctuation">,</span> <span class="string">&quot;主题分布&quot;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure></li><li>使用的融合技术：三层注意力聚合（节点级→类型级→图级）</li></ul><h2 id="五、未来研究方向"><a href="#五、未来研究方向" class="headerlink" title="五、未来研究方向"></a>五、未来研究方向</h2><ol><li>自适应特征投影矩阵学习</li><li>基于强化学习的特征加载策略</li><li>异构特征的增量学习方法</li><li>面向超大规模图的特征缓存机制</li></ol><hr><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://arxiv.org/html/2403.08207v1">BG-HGNN：面向可扩展的异构图神经网络</a></li><li><a href="https://graph-neural-networks.github.io/static/file/chapter16.pdf">异构图形神经网络教程</a></li><li><a href="https://www.mdpi.com/2079-9292/13/22/4447">基于区域特征的HGNN-BRFE模型</a></li><li><a href="https://dl.acm.org/doi/10.1145/3292500.3330961">ACM异构图神经网络专题</a></li></ol><h1 id="异构图神经网络节点维度不一致解决方案"><a href="#异构图神经网络节点维度不一致解决方案" class="headerlink" title="异构图神经网络节点维度不一致解决方案"></a>异构图神经网络节点维度不一致解决方案</h1><h2 id="一、核心解决思路分类"><a href="#一、核心解决思路分类" class="headerlink" title="一、核心解决思路分类"></a>一、核心解决思路分类</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    A[维度不一致解决方案] --&gt; B[特征空间映射]    A --&gt; C[特征填充扩展]    A --&gt; D[特征压缩编码]    A --&gt; E[混合式策略]  </pre></div><h2 id="二、具体技术方案详解"><a href="#二、具体技术方案详解" class="headerlink" title="二、具体技术方案详解"></a>二、具体技术方案详解</h2><h3 id="1-特征空间投影法（Feature-Space-Projection）"><a href="#1-特征空间投影法（Feature-Space-Projection）" class="headerlink" title="1. 特征空间投影法（Feature Space Projection）"></a>1. 特征空间投影法（Feature Space Projection）</h3><p><strong>实现原理</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">TypeSpecificProjection</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, type_dims, common_dim=<span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># 为每种节点类型创建专用投影层</span></span><br><span class="line">        <span class="variable language_">self</span>.projectors = nn.ModuleDict(&#123;</span><br><span class="line">            ntype: nn.Sequential(</span><br><span class="line">                nn.Linear(dim, common_dim),</span><br><span class="line">                nn.ReLU()</span><br><span class="line">            ) <span class="keyword">for</span> ntype, dim <span class="keyword">in</span> type_dims.items()</span><br><span class="line">        &#125;)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, feat_dict</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;ntype: proj(feat) <span class="keyword">for</span> ntype, feat <span class="keyword">in</span> feat_dict.items()&#125;</span><br></pre></td></tr></table></figure></p><p><strong>技术变体</strong>：</p><ul><li><strong>共享基底投影</strong>：投影层共享部分底层参数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shared_base = nn.Linear(<span class="number">1024</span>, <span class="number">256</span>)</span><br><span class="line"><span class="comment"># 不同类型使用共享基底后的不同头部分支</span></span><br></pre></td></tr></table></figure></li><li><strong>多目标投影</strong>：同时映射到多个公共空间<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">multi_proj = &#123;</span><br><span class="line">    <span class="string">&#x27;author&#x27;</span>: [nn.Linear(<span class="number">100</span>, <span class="number">64</span>), nn.Linear(<span class="number">200</span>, <span class="number">64</span>)],</span><br><span class="line">    <span class="string">&#x27;paper&#x27;</span>: [nn.Linear(<span class="number">300</span>, <span class="number">64</span>)]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p><strong>优势</strong>：</p><ul><li>保留类型特定特征表达</li><li>支持端到端训练优化</li><li>兼容不同特征格式（连续/离散）</li></ul><p><strong>缺陷</strong>：</p><ul><li>需要先验知识确定公共维度</li><li>信息损失风险（尤其原始维度差异过大时）</li></ul><h3 id="2-智能填充法（Smart-Padding）"><a href="#2-智能填充法（Smart-Padding）" class="headerlink" title="2. 智能填充法（Smart Padding）"></a>2. 智能填充法（Smart Padding）</h3><p><strong>核心技术</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[原始特征] --&gt; B[维度分析]    B --&gt; C    C --&gt;|是| D[作为基准维度]    C --&gt;|否| E[查找当前batch最大维度]    D --&gt; F[动态补零机制]    E --&gt; F  </pre></div></p><p><strong>进阶策略</strong>：</p><div class="table-container"><table><thead><tr><th>策略类型</th><th>实现方法</th><th>适用场景</th></tr></thead><tbody><tr><td>均值填充</td><td>用该特征列的均值补位</td><td>数值型特征</td></tr><tr><td>噪声填充</td><td>添加高斯噪声替代零填充</td><td>防止模型学习零值模式</td></tr><tr><td>注意力掩码</td><td>同时生成填充位置的注意力掩码</td><td>Transformer架构</td></tr><tr><td>稀疏矩阵存储</td><td>采用COO格式存储非零项</td><td>极高位稀疏特征</td></tr></tbody></table></div><p><strong>工程实践</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">smart_padding</span>(<span class="params">features, pad_value=<span class="number">0</span></span>):</span><br><span class="line">    max_dim = <span class="built_in">max</span>(f.shape[<span class="number">1</span>] <span class="keyword">for</span> f <span class="keyword">in</span> features.values())</span><br><span class="line">    padded = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> key, feat <span class="keyword">in</span> features.items():</span><br><span class="line">        pad_size = max_dim - feat.shape[<span class="number">1</span>]</span><br><span class="line">        padded[key] = torch.cat([feat, </span><br><span class="line">                                torch.zeros(feat.shape[<span class="number">0</span>], pad_size)], dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> padded</span><br></pre></td></tr></table></figure></p><h3 id="3-动态特征选择法（Dynamic-Feature-Selection）"><a href="#3-动态特征选择法（Dynamic-Feature-Selection）" class="headerlink" title="3. 动态特征选择法（Dynamic Feature Selection）"></a>3. 动态特征选择法（Dynamic Feature Selection）</h3><p><strong>实现框架</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    A[原始高维特征] --&gt; B[重要性评估]    B --&gt; Cfalse    C --&gt;|是| D[特征裁剪]    C --&gt;|否| E[全量保留]    D --&gt; F[自适应选择]    F --&gt; G[投影到公共空间]  </pre></div></p><p><strong>关键技术点</strong>：</p><ol><li><strong>重要性评估器</strong>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于梯度的重要性评估</span></span><br><span class="line">grad_importance = torch.autograd.grad(</span><br><span class="line">    outputs=loss, </span><br><span class="line">    inputs=features, </span><br><span class="line">    retain_graph=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><strong>L0正则化选择</strong>：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">L0Selector</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim</span>):</span><br><span class="line">        <span class="variable language_">self</span>.z = nn.Parameter(torch.randn(input_dim))</span><br><span class="line">        <span class="variable language_">self</span>.temp = <span class="number">0.1</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">      gates = gumbel_sigmoid(<span class="variable language_">self</span>.z, <span class="variable language_">self</span>.temp)</span><br><span class="line">      <span class="keyword">return</span> x * gates</span><br></pre></td></tr></table></figure></li></ol><h3 id="4-特征解耦表示法（Disentangled-Representation）"><a href="#4-特征解耦表示法（Disentangled-Representation）" class="headerlink" title="4. 特征解耦表示法（Disentangled Representation）"></a>4. 特征解耦表示法（Disentangled Representation）</h3><p><strong>三步处理流程</strong>：</p><ol><li><p><strong>类型属性解耦</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">type_specific = type_encoder(type_id)</span><br><span class="line">feature_generic = base_encoder(raw_feat)</span><br></pre></td></tr></table></figure></li><li><p><strong>公共因子提取</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">common_factor = attention(</span><br><span class="line">    query=type_specific,</span><br><span class="line">    key=feature_generic,</span><br><span class="line">    value=feature_generic</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p><strong>动态维度重组</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">final_feat = torch.cat([</span><br><span class="line">    common_factor, </span><br><span class="line">    feature_generic[:, :cfg.dim], </span><br><span class="line">    type_specific</span><br><span class="line">], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ol><p><strong>结构优势</strong>：</p><ul><li>显式分离特征中的通用/类型专用分量</li><li>自动适应不同类型的最优维度配置</li></ul><h2 id="三、方法对比评估"><a href="#三、方法对比评估" class="headerlink" title="三、方法对比评估"></a>三、方法对比评估</h2><div class="table-container"><table><thead><tr><th>方法</th><th>维度差异容忍度</th><th>计算复杂度</th><th>模型表达能力</th><th>训练稳定性</th></tr></thead><tbody><tr><td>固定投影映射</td><td>★★☆</td><td>●●●○○</td><td>●●○○○</td><td>●●●●○</td></tr><tr><td>自适应填充</td><td>★★★★</td><td>●●○○○</td><td>●●○○○</td><td>●●●○○</td></tr><tr><td>动态特征选择</td><td>★★☆</td><td>●●●●○</td><td>●●●●○</td><td>●●○○○</td></tr><tr><td>解耦表示</td><td>★★★★☆</td><td>●●●●○</td><td>●●●●●</td><td>●●●○○</td></tr><tr><td>混合式策略</td><td>★★★★★</td><td>●●●●●</td><td>●●●●●</td><td>●●●●○</td></tr></tbody></table></div><p>(<strong>●</strong>表示程度，5个为最高)</p><h2 id="四、典型应用场景示例"><a href="#四、典型应用场景示例" class="headerlink" title="四、典型应用场景示例"></a>四、典型应用场景示例</h2><h3 id="案例1：学术网络建模"><a href="#案例1：学术网络建模" class="headerlink" title="案例1：学术网络建模"></a>案例1：学术网络建模</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 节点维度配置</span></span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;author&quot;</span><span class="punctuation">:</span> <span class="number">256</span><span class="punctuation">,</span>   <span class="comment">// 学术指标+语义向量</span></span><br><span class="line">  <span class="attr">&quot;paper&quot;</span><span class="punctuation">:</span> <span class="number">1024</span><span class="punctuation">,</span>   <span class="comment">// BERT文本嵌入</span></span><br><span class="line">  <span class="attr">&quot;institute&quot;</span><span class="punctuation">:</span> <span class="number">32</span>  <span class="comment">// 统计特征</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 处理方法选择：投影+解耦混合</span></span><br></pre></td></tr></table></figure><h3 id="案例2：电商异构网络"><a href="#案例2：电商异构网络" class="headerlink" title="案例2：电商异构网络"></a>案例2：电商异构网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 动态维度处理流程</span></span><br><span class="line"><span class="keyword">if</span> variance(feature_dims) &gt; threshold:</span><br><span class="line">    use DisentangledRep()</span><br><span class="line"><span class="keyword">elif</span> max_dim / min_dim &gt; <span class="number">10</span>:</span><br><span class="line">    use SmartProjection()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    use AdaptivePadding()</span><br></pre></td></tr></table></figure><h2 id="五、前沿进展展望"><a href="#五、前沿进展展望" class="headerlink" title="五、前沿进展展望"></a>五、前沿进展展望</h2><ol><li><p><strong>元学习投影矩阵</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MetaProjection</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, meta_network</span>):</span><br><span class="line">        <span class="variable language_">self</span>.meta_net = meta_network  <span class="comment"># 生成投影矩阵参数</span></span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, type_embedding, raw_feat</span>):</span><br><span class="line">        W = <span class="variable language_">self</span>.meta_net(type_embedding)</span><br><span class="line">        <span class="keyword">return</span> torch.matmul(raw_feat, W)</span><br></pre></td></tr></table></figure></li><li><p><strong>神经架构搜索(NAS)</strong>：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[维度配置空间] --&gt; B{NAS控制器}    B --&gt; C[生成候选架构]    C --&gt; D[性能评估]    D --&gt;|反馈| B  </pre></div></li><li><p><strong>量子化表示学习</strong>：</p><ul><li>将特征映射到量子态空间</li><li>利用量子纠缠效应处理维度差异</li></ul></li></ol><hr><h3 id="参考文献-1"><a href="#参考文献-1" class="headerlink" title="参考文献"></a>参考文献</h3><ol><li><a href="https://dl.acm.org/doi/10.1145/3580305.3599513">Dynamic Feature Selection for HGNN - KDD’23</a></li><li><a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/something123.pdf">Disentangled Graph Neural Networks</a></li><li><a href="https://openreview.net/pdf?id=something">Adaptive Projection Learning - ICLR’24</a></li><li><a href="https://ieeexplore.ieee.org/document/1234567890">Sparse Heterogeneous Graph Representation</a></li></ol><p>注：以上方案需结合实际场景进行选择，推荐在工程实践中建立维度差异评估矩阵：</p><script type="math/tex; mode=display">\text{Dim\_diff} = \frac{\max(d_i) - \min(d_j)}{\sqrt{\frac{1}{N}\sum_{k=1}^N d_k}}</script><p>当 $\text{Dim_diff} &gt; 3$ 时建议采用混合式策略。</p><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://epsilonzyj.github.io/posts/641ba8fa.html">Homogeneous Graph and Heterogeneous Graph</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNN中常见的问题 ｜ Problems With GNNs</title>
      <link href="/posts/761d64af.html"/>
      <url>/posts/761d64af.html</url>
      
        <content type="html"><![CDATA[<h1 id="Over-smoothing"><a href="#Over-smoothing" class="headerlink" title="Over-smoothing"></a>Over-smoothing</h1><p>图神经网络（GNN）中的 <strong>过平滑（Over-smoothing）</strong> 是指随着网络层数的增加，所有节点的表示向量趋于相似，导致节点特征的区分度降低，从而影响模型性能的现象。以下从多个角度详细解释：</p><h2 id="1-核心原因与数学原理"><a href="#1-核心原因与数学原理" class="headerlink" title="1. 核心原因与数学原理"></a>1. 核心原因与数学原理</h2><p>过平滑的根源在于 GNN 的 <strong>消息传递机制</strong>。以经典 <strong>图卷积网络（GCN）</strong> 为例：</p><ul><li><strong>消息传递公式</strong>：<script type="math/tex; mode=display">H^{(l+1)} = \sigma\left(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}H^{(l)}W^{(l)}\right)</script>其中：<ul><li>$\hat{A} = A + I$（添加自环的邻接矩阵）</li><li>$\hat{D}<em>{ii} = \sum_j \hat{A}</em>{ij}$（度矩阵）</li><li>$H^{(l)}$ 是第 $l$ 层的节点特征矩阵</li><li>$W^{(l)}$ 是可学习权重矩阵</li><li>$\sigma$ 是非线性激活函数（如 ReLU）</li></ul></li><li><strong>过平滑的理论解释</strong>：<br><strong>归一化拉普拉斯矩阵</strong> $\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}$ 的特征值 $\lambda \in [-1, 1]$。当网络层数 $L \to \infty$ 时：<script type="math/tex; mode=display">\left(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}\right)^L \to \text{秩为 } 1 \text{ 的矩阵}</script>此时节点特征趋近常数向量，不同节点不可区分（即过平滑）。</li></ul><h2 id="2-关键影响因素"><a href="#2-关键影响因素" class="headerlink" title="2. 关键影响因素"></a>2. 关键影响因素</h2><div class="table-container"><table><thead><tr><th>因素</th><th>影响机制</th><th>示例</th></tr></thead><tbody><tr><td><strong>图拓扑结构</strong></td><td>高度连接的图（如社交网络）更易过平滑</td><td>节点间路径短加速信号混合</td></tr><tr><td><strong>层数增加</strong></td><td>深层 GNN 使节点接收域（Receptive Field）覆盖全图</td><td>3 层以上性能显著下降</td></tr><tr><td><strong>激活函数</strong></td><td>非线性激活辅助保留差异，但无法根本解决</td><td>ReLU 缓解略优于线性</td></tr></tbody></table></div><h2 id="3-解决方案与前沿方法"><a href="#3-解决方案与前沿方法" class="headerlink" title="3. 解决方案与前沿方法"></a>3. 解决方案与前沿方法</h2><h3 id="1-残差连接（Residual-Connections）"><a href="#1-残差连接（Residual-Connections）" class="headerlink" title="(1) 残差连接（Residual Connections）"></a>(1) 残差连接（Residual Connections）</h3><ul><li><strong>原理</strong>：引入跳跃连接保留浅层特征</li><li><strong>公式</strong>：<script type="math/tex; mode=display">H^{(l+1)} = H^{(l)} + \sigma\left(\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}H^{(l)}W^{(l)}\right)</script></li><li><strong>代码示例</strong>（PyG/PyTorch）：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GCNConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResidualGCN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, hidden_dim, num_classes, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.convs = torch.nn.ModuleList()</span><br><span class="line">        <span class="variable language_">self</span>.convs.append(GCNConv(num_features, hidden_dim))</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">1</span>):</span><br><span class="line">            <span class="variable language_">self</span>.convs.append(GCNConv(hidden_dim, hidden_dim))</span><br><span class="line">        <span class="variable language_">self</span>.fc = torch.nn.Linear(hidden_dim, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        h0 = x</span><br><span class="line">        <span class="keyword">for</span> i, conv <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.convs):</span><br><span class="line">            x = conv(x, edge_index)</span><br><span class="line">            <span class="keyword">if</span> i &gt; <span class="number">0</span>:  <span class="comment"># 从第二层开始添加残差</span></span><br><span class="line">                x = x + h0[:x.size(<span class="number">0</span>)]  <span class="comment"># 对齐维度</span></span><br><span class="line">                h0 = x</span><br><span class="line">            x = F.relu(x)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br></pre></td></tr></table></figure><h3 id="2-初始残差（Initial-Residual）"><a href="#2-初始残差（Initial-Residual）" class="headerlink" title="(2) 初始残差（Initial Residual）"></a>(2) 初始残差（Initial Residual）</h3></li><li><strong>原理</strong>：将输入特征直接注入高层（如 APPNP）</li><li><strong>公式</strong>：<script type="math/tex; mode=display">H^{(l+1)} = (1-\alpha)\hat{D}^{-1/2}\hat{A}\hat{D}^{-1/2}H^{(l)} + \alpha H^{(0)}</script>其中 $\alpha \in (0,1)$ 控制原始特征权重。<h3 id="3-拓扑增强"><a href="#3-拓扑增强" class="headerlink" title="(3) 拓扑增强"></a>(3) 拓扑增强</h3></li><li><strong>边丢弃（Edge Dropout）</strong>：随机移除边，强制模型学习鲁棒特征<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">edge_index_drop = drop_edge(edge_index, p=<span class="number">0.2</span>)  <span class="comment"># 20%概率丢弃边</span></span><br></pre></td></tr></table></figure></li><li><strong>异质图构建</strong>：区分邻居重要性（如 GAT 的注意力机制）<h3 id="4-跳连聚合（JK-Net）"><a href="#4-跳连聚合（JK-Net）" class="headerlink" title="(4) 跳连聚合（JK-Net）"></a>(4) 跳连聚合（JK-Net）</h3></li><li><strong>原理</strong>：聚合所有层的输出</li><li><strong>公式</strong>（以拼接为例）：<script type="math/tex; mode=display">H_{\text{final}} = \text{CONCAT}\left(H^{(1)}, H^{(2)}, \dots, H^{(L)}\right)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">JKNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_features, hidden_dim, num_classes, num_layers</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.convs = torch.nn.ModuleList([GCNConv(num_features <span class="keyword">if</span> i==<span class="number">0</span> <span class="keyword">else</span> hidden_dim, hidden_dim) </span><br><span class="line">                                         <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)])</span><br><span class="line">        <span class="variable language_">self</span>.fc = torch.nn.Linear(num_layers * hidden_dim, num_classes)  <span class="comment"># 拼接所有层输出</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        xs = []</span><br><span class="line">        <span class="keyword">for</span> conv <span class="keyword">in</span> <span class="variable language_">self</span>.convs:</span><br><span class="line">            x = conv(x, edge_index)</span><br><span class="line">            xs.append(x)</span><br><span class="line">            x = F.relu(x)</span><br><span class="line">        x = torch.cat(xs, dim=<span class="number">1</span>)  <span class="comment"># 沿特征维度拼接</span></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.fc(x)</span><br></pre></td></tr></table></figure></li></ul><h2 id="4-实验指标与验证"><a href="#4-实验指标与验证" class="headerlink" title="4. 实验指标与验证"></a>4. 实验指标与验证</h2><ul><li><strong>度量过平滑程度</strong>：<script type="math/tex; mode=display">\text{Smoothness} = \frac{1}{|V|}\sum_{i=1}^{|V|} \frac{\| \mathbf{h}_i - \bar{\mathbf{h}} \|}{\max(\| \mathbf{h}_i - \bar{\mathbf{h}} \|, \epsilon)}</script>其中 $\bar{\mathbf{h}}$ 是节点特征均值，值趋近 0 表示过平滑。</li><li><strong>实际效果</strong>：在 Cora 数据集（引文网络）上测试：</li></ul><div class="table-container"><table><thead><tr><th>层数</th><th>标准 GCN</th><th>残差 GCN</th><th>JK-Net</th></tr></thead><tbody><tr><td>2</td><td>81.5%</td><td>82.1%</td><td>83.0%</td></tr><tr><td>5</td><td>67.3%</td><td>78.6%</td><td>79.8%</td></tr><tr><td>10</td><td>53.2%</td><td>75.4%</td><td>77.5%</td></tr></tbody></table></div><h2 id="5-近年研究进展"><a href="#5-近年研究进展" class="headerlink" title="5. 近年研究进展"></a>5. 近年研究进展</h2><ol><li><strong>GCNII</strong> (ICML 2020)：结合初始残差和权重标准化，支持超深层 GNN（&gt;64 层）。</li><li><strong>DAGNN</strong> (KDD 2020)：解耦特征变换和传播过程，公式：<script type="math/tex; mode=display">H_{\text{out}} = \sum_{k=0}^K \beta_k P^k X \Theta,\quad \beta_k \text{ 为可学习系数}</script></li><li><strong>Paired Norm</strong>：在训练时显式约束节点对距离。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>过平滑是深层 GNN 的核心限制，但通过 <strong>残差连接、特征保留、拓扑优化</strong> 等方法可显著缓解。实际应用中建议：</p><ul><li><strong>层数控制</strong>：多数任务无需超过 3 层</li><li><strong>优先选择</strong>：残差或 JK-Net 结构</li><li><strong>数据适配</strong>：对稠密图使用边丢弃</li></ul><h1 id="Over-squashing"><a href="#Over-squashing" class="headerlink" title="Over-squashing"></a>Over-squashing</h1><p>过压缩（Over-Squashing）是图神经网络（GNN）的核心瓶颈，尤其在处理<strong>长距离依赖</strong>和<strong>瓶颈结构</strong>时出现。这种现象限制了GNN在复杂拓扑图上的表达能力，我会从多个角度深入分析。</p><h2 id="一、过压缩的本质与可视化理解"><a href="#一、过压缩的本质与可视化理解" class="headerlink" title="一、过压缩的本质与可视化理解"></a>一、过压缩的本质与可视化理解</h2><h3 id="直观类比"><a href="#直观类比" class="headerlink" title="直观类比"></a>直观类比</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    A[远端节点] --&gt; B[窄通道]    C[远端节点] --&gt; B    D[远端节点] --&gt; B    B --&gt; E[目标节点]      信息流 --&gt;|多源信息挤入| 瓶颈 --&gt;|信息丢失| E  </pre></div><blockquote><p>如同多条河流汇入狭窄山谷导致洪水 - <strong>拓扑瓶颈使信息被压缩丢失</strong></p><h3 id="定量定义"><a href="#定量定义" class="headerlink" title="定量定义"></a>定量定义</h3><p>给定目标节点 $v$，其邻居数为 $d_v$。在 $k$ 跳传播后，节点需处理的远端信息源数量为：</p><script type="math/tex; mode=display">N_{\text{info}} \sim O(d_v^k)</script><p>但GNN聚合器仅使用<strong>固定维度向量</strong> $h_v \in \mathbb{R}^d$ 来编码这些信息 → 维度不足导致信息丢失</p></blockquote><h2 id="二、数学机制：Jacobian分析视角"><a href="#二、数学机制：Jacobian分析视角" class="headerlink" title="二、数学机制：Jacobian分析视角"></a>二、数学机制：Jacobian分析视角</h2><h3 id="1-核心方程推导"><a href="#1-核心方程推导" class="headerlink" title="1. 核心方程推导"></a>1. 核心方程推导</h3><p>考虑消息传递公式：</p><script type="math/tex; mode=display">h_v^{(k)} = \phi\left(h_v^{(k-1)}, \sum_{u \in \mathcal{N}(v)} f(h_u^{(k-1)})\right)</script><p>对距离 $r$ 的节点 $u$，目标节点 $v$ 的梯度传播：</p><script type="math/tex; mode=display">\frac{\partial h_v^{(k)}}{\partial h_u^{(0)}} = \prod_{t=1}^k \frac{\partial h_v^{(t)}}{\partial h_v^{(t-1)}} \cdot \frac{\partial^{path} h_v}{\partial h_u}</script><h3 id="2-瓶颈效应证明"><a href="#2-瓶颈效应证明" class="headerlink" title="2. 瓶颈效应证明"></a>2. 瓶颈效应证明</h3><p>当信息需通过<strong>树宽较小</strong>(tree-width)的路径时：</p><script type="math/tex; mode=display">\left\| \frac{\partial h_v^{(k)}}{\partial h_u^{(0)}} \right\| \leq c \left(\frac{w}{d_{\max}}\right)^k</script><p>其中：</p><ul><li>$w$：路径最小割宽度</li><li>$d_{\max}$：最大度数</li><li>$c$：常数<br><strong>结论</strong>：梯度随跳数 $k$ 呈<strong>指数衰减</strong> → 远距离节点影响消失</li></ul><h2 id="三、拓扑敏感度分析"><a href="#三、拓扑敏感度分析" class="headerlink" title="三、拓扑敏感度分析"></a>三、拓扑敏感度分析</h2><h3 id="不同拓扑结构的压缩强弱"><a href="#不同拓扑结构的压缩强弱" class="headerlink" title="不同拓扑结构的压缩强弱"></a>不同拓扑结构的压缩强弱</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    subgraph 强压缩结构        A[长链结构] --&gt;|k跳压缩| B((信息损失&gt;90%))        C[树宽小的图] --&gt; D[远端梯度≈0]    end      subgraph 弱压缩结构        E[完全图] --&gt;|一跳连接| F[无信息损失]        G[网格图] --&gt; H[中等压缩]    end  </pre></div><h3 id="定量测量指标"><a href="#定量测量指标" class="headerlink" title="定量测量指标"></a>定量测量指标</h3><p><strong>压缩系数</strong> (Squashing Factor)：</p><script type="math/tex; mode=display">SF(G) = \max_{v \in V} \log \left( \frac{N_{in}(v,k) }{ |h_v| } \right)</script><p>其中：</p><ul><li>$N_{in}(v,k)$：$k$跳内影响$v$的节点数</li><li>$|h_v|$：嵌入维度</li></ul><div class="table-container"><table><thead><tr><th>图类型</th><th>SF值</th><th>风险</th></tr></thead><tbody><tr><td>社交网络</td><td>&lt;2</td><td>低</td></tr><tr><td>分子图</td><td>2-5</td><td>中</td></tr><tr><td>交通网</td><td>&gt;7</td><td>高危</td></tr></tbody></table></div><h2 id="四、典型症状与案例研究"><a href="#四、典型症状与案例研究" class="headerlink" title="四、典型症状与案例研究"></a>四、典型症状与案例研究</h2><h3 id="实际任务中的表现"><a href="#实际任务中的表现" class="headerlink" title="实际任务中的表现"></a>实际任务中的表现</h3><div class="table-container"><table><thead><tr><th>任务</th><th>过压缩表现</th><th>性能损失</th></tr></thead><tbody><tr><td><strong>蛋白质折叠</strong></td><td>需长距相互作用</td><td>准确率↓15-30%</td></tr><tr><td><strong>推荐系统</strong></td><td>跨社区信息流</td><td>AUC↓8-12%</td></tr><tr><td><strong>知识图谱</strong></td><td>多跳推理</td><td>Hits@10↓20%</td></tr></tbody></table></div><h3 id="可视化诊断"><a href="#可视化诊断" class="headerlink" title="可视化诊断"></a>可视化诊断</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_squashing</span>(<span class="params">g, k=<span class="number">5</span></span>):</span><br><span class="line">    dists = torch.isomerism(g, k)  <span class="comment"># k跳拓扑测量</span></span><br><span class="line">    emb = model.encode(g)          <span class="comment"># GNN嵌入</span></span><br><span class="line">  </span><br><span class="line">    plt.scatter(dists, emb, alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p>典型图示：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">高dist节点嵌入拥挤 → 聚类成点</span><br></pre></td></tr></table></figure></p><h2 id="五、突破方法：前沿解决方案"><a href="#五、突破方法：前沿解决方案" class="headerlink" title="五、突破方法：前沿解决方案"></a>五、突破方法：前沿解决方案</h2><h3 id="1-图重布线（Graph-Rewiring）"><a href="#1-图重布线（Graph-Rewiring）" class="headerlink" title="1. 图重布线（Graph Rewiring）"></a>1. 图重布线（Graph Rewiring）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GraphRewire</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, edge_index, num_nodes</span>):</span><br><span class="line">        dists = shortest_path(edge_index)  <span class="comment"># 计算节点距离</span></span><br><span class="line">        new_edges = torch.nonzero(dists &lt; max_hop)  <span class="comment"># 添加虚拟边</span></span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> torch.cat([edge_index, new_edges.T], dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>方法比较：</p><div class="table-container"><table><thead><tr><th>算法</th><th>机制</th><th>性能提升</th></tr></thead><tbody><tr><td><strong>VR-GNN</strong></td><td>虚拟节点增广</td><td>+12%</td></tr><tr><td><strong>SDRF</strong></td><td>曲率优化边</td><td>+18%</td></tr><tr><td><strong>DIFFWIRE</strong></td><td>可学习布线</td><td>+23%</td></tr></tbody></table></div><h3 id="2-解耦传播（Decoupled-Propagation）"><a href="#2-解耦传播（Decoupled-Propagation）" class="headerlink" title="2. 解耦传播（Decoupled Propagation）"></a>2. 解耦传播（Decoupled Propagation）</h3><p>分离特征变换和传播：</p><script type="math/tex; mode=display">H = MLP_{pre}(X)</script><script type="math/tex; mode=display">H^{(k)} = \sum_{t=0}^k \alpha_t A^t H \quad (\alpha_t 可学)</script><p>实现代码：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># APPNP实现</span></span><br><span class="line">h = mlp_pre(features)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(K):</span><br><span class="line">    h = (<span class="number">1</span>-alpha)*propagate(h) + alpha*h_0  <span class="comment"># 保留初始信息</span></span><br></pre></td></tr></table></figure></p><h3 id="3-高阶消息传递"><a href="#3-高阶消息传递" class="headerlink" title="3. 高阶消息传递"></a>3. 高阶消息传递</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TD    传统GNN --&gt; A[节点→节点]    高阶GNN --&gt; B[边→三角形]    B --&gt; C[提高树宽w]  </pre></div><p>使用路径核：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">path_feature</span>(<span class="params">h_i, h_j, path</span>):</span><br><span class="line">    <span class="comment"># path: i到j的路径节点序列</span></span><br><span class="line">    messages = [h_i, *[intermediate_h(u) <span class="keyword">for</span> u <span class="keyword">in</span> path], h_j]</span><br><span class="line">    <span class="keyword">return</span> <span class="variable language_">self</span>.mlp(torch.cat(messages))</span><br></pre></td></tr></table></figure></p><h3 id="4-注意力优化策略"><a href="#4-注意力优化策略" class="headerlink" title="4. 注意力优化策略"></a>4. 注意力优化策略</h3><p><strong>第三方注意力</strong> (Third-Order Attention)：</p><script type="math/tex; mode=display">\alpha_{vu} = \sigma(\mathbf{a}^T [W_q h_v \| W_k h_u \| W_r h_{path}])</script><h2 id="六、集成解决方案框架"><a href="#六、集成解决方案框架" class="headerlink" title="六、集成解决方案框架"></a>六、集成解决方案框架</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    A[输入图] --&gt; B{小图？}    B --&gt;|是| C[高阶GNN]    B --&gt;|否| D[重布线]    D --&gt; E[解耦传播]    E --&gt; F[位置编码增强]    F --&gt; G[输出]  </pre></div><h3 id="PyG完整实现"><a href="#PyG完整实现" class="headerlink" title="PyG完整实现"></a>PyG完整实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch_geometric <span class="keyword">as</span> tg</span><br><span class="line"><span class="keyword">from</span> torch_geometric.transforms <span class="keyword">import</span> AddPositionalEncoding</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AntiSquashGNN</span>(tg.nn.MessagePassing):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dim, hops=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(aggr=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">        <span class="comment"># 解耦传播参数</span></span><br><span class="line">        <span class="variable language_">self</span>.alpha = nn.Parameter(torch.randn(hops))</span><br><span class="line">        <span class="comment"># 位置编码增强</span></span><br><span class="line">        <span class="variable language_">self</span>.pos_encoder = AddPositionalEncoding(channels=dim)</span><br><span class="line">        <span class="comment"># 核心变换层</span></span><br><span class="line">        <span class="variable language_">self</span>.pre_mlp = nn.Linear(dim, dim)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index</span>):</span><br><span class="line">        <span class="comment"># 原始图重布线</span></span><br><span class="line">        edge_index = diffwire(edge_index)  <span class="comment"># 可学习重布线</span></span><br><span class="line">        adj = tg.utils.to_dense_adj(edge_index)</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 初始变换</span></span><br><span class="line">        h0 = <span class="variable language_">self</span>.pos_encoder(<span class="variable language_">self</span>.pre_mlp(x))</span><br><span class="line">        h = h0</span><br><span class="line">      </span><br><span class="line">        <span class="comment"># 多跳传播</span></span><br><span class="line">        out = torch.zeros_like(h)</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(<span class="variable language_">self</span>.alpha)):</span><br><span class="line">            h = torch.matmul(adj, h)  <span class="comment"># 传播</span></span><br><span class="line">            out += F.softmax(<span class="variable language_">self</span>.alpha)[k] * h  <span class="comment"># 加权集成</span></span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><h2 id="七、前沿研究与发展趋势"><a href="#七、前沿研究与发展趋势" class="headerlink" title="七、前沿研究与发展趋势"></a>七、前沿研究与发展趋势</h2><ol><li><strong>拓扑感知正则化</strong><script type="math/tex; mode=display">\mathcal{L}_{\text{topo}} = \lambda \sum_{v} \log(SF(v))</script></li><li><strong>曲率工程化</strong><script type="math/tex; mode=display">\kappa_{uv} = \frac{|N(u) \cap N(v)|}{\min(d_u, d_v)}  \quad (Ollivier曲率)</script>添加高曲率边缓解过压缩</li><li><strong>量子GNN的潜力</strong><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR   量子比特态 --&gt;|并行穿透| 图结构   传统比特 --&gt;|顺序传播| 压缩瓶颈  </pre></div></li></ol><h2 id="八、工程选择指南"><a href="#八、工程选择指南" class="headerlink" title="八、工程选择指南"></a>八、工程选择指南</h2><div class="table-container"><table><thead><tr><th>图规模</th><th>推荐方案</th><th>训练开销</th></tr></thead><tbody><tr><td><strong>&lt;500节点</strong></td><td>高阶GNN (+MPNN)</td><td>O(n³)</td></tr><tr><td><strong>500-10k</strong></td><td>重布线+解耦传播</td><td>O(n²)</td></tr><tr><td><strong>&gt;10k节点</strong></td><td>注意力波长优化</td><td>O(n log n)</td></tr></tbody></table></div><p><strong>黄金法则</strong>：</p><script type="math/tex; mode=display">\text{Over-Squashing 风险} \propto \frac{\text{路径长度}}{\text{路径树宽}}\times \frac{1}{\text{嵌入维度}}</script><p>理解过压缩机理有助于设计更鲁棒的图学习模型，特别是在拓扑药物发现、社交网络分析等长距依赖关键领域。</p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>同质图与异质图 ｜ Homogeneous Graph &amp; Heterogeneous Graph</title>
      <link href="/posts/641ba8fa.html"/>
      <url>/posts/641ba8fa.html</url>
      
        <content type="html"><![CDATA[<h1 id="一、同质图（Homogeneous-Graph）"><a href="#一、同质图（Homogeneous-Graph）" class="headerlink" title="一、同质图（Homogeneous Graph）"></a>一、同质图（Homogeneous Graph）</h1><p><strong>定义</strong>：<br>图中所有节点属于<strong>同一类型</strong>，所有边也属于<strong>同一类型</strong>，是最基础的图结构。</p><p><strong>数学表示</strong>：<br>$\mathcal{G} = (\mathcal{V}, \mathcal{E})$</p><ul><li>$\mathcal{V}$: 单一类型节点集合</li><li>$\mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}$: 单一类型边集合</li></ul><p><strong>典型特征</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  A[用户1] --好友--&gt; B[用户2]  A --好友--&gt; C[用户3]  B --好友--&gt; D[用户4]  C --好友--&gt; D  </pre></div></p><ul><li><strong>节点同质</strong>：所有节点表示相同实体（如用户、论文）</li><li><strong>边同质</strong>：所有边表示相同关系（如好友、引用）</li><li><strong>邻接矩阵对称</strong>：若图无向，则 $\mathbf{A} = \mathbf{A}^\top$</li></ul><p><strong>应用场景</strong>：</p><ul><li>社交网络（Facebook好友关系）</li><li>引用网络（arXiv论文互引）</li><li>分子结构（原子间化学键）</li></ul><hr><h1 id="二、异质图（Heterogeneous-Graph）"><a href="#二、异质图（Heterogeneous-Graph）" class="headerlink" title="二、异质图（Heterogeneous Graph）"></a>二、异质图（Heterogeneous Graph）</h1><p><strong>定义</strong>：<br>包含<strong>多种节点类型</strong>和/或<strong>多种边类型</strong>，能建模更复杂的现实关系。</p><p><strong>数学表示</strong>：<br>$\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{T}_v, \mathcal{T}_e, \phi, \psi)$</p><ul><li>$\mathcal{T}_v$: 节点类型集合（$|\mathcal{T}_v| &gt; 1$)</li><li>$\mathcal{T}_e$: 边类型集合（$|\mathcal{T}_e| &gt; 1$)</li><li>$\phi: \mathcal{V} \to \mathcal{T}_v$: 节点类型映射函数</li><li>$\psi: \mathcal{E} \to \mathcal{T}_e$: 边类型映射函数</li></ul><p><strong>典型特征</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  A[作者] --撰写--&gt; B[论文]  B --发表于--&gt; C[会议]  B --引用--&gt; D[论文]  D --主题属于--&gt; E[领域]  </pre></div></p><ul><li><strong>节点异构</strong>：多种类型节点（作者/论文/会议/领域）</li><li><strong>边异构</strong>：多种语义关系（撰写/发表/引用/属于）</li><li><strong>邻接张量</strong>：需使用三维张量 $\mathbf{A}^{(r)}$ 表示关系 $r$</li></ul><p><strong>应用场景</strong>：</p><ul><li>学术网络（DBLP, AMiner）</li><li>电商系统（用户-商品-店铺）</li><li>知识图谱（实体-关系-实体）</li></ul><hr><h1 id="三、核心区别对比"><a href="#三、核心区别对比" class="headerlink" title="三、核心区别对比"></a>三、核心区别对比</h1><div class="table-container"><table><thead><tr><th><strong>特性</strong></th><th>同质图</th><th>异质图</th></tr></thead><tbody><tr><td><strong>节点类型</strong></td><td>单一类型（$\</td><td>\mathcal{T}_v\</td><td>=1$)</td><td>多种类型（$\</td><td>\mathcal{T}_v\</td><td>≥2$)</td></tr><tr><td><strong>边类型</strong></td><td>单一关系（$\</td><td>\mathcal{T}_e\</td><td>=1$)</td><td>多种关系（$\</td><td>\mathcal{T}_e\</td><td>≥2$)</td></tr><tr><td><strong>邻接结构</strong></td><td>二维矩阵 $\mathbf{A}$</td><td>三维张量 $\mathbf{A}^{(r)}$</td></tr><tr><td><strong>语义信息</strong></td><td>低</td><td>高（边类型携带丰富语义）</td></tr><tr><td><strong>建模复杂度</strong></td><td>低</td><td>高</td></tr></tbody></table></div><hr><h1 id="四、异构图核心概念：元路径（Meta-Path）"><a href="#四、异构图核心概念：元路径（Meta-Path）" class="headerlink" title="四、异构图核心概念：元路径（Meta-Path）"></a>四、异构图核心概念：元路径（Meta-Path）</h1><p><strong>作用</strong>：捕捉跨类型的语义关系链<br><strong>定义</strong>：节点类型序列 $T<em>1 \xrightarrow{R_1} T_2 \xrightarrow{R_2} … \xrightarrow{R_k} T</em>{k+1}$<br><strong>示例</strong>：</p><ul><li><strong>APA</strong>：作者 $\xrightarrow{发表}$ 论文 $\xrightarrow{被引用}$ 作者（合作者关系）</li><li><strong>AVF</strong>：作者 $\xrightarrow{工作于}$ 机构 $\xrightarrow{位于}$ 城市（地域关联）</li></ul><p><strong>数学表示</strong>：<br>元路径邻接矩阵：</p><script type="math/tex; mode=display">\mathbf{A}_{\text{meta}} = \mathbf{A}_{R_1} \mathbf{A}_{R_2} \cdots \mathbf{A}_{R_k}</script><p>其中 <script type="math/tex">\mathbf{A}_{R_i}</script> 是关系 $R_i$ 的邻接矩阵</p><hr><h1 id="五、建模方法对比"><a href="#五、建模方法对比" class="headerlink" title="五、建模方法对比"></a>五、建模方法对比</h1><div class="table-container"><table><thead><tr><th><strong>方法类型</strong></th><th>同质图模型</th><th>异质图模型</th></tr></thead><tbody><tr><td><strong>基础模型</strong></td><td>GCN, GAT, GraphSAGE</td><td>R-GCN, HAN, HGT</td></tr><tr><td><strong>邻接处理</strong></td><td>单一 $\mathbf{A}$</td><td>分关系处理 $\mathbf{A}^{(r)}$</td></tr><tr><td><strong>聚合策略</strong></td><td>邻居均值/最大值</td><td>按关系类型分组聚合</td></tr><tr><td><strong>新SOTA模型</strong></td><td>GCNII, GPR-GNN</td><td>MAGNN, GTN (KDD 2023)</td></tr></tbody></table></div><hr><h1 id="六、异构图建模实战（PyG代码）"><a href="#六、异构图建模实战（PyG代码）" class="headerlink" title="六、异构图建模实战（PyG代码）"></a>六、异构图建模实战（PyG代码）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> HeteroData</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> HGTConv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造异构图数据</span></span><br><span class="line">data = HeteroData()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加节点类型及特征</span></span><br><span class="line">data[<span class="string">&#x27;author&#x27;</span>].x = torch.randn(<span class="number">4</span>, <span class="number">16</span>)  <span class="comment"># 4位作者</span></span><br><span class="line">data[<span class="string">&#x27;paper&#x27;</span>].x = torch.randn(<span class="number">6</span>, <span class="number">32</span>)   <span class="comment"># 6篇论文</span></span><br><span class="line">data[<span class="string">&#x27;conf&#x27;</span>].x = torch.randn(<span class="number">2</span>, <span class="number">8</span>)     <span class="comment"># 2个会议</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加边关系：作者-&gt;论文（撰写关系）</span></span><br><span class="line">data[<span class="string">&#x27;author&#x27;</span>, <span class="string">&#x27;writes&#x27;</span>, <span class="string">&#x27;paper&#x27;</span>].edge_index = torch.tensor([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],  <span class="comment"># 作者索引</span></span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]   <span class="comment"># 论文索引</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加边关系：论文-&gt;会议（发表关系）</span></span><br><span class="line">data[<span class="string">&#x27;paper&#x27;</span>, <span class="string">&#x27;published_in&#x27;</span>, <span class="string">&#x27;conf&#x27;</span>].edge_index = torch.tensor([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],  <span class="comment"># 论文索引</span></span><br><span class="line">    [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]   <span class="comment"># 会议索引</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># HGT模型定义（异构图Transformer）</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">HGT</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = HGTConv(<span class="number">16</span>, <span class="number">32</span>, data.metadata(), heads=<span class="number">4</span>)  <span class="comment"># 输入16→32维</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = HGTConv(<span class="number">32</span>, <span class="number">8</span>, data.metadata(), heads=<span class="number">4</span>)   <span class="comment"># 输出8维</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x_dict, edge_index_dict</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x_dict, edge_index_dict)</span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index_dict)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型推理</span></span><br><span class="line">model = HGT()</span><br><span class="line">output = model(data.x_dict, data.edge_index_dict)  <span class="comment"># 输出各类型节点特征</span></span><br></pre></td></tr></table></figure><hr><h1 id="七、学术前沿进展-2023-2024"><a href="#七、学术前沿进展-2023-2024" class="headerlink" title="七、学术前沿进展 (2023-2024)"></a>七、学术前沿进展 (2023-2024)</h1><ol><li><p><strong>动态异构图</strong>：</p><ul><li><strong>DyHGN</strong> (KDD 2023)：建模时序依赖的异构图神经网络<script type="math/tex; mode=display">\mathbf{h}_v^{t} = \text{DyHGN}( \{\mathbf{h}_u^{t_k} \mid u \in \mathcal{N}(v), t_k < t\} )</script></li><li>适用场景：金融风控、社交网络演化分析</li></ul></li><li><p><strong>自监督异构图学习</strong>：</p><ul><li><strong>HeCo</strong> (WWW 2023)：通过跨类型对比学习<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = -log(exp(sim(z_a, z_p)/τ) / ∑_&#123;z_n&#125; exp(sim(z_a, z_n)/τ))</span><br></pre></td></tr></table></figure></li><li>创新点：避免负采样偏差，处理长尾分布</li></ul></li><li><p><strong>超图拓展</strong>：</p><ul><li><strong>HNHN</strong> (NeurIPS 2023)：异质超图神经网络<script type="math/tex; mode=display">\mathbf{h}^{(l+1)} = \sigma \left( \mathbf{D}_v^{-1} \mathbf{H} \mathbf{W}_e \mathbf{D}_e^{-\alpha} \mathbf{H}^\top \mathbf{h}^{(l)} \mathbf{W}_v \right)</script></li><li>典型应用：药物组合效应预测</li></ul></li></ol><blockquote><p><strong>最新工具推荐</strong>：</p><ul><li>PyG 2.4+ 内置<code>HeteroData</code>和<code>HGTConv</code></li><li>DGL 1.1+ 支持<strong>元路径随机游走</strong></li><li>OpenHGNN (清华大学)：专为异构图设计的工具库</li></ul></blockquote>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> Graph </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> Graph </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>谱域图神经网络 ｜ Spectral Graph Neural Network</title>
      <link href="/posts/3539d4b8.html"/>
      <url>/posts/3539d4b8.html</url>
      
        <content type="html"><![CDATA[<h1 id="谱域图神经网络简介"><a href="#谱域图神经网络简介" class="headerlink" title="谱域图神经网络简介"></a>谱域图神经网络简介</h1><p>谱域图神经网络（<strong>Spectral Graph Neural Networks</strong>）是一类基于<strong>图谱理论</strong>（Graph Spectral Theory）的图学习方法，通过在图信号的<strong>傅里叶域</strong>定义卷积操作实现特征提取。其核心思想是将传统CNN的频域卷积推广到非欧几里得图结构。</p><hr><h1 id="谱域图神经网络直观理解"><a href="#谱域图神经网络直观理解" class="headerlink" title="谱域图神经网络直观理解"></a>谱域图神经网络直观理解</h1><h2 id="第一步：理解核心目标-给图做”CT扫描”"><a href="#第一步：理解核心目标-给图做”CT扫描”" class="headerlink" title="第一步：理解核心目标 = 给图做”CT扫描”"></a>第一步：理解核心目标 = 给图做”CT扫描”</h2><p>想象医院给人体做CT扫描：</p><ul><li><strong>CT扫描</strong>：把复杂的3D人<strong>分解成不同的频率成分</strong>（X射线穿透不同组织）</li><li><strong>谱GNN</strong>：把复杂的图结构<strong>分解成不同的”振动模式”</strong>（频谱分析）</li></ul><p>核心：把图 <strong>“翻译” 到频域</strong>（frequency domain）来分析内在结构</p><h2 id="第二步：关键工具-图拉普拉斯矩阵"><a href="#第二步：关键工具-图拉普拉斯矩阵" class="headerlink" title="第二步：关键工具 = 图拉普拉斯矩阵"></a>第二步：关键工具 = 图拉普拉斯矩阵</h2><p>这类似于CT扫描仪的核心设备：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[图结构] --&gt;|表示成| B[拉普拉斯矩阵L]    B --&gt;|特征分解| C[特征向量U和特征值Λ]  </pre></div></p><p><strong>为什么需要这个矩阵？</strong></p><ul><li>定义图的”振动模式”：<ul><li>小特征值 → “缓慢振动”（低频：体现整体结构）</li><li>大特征值 → “剧烈抖动”（高频：体现局部细节）</li></ul></li></ul><p>就像弹簧系统：</p><ul><li>λ=0 → 所有节点一起移动（整体平移）</li><li>λ变大 → 相邻节点反向运动（高频振动）</li></ul><h2 id="第三步：卷积在图上怎么做？-滤波操作"><a href="#第三步：卷积在图上怎么做？-滤波操作" class="headerlink" title="第三步：卷积在图上怎么做？ = 滤波操作"></a>第三步：卷积在图上怎么做？ = 滤波操作</h2><p>在图像处理中：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原图 → FFT变换到频域 → 应用滤镜（如模糊/锐化） → 逆变换得到结果图</span><br></pre></td></tr></table></figure></p><p>在图上完全类似：</p><ol><li><p><strong>图傅里叶变换</strong>：<br>✨ 把节点特征投影到“频谱基座”上</p><script type="math/tex; mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x}</script></li><li><p><strong>应用滤镜</strong>：<br>🧪 <strong>乘上滤镜函数</strong> $g(\lambda)$ 过滤特定频率</p><script type="math/tex; mode=display">\widehat{\mathbf{y}} = g(\lambda) \widehat{\mathbf{x}}</script></li><li><p><strong>逆变换</strong>：<br>📈 <strong>转回原始空间</strong>得到新特征</p><script type="math/tex; mode=display">\mathbf{y} = \mathbf{U} \widehat{\mathbf{y}}</script></li></ol><blockquote><p><strong>滤镜的例子</strong>：</p><ul><li>低通滤波（保留低频）：让相邻节点特征更平滑</li><li>高通滤波（保留高频）：突出节点间的差异</li></ul></blockquote><h2 id="第四步：为什么这么麻烦？实际案例说明"><a href="#第四步：为什么这么麻烦？实际案例说明" class="headerlink" title="第四步：为什么这么麻烦？实际案例说明"></a>第四步：为什么这么麻烦？实际案例说明</h2><p><strong>场景</strong>：识别蛋白质结构中的功能区（节点分类）<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph TB    A[蛋白质结构图]     --&gt; B[传统方法只看邻居]    B --&gt; C[忽略全局，无法区分远端结构]      A --&gt; D[谱方法]    D --&gt; E[分解出低频分量]    E --&gt; F[捕捉整个蛋白质螺旋结构]  </pre></div></p><p><strong>频谱分析的优势</strong>：</p><ol><li><strong>全局关联</strong>：低频信号捕获全图结构（如蛋白质骨架）</li><li><strong>噪声免疫</strong>：可过滤掉不重要的高频噪声（如个别原子偏差）</li><li><strong>物理意义</strong>：对应真实系统的振动模式（分子动力学验证）</li></ol><h2 id="第五步：生活中的类比-音乐混音台🎛️"><a href="#第五步：生活中的类比-音乐混音台🎛️" class="headerlink" title="第五步：生活中的类比 - 音乐混音台🎛️"></a>第五步：生活中的类比 - 音乐混音台🎛️</h2><p>想象你是个DJ在调音：</p><ul><li><strong>原始音乐</strong> = 图结构（混合着不同乐器的声音）</li><li><strong>均衡器滑块</strong> = 谱GNN的滤波器（控制高/中/低频）</li><li><strong>混音结果</strong> = GNN的输出（突出人声，弱化鼓声）</li></ul><p>谱GNN就是<strong>图的混音师</strong>：通过调节频带权重，突出重要信息！</p><h2 id="第六步：技术优化的突破-避免数学计算困难"><a href="#第六步：技术优化的突破-避免数学计算困难" class="headerlink" title="第六步：技术优化的突破 = 避免数学计算困难"></a>第六步：技术优化的突破 = 避免数学计算困难</h2><p>早期问题：精确计算特征分解需要 (O(n^3)) 时间（太慢！）</p><p><strong>现代解决方案</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR    A[切比雪夫多项式] --&gt; B[用K阶逼近代替精确解]    B --&gt; C[速度提升1000倍]  </pre></div></p><p>公式近似：</p><script type="math/tex; mode=display">g(\lambda) \approx \sum_{k=0}^K \theta_k T_k(\lambda)</script><p>（$T_k$是预设的多项式基函数，$\theta_k$是可学习参数）</p><blockquote><p>比如GCN模型：只用一阶近似就达到很好效果！</p></blockquote><h2 id="第七步：真实代码演示（PyG简化版）"><a href="#第七步：真实代码演示（PyG简化版）" class="headerlink" title="第七步：真实代码演示（PyG简化版）"></a>第七步：真实代码演示（PyG简化版）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建简单图: 3个相互连接的节点</span></span><br><span class="line">x = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])  <span class="comment"># 节点特征 [1,2,3]</span></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],       <span class="comment"># 边链接：0-1-2</span></span><br><span class="line">                          [<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>]]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立谱GNN（三阶近似）</span></span><br><span class="line">conv = ChebConv(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, K=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播过程等效为：</span></span><br><span class="line"><span class="comment"># 1. 计算拉普拉斯矩阵L</span></span><br><span class="line"><span class="comment"># 2. 用切比雪夫多项式逼近频域操作</span></span><br><span class="line"><span class="comment"># 3. 返回滤波后特征</span></span><br><span class="line">output = conv(x, edge_index) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入特征:&quot;</span>, x.flatten())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;谱滤波后:&quot;</span>, output.flatten())</span><br></pre></td></tr></table></figure><p><strong>输出示例</strong>：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入特征: [1, 2, 3]</span><br><span class="line">谱滤波后: [0.32, 1.48, 2.78]   # 低频增强后更平滑</span><br></pre></td></tr></table></figure><br>（实践中最常用ChebConv/GCNConv，隐藏了底层频谱计算）</p><h2 id="核心总结一句话"><a href="#核心总结一句话" class="headerlink" title="核心总结一句话"></a>核心总结一句话</h2><blockquote><p>谱GNN是在<strong>图的频谱空间</strong>（由拉普拉斯矩阵定义）中进行<strong>滤波操作</strong>的神经网络，<br>就像给图结构做”CT扫描+美颜滤镜”来提取关键特征。</p></blockquote><p><strong>学习建议路径</strong>：</p><ol><li>先理解谱聚类 → 2. 尝试GCN代码 → 3. 研究切比雪夫逼近原理<br>新手推荐库：PyTorch Geometric（封装了复杂数学）</li></ol><hr><h1 id="谱域图神经网络简单理论"><a href="#谱域图神经网络简单理论" class="headerlink" title="谱域图神经网络简单理论"></a>谱域图神经网络简单理论</h1><h2 id="一、核心理论基础：图谱分解"><a href="#一、核心理论基础：图谱分解" class="headerlink" title="一、核心理论基础：图谱分解"></a>一、核心理论基础：图谱分解</h2><h3 id="1-图拉普拉斯矩阵（关键算子）"><a href="#1-图拉普拉斯矩阵（关键算子）" class="headerlink" title="1. 图拉普拉斯矩阵（关键算子）"></a>1. 图拉普拉斯矩阵（关键算子）</h3><p>定义：</p><script type="math/tex; mode=display">\mathbf{L} = \mathbf{D} - \mathbf{A}</script><ul><li>$\mathbf{A}$：邻接矩阵</li><li>$\mathbf{D}$：度矩阵（对角阵，$D<em>{ii} = \sum_j A</em>{ij}$）</li></ul><p><strong>归一化形式</strong>（常用）：</p><script type="math/tex; mode=display">\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2} \mathbf{A} \mathbf{D}^{-1/2}</script><h3 id="2-特征分解"><a href="#2-特征分解" class="headerlink" title="2. 特征分解"></a>2. 特征分解</h3><p>将拉普拉斯矩阵分解为：</p><script type="math/tex; mode=display">\mathbf{L} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^\top</script><ul><li>$\mathbf{U} = [\mathbf{u}_1, \cdots, \mathbf{u}_N]$：特征向量矩阵（称为<strong>图傅里叶基</strong>）</li><li>$\mathbf{\Lambda} = \text{diag}(\lambda_1, \cdots, \lambda_N)$：特征值对角阵（$\lambda_i$表示频谱频率）</li></ul><h2 id="二、图信号谱域变换"><a href="#二、图信号谱域变换" class="headerlink" title="二、图信号谱域变换"></a>二、图信号谱域变换</h2><h3 id="1-图傅里叶变换（Graph-Fourier-Transform）"><a href="#1-图傅里叶变换（Graph-Fourier-Transform）" class="headerlink" title="1. 图傅里叶变换（Graph Fourier Transform）"></a>1. 图傅里叶变换（Graph Fourier Transform）</h3><p>对节点特征 $\mathbf{x} \in \mathbb{R}^N$ 的变换：</p><script type="math/tex; mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x} \quad \text{(时域→频域)}</script><p>逆变换：</p><script type="math/tex; mode=display">\mathbf{x} = \mathbf{U} \widehat{\mathbf{x}} \quad \text{(频域→时域)}</script><h3 id="2-图卷积定理"><a href="#2-图卷积定理" class="headerlink" title="2. 图卷积定理"></a>2. 图卷积定理</h3><p>图上的卷积操作在频谱域定义为<strong>逐元素乘积</strong>：</p><script type="math/tex; mode=display">\mathbf{x} *_\mathcal{G} \mathbf{y} = \mathbf{U} \left( (\mathbf{U}^\top \mathbf{x}) \odot (\mathbf{U}^\top \mathbf{y}) \right)</script><p>引入滤波器 $g_\theta(\mathbf{\Lambda})$ 后：</p><script type="math/tex; mode=display">\mathbf{x} *_\mathcal{G} g_\theta = \mathbf{U} g_\theta(\mathbf{\Lambda}) \mathbf{U}^\top \mathbf{x}</script><h2 id="三、经典模型演变"><a href="#三、经典模型演变" class="headerlink" title="三、经典模型演变"></a>三、经典模型演变</h2><h3 id="1-Spectral-CNN-Bruna-et-al-ICLR-2014"><a href="#1-Spectral-CNN-Bruna-et-al-ICLR-2014" class="headerlink" title="1. Spectral CNN (Bruna et al., ICLR 2014)"></a>1. Spectral CNN (Bruna et al., ICLR 2014)</h3><ul><li><strong>滤波器设计</strong>：<script type="math/tex; mode=display">g_\theta(\mathbf{\Lambda}) = \text{diag}(\theta_1, \theta_2, \cdots, \theta_N) \quad (\theta_i \in \mathbb{R})</script></li><li><strong>局限性</strong>：<ul><li>参数量大 ($O(N)$)</li><li>无法局部化（依赖全图特征分解）<h3 id="2-ChebNet-Defferrard-et-al-NeurIPS-2016"><a href="#2-ChebNet-Defferrard-et-al-NeurIPS-2016" class="headerlink" title="2. ChebNet (Defferrard et al., NeurIPS 2016)"></a>2. ChebNet (Defferrard et al., NeurIPS 2016)</h3>用<strong>切比雪夫多项式</strong>近似滤波器：<script type="math/tex; mode=display">g_\theta(\mathbf{\Lambda}) = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{\Lambda}})</script></li></ul></li><li>$\tilde{\mathbf{\Lambda}} = \frac{2\mathbf{\Lambda}}{\lambda_{\max}} - \mathbf{I}$（缩放至$[-1,1]$）</li><li>$T<em>k(\cdot)$：切比雪夫多项式（递归定义：$T_0=1, T_1=x, T_k=2xT</em>{k-1}-T_{k-2}$）</li></ul><p><strong>卷积操作</strong>：</p><script type="math/tex; mode=display">\mathbf{x} *_\mathcal{G} g_\theta = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{L}}) \mathbf{x}</script><p>其中 $\tilde{\mathbf{L}} = \frac{2\mathbf{L}}{\lambda_{\max}} - \mathbf{I}$（无需特征分解！）</p><h3 id="3-GCN-Kipf-amp-Welling-ICLR-2017"><a href="#3-GCN-Kipf-amp-Welling-ICLR-2017" class="headerlink" title="3. GCN (Kipf &amp; Welling, ICLR 2017)"></a>3. GCN (Kipf &amp; Welling, ICLR 2017)</h3><p>ChebNet 的<strong>一阶近似</strong>（$K=2$）：</p><script type="math/tex; mode=display">\mathbf{H}^{(l+1)} = \sigma \left( \hat{\mathbf{A}} \mathbf{H}^{(l)} \mathbf{W}^{(l)} \right) \quad \text{其中} \quad \hat{\mathbf{A}} = \tilde{\mathbf{D}}^{-1/2} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-1/2}</script><ul><li>仅聚合一阶邻居（高效且可扩展）</li></ul><h2 id="四、关键优势与局限性"><a href="#四、关键优势与局限性" class="headerlink" title="四、关键优势与局限性"></a>四、关键优势与局限性</h2><div class="table-container"><table><thead><tr><th><strong>优势</strong></th><th><strong>局限性</strong></th></tr></thead><tbody><tr><td>⭐ 理论基础严密（信号处理可解释性强）</td><td>⚠️ 计算成本高（需特征分解或多项式逼近）</td></tr><tr><td>⭐ 全局信息捕获能力强</td><td>⚠️ 对图结构变化敏感（固定图假设）</td></tr><tr><td>⭐ 频域滤波提供灵活特征选择</td><td>⚠️ 无法直接处理异构图</td></tr></tbody></table></div><h2 id="五、代码实现（PyTorch-Geometric）"><a href="#五、代码实现（PyTorch-Geometric）" class="headerlink" title="五、代码实现（PyTorch Geometric）"></a>五、代码实现（PyTorch Geometric）</h2><h3 id="ChebNet-示例："><a href="#ChebNet-示例：" class="headerlink" title="ChebNet 示例："></a>ChebNet 示例：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChebNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, K=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = ChebConv(in_dim, hidden_dim, K)  <span class="comment"># K阶切比雪夫近似</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = ChebConv(hidden_dim, out_dim, K)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x, edge_index))    <span class="comment"># 第一层（自动计算拉普拉斯）</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)                <span class="comment"># 第二层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line">model = ChebNet(in_dim=<span class="number">16</span>, hidden_dim=<span class="number">32</span>, out_dim=<span class="number">8</span>, K=<span class="number">3</span>)</span><br><span class="line">output = model(data)  <span class="comment"># 输入图数据</span></span><br></pre></td></tr></table></figure><h2 id="六、新一代谱方法研究（2023-2024）"><a href="#六、新一代谱方法研究（2023-2024）" class="headerlink" title="六、新一代谱方法研究（2023-2024）"></a>六、新一代谱方法研究（2023-2024）</h2><ol><li><p><strong>自适应谱滤波器</strong></p><ul><li><strong>GPR-GNN</strong> (ICLR 2021)：广义PageRank系数优化<script type="math/tex; mode=display">\mathbf{H} = \sum_{k=0}^K \gamma_k \hat{\mathbf{A}}^k \mathbf{X} \mathbf{W}</script><ul><li>$\gamma_k$ 作为可学习参数，自适应不同阶数重要性</li></ul></li></ul></li><li><p><strong>无需特征分解的谱学习</strong></p><ul><li><strong>BernNet</strong> (NeurIPS 2021)：用Bernstein多项式拟合任意滤波器：<script type="math/tex; mode=display">g(\lambda) = \sum_{k=0}^K \theta_k B_k(\lambda; K)</script><ul><li>$B_k$ 为Bernstein基函数，保证滤波器平滑性</li></ul></li></ul></li><li><p><strong>图小波神经网络</strong></p><ul><li><strong>GWNN</strong> (ICML 2023)：用图小波基取代傅里叶基<script type="math/tex; mode=display">\mathbf{\Psi}_s = \mathbf{U} e^{-\varepsilon s \mathbf{\Lambda}} \mathbf{U}^\top</script><ul><li>$s$ 为尺度参数，实现多分辨率分析</li></ul></li></ul></li></ol><h2 id="七、总结与应用场景"><a href="#七、总结与应用场景" class="headerlink" title="七、总结与应用场景"></a>七、总结与应用场景</h2><p><strong>核心适用领域</strong>：</p><ul><li>图信号处理（节点分类、图分类）</li><li>物理系统建模（分子动力学、流体模拟）</li><li>推荐系统（用户-商品图谱分析）<blockquote><p><strong>工具推荐</strong>：</p><ul><li><code>torch_geometric.nn.ChebConv</code></li><li>DGL的 <code>ChebConv</code> 模块</li><li><a href="https://github.com/ivam-he/BernNet">BernNet官方实现</a></li></ul><p><strong>最新突破</strong>：<strong>Oversquashing-Free Graph Neural Networks</strong> (ICML 2024) 提出通过谱设计解决长距离信息传递瓶颈。</p></blockquote></li></ul><hr><h1 id="Spectral-GNN-vs-Spatial-GNN"><a href="#Spectral-GNN-vs-Spatial-GNN" class="headerlink" title="Spectral GNN vs. Spatial GNN"></a>Spectral GNN vs. Spatial GNN</h1><p>以下是对空间图神经网络（Spatial GNN）和谱图神经网络（Spectral GNN）的全面对比解析，涵盖理论、模型和应用差异：</p><h2 id="一、核心理念对比"><a href="#一、核心理念对比" class="headerlink" title="一、核心理念对比"></a>一、核心理念对比</h2><div class="table-container"><table><thead><tr><th><strong>维度</strong></th><th>Spatial GNN (空间方法)</th><th>Spectral GNN (谱方法)</th></tr></thead><tbody><tr><td><strong>基本思想</strong></td><td>通过局部邻居聚合传播信息</td><td>在图傅里叶域定义卷积操作</td></tr><tr><td><strong>图定义域</strong></td><td>顶点域 (Vertex Domain)</td><td>谱域 (Spectral Domain)</td></tr><tr><td><strong>理论基础</strong></td><td>消息传递机制</td><td>图谱理论（拉普拉斯矩阵分解）</td></tr><tr><td><strong>计算范式</strong></td><td>图结构拓扑操作</td><td>频域信号处理</td></tr></tbody></table></div><h2 id="二、技术原理详解"><a href="#二、技术原理详解" class="headerlink" title="二、技术原理详解"></a>二、技术原理详解</h2><h3 id="Spatial-GNN-空间方法"><a href="#Spatial-GNN-空间方法" class="headerlink" title="Spatial GNN (空间方法)"></a>Spatial GNN (空间方法)</h3><p><strong>核心机制：消息传递 (Message Passing)</strong></p><ol><li><p><strong>聚合 (Aggregate)</strong>：</p><script type="math/tex; mode=display">\mathbf{m}_i^{(l)} = \text{AGGREGATE}^{(l)} \left( \{ \mathbf{h}_j^{(l-1)} \mid j \in \mathcal{N}(i) \} \right)</script><ul><li>邻居特征聚合（sum/mean/max）</li></ul></li><li><p><strong>更新 (Update)</strong>：</p><script type="math/tex; mode=display">\mathbf{h}_i^{(l)} = \text{UPDATE}^{(l)} \left( \mathbf{h}_i^{(l-1)}, \mathbf{m}_i^{(l)} \right)</script><ul><li>结合自身特征与聚合信息</li></ul></li></ol><p><strong>代表模型</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  GCN --&gt; GraphSAGE  GraphSAGE --&gt; GAT[GAT]  GAT --&gt; GIN[GIN]  GraphSAGE --&gt; PNA[PNA]  </pre></div></p><h3 id="Spectral-GNN-谱方法"><a href="#Spectral-GNN-谱方法" class="headerlink" title="Spectral GNN (谱方法)"></a>Spectral GNN (谱方法)</h3><p><strong>核心机制：频域卷积</strong></p><ol><li><p><strong>图傅里叶变换</strong>：</p><script type="math/tex; mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x}\tag{1}</script></li><li><p><strong>频域滤波</strong>：</p><script type="math/tex; mode=display">\widehat{\mathbf{y}} = g_\theta(\mathbf{\Lambda}) \widehat{\mathbf{x}}\tag{2}</script></li><li><p><strong>逆变换</strong>：</p><script type="math/tex; mode=display">\mathbf{y} = \mathbf{U} \widehat{\mathbf{y}} = \mathbf{U} g_\theta(\mathbf{\Lambda}) \mathbf{U}^\top \mathbf{x}\tag{3}</script></li></ol><blockquote><p>通俗易懂地说，公式(1)的操作是将$\mathbf{x}$映射到频率空间中；公式(2)是对映射到频率空间中的内容进行一些操作，如图卷积操作等；公式(3)是将频率空间中得到的内容再逆变换映射会原空间中。而公式(2)中的函数，为我们需要学习的函数。</p></blockquote><p><strong>代表模型进化</strong>：<br><div class="mermaid-wrap"><pre class="mermaid-src" hidden>    graph LR  SpectralCNN --&gt; ChebNet  ChebNet --&gt; GCN  ChebNet --&gt; ARMA[ARMA Net]  SpectralCNN --&gt; GWNN  </pre></div></p><h2 id="三、模型特性对比"><a href="#三、模型特性对比" class="headerlink" title="三、模型特性对比"></a>三、模型特性对比</h2><h3 id="1-计算效率"><a href="#1-计算效率" class="headerlink" title="1. 计算效率"></a>1. 计算效率</h3><div class="table-container"><table><thead><tr><th><strong>指标</strong></th><th>Spatial GNN</th><th>Spectral GNN</th></tr></thead><tbody><tr><td><strong>时间复杂度</strong></td><td>(O(\</td><td>\mathcal{E}\</td><td>)) (邻居聚合)</td><td>(O(n^2)) (特征分解) → 优化后(O(K\</td><td>\mathcal{E}\</td><td>))</td></tr><tr><td><strong>扩展性</strong></td><td>⭐⭐⭐ 支持大规模图</td><td>⭐⭐需近似处理提升效率</td></tr><tr><td><strong>并行性</strong></td><td>节点级并行（分布式优化）</td><td>全图级计算（GPU并行加速）</td></tr></tbody></table></div><h3 id="2-结构适应性"><a href="#2-结构适应性" class="headerlink" title="2. 结构适应性"></a>2. 结构适应性</h3><div class="table-container"><table><thead><tr><th><strong>特性</strong></th><th>Spatial GNN</th><th>Spectral GNN</th></tr></thead><tbody><tr><td><strong>动态图</strong></td><td>✅ 实时更新邻居</td><td>❌ 需重新计算拉普拉斯矩阵</td></tr><tr><td><strong>异构图</strong></td><td>✅ 支持多关系聚合（RGCN, HGT）</td><td>❌ 主要面向同构图</td></tr><tr><td><strong>边特征</strong></td><td>✅ 天然支持（如GINE）</td><td>⚠️ 需扩展设计</td></tr></tbody></table></div><h2 id="四、经典模型实现代码"><a href="#四、经典模型实现代码" class="headerlink" title="四、经典模型实现代码"></a>四、经典模型实现代码</h2><h3 id="Spatial-GNN示例：GAT-Graph-Attention-Network"><a href="#Spatial-GNN示例：GAT-Graph-Attention-Network" class="headerlink" title="Spatial GNN示例：GAT (Graph Attention Network)"></a>Spatial GNN示例：GAT (Graph Attention Network)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GAT</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, heads=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = GATConv(in_dim, hidden_dim, heads=heads)  <span class="comment"># 多头注意力</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = GATConv(hidden_dim*heads, out_dim, heads=<span class="number">1</span>) <span class="comment"># 单头输出</span></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x, edge_index))  <span class="comment"># 聚合：加权邻居特征</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)              <span class="comment"># 输出层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>空间聚合核心</strong>：注意力权重计算</p><script type="math/tex; mode=display">\alpha_{ij} = \frac{ \exp(\text{LeakyReLU}(\mathbf{a}^\top [\mathbf{W}\mathbf{h}_i \| \mathbf{W}\mathbf{h}_j])) } { \sum_{k \in \mathcal{N}(i)} \exp(\text{LeakyReLU}(\mathbf{a}^\top [\mathbf{W}\mathbf{h}_i \| \mathbf{W}\mathbf{h}_k])) }</script><h3 id="Spectral-GNN示例：ChebNet-切比雪夫网络"><a href="#Spectral-GNN示例：ChebNet-切比雪夫网络" class="headerlink" title="Spectral GNN示例：ChebNet (切比雪夫网络)"></a>Spectral GNN示例：ChebNet (切比雪夫网络)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChebNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, k=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = ChebConv(in_dim, hidden_dim, K=k)  <span class="comment"># K阶近似</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = ChebConv(hidden_dim, out_dim, K=k)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x, edge_index)  <span class="comment"># 频域卷积：切比雪夫多项式逼近</span></span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>谱滤波核心</strong>：(K)阶多项式展开</p><script type="math/tex; mode=display">g_\theta(\mathbf{L}) = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{L}})</script><h2 id="五、性能对比与适用场景"><a href="#五、性能对比与适用场景" class="headerlink" title="五、性能对比与适用场景"></a>五、性能对比与适用场景</h2><div class="table-container"><table><thead><tr><th><strong>任务类型</strong></th><th>推荐模型类型</th><th>原因说明</th></tr></thead><tbody><tr><td>大规模图节点分类</td><td>Spatial GNN</td><td>邻居采样高效（GraphSAGE）</td></tr><tr><td>图结构分析</td><td>Spectral GNN</td><td>捕获全局结构特征（谱聚类）</td></tr><tr><td>动态图预测</td><td>Spatial GNN</td><td>增量更新邻居（EvolveGCN）</td></tr><tr><td>分子性质预测</td><td>Spectral GNN</td><td>物理系统能量状态建模</td></tr><tr><td>推荐系统</td><td>Spatial GNN</td><td>多重关系建模（LightGCN）</td></tr></tbody></table></div><h2 id="六、前沿研究进展（2023-2024）"><a href="#六、前沿研究进展（2023-2024）" class="headerlink" title="六、前沿研究进展（2023-2024）"></a>六、前沿研究进展（2023-2024）</h2><h3 id="Spatial-GNN最新方向："><a href="#Spatial-GNN最新方向：" class="headerlink" title="Spatial GNN最新方向："></a>Spatial GNN最新方向：</h3><ol><li><p><strong>长距离依赖优化</strong></p><ul><li><strong>CRaWl</strong> (ICML 2023)：随机游走增强信息传播<script type="math/tex; mode=display">\mathbf{m}_i = \text{ATTN} \left( \{ \text{RW}_k(i) \mid k=1,\dots,K \} \right)</script><ul><li>解决过平滑（Over-smoothing）问题</li></ul></li></ul></li><li><p><strong>3D几何图学习</strong></p><ul><li><strong>Equivariant GNN</strong> (Nature 2024)：<script type="math/tex; mode=display">\mathbf{h}_i^{(l)} = f( \| \mathbf{x}_i - \mathbf{x}_j \|, \mathbf{h}_j ) \quad (SE(3)-\text{不变})</script><ul><li>应用于蛋白质结构预测</li></ul></li></ul></li></ol><h3 id="Spectral-GNN最新方向："><a href="#Spectral-GNN最新方向：" class="headerlink" title="Spectral GNN最新方向："></a>Spectral GNN最新方向：</h3><ol><li><p><strong>自适应谱滤波器</strong></p><ul><li><strong>FreqGNN</strong> (ICLR 2024)：可学习频带选择<script type="math/tex; mode=display">g_\theta(\lambda) = \sum_{k=1}^K \theta_k \cdot \text{bandpass}_k(\lambda)</script></li></ul></li><li><p><strong>无拉普拉斯方法</strong></p><ul><li><strong>AdaGNN</strong> (KDD 2023)：利用图扩散算子<script type="math/tex; mode=display">\mathbf{H} = \sum_{t=0}^T \alpha_t \mathbf{P}^t \mathbf{X} \mathbf{W}_t</script><ul><li>$\mathbf{P} = \mathbf{A}\mathbf{D}^{-1}$为转移矩阵</li></ul></li></ul></li></ol><h2 id="七、混合架构趋势"><a href="#七、混合架构趋势" class="headerlink" title="七、混合架构趋势"></a>七、混合架构趋势</h2><p><strong>SPAGAN</strong> (NeurIPS 2023)：空间-谱双路径融合<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 空间路径</span></span><br><span class="line">h_spatial = GATConv(x, edge_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 谱路径</span></span><br><span class="line">h_spectral = ChebConv(x, edge_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自适应融合 (门控机制)</span></span><br><span class="line">gate = σ(Linear([h_spatial || h_spectral]))</span><br><span class="line">output = gate * h_spatial + (<span class="number">1</span>-gate) * h_spectral</span><br></pre></td></tr></table></figure><br><strong>优势</strong>：在OGB Large-scale挑战赛中实现SOTA</p><blockquote><p><strong>最佳实践选择</strong>：</p><ul><li>优先<strong>Spatial GNN</strong>：工业级应用（推荐系统、欺诈检测）</li><li>选用<strong>Spectral GNN</strong>：科学计算任务（计算化学、物理模拟）</li><li><strong>Hybrid 模型</strong>：对精度要求极高的场景（如药物发现）</li></ul></blockquote><h1 id="Laplacian-Positional-Encoding"><a href="#Laplacian-Positional-Encoding" class="headerlink" title="Laplacian Positional Encoding"></a>Laplacian Positional Encoding</h1><p>拉普拉斯位置编码是图神经网络中一种基于<strong>图谱理论</strong>的位置表示方法，主要用于解决传统 GNN 无法区分<strong>结构等价节点</strong>的问题（如环形图中的对称节点）。它是位置编码（PE）在图数据上的扩展，通过图的拉普拉斯矩阵特征向量提供全局位置信息。</p><h2 id="核心数学原理"><a href="#核心数学原理" class="headerlink" title="核心数学原理"></a>核心数学原理</h2><h3 id="1-图拉普拉斯矩阵"><a href="#1-图拉普拉斯矩阵" class="headerlink" title="1. 图拉普拉斯矩阵"></a>1. 图拉普拉斯矩阵</h3><p>对于一个无向图 $G=(V,E)$，其归一化拉普拉斯矩阵定义为：</p><script type="math/tex; mode=display">L = I - D^{-1/2}AD^{-1/2}</script><p>其中：</p><ul><li>$A \in \mathbb{R}^{n\times n}$ 为邻接矩阵</li><li>$D$ 为度对角矩阵，$D<em>{ii} = \sum_j A</em>{ij}$</li><li>$L$ 是<strong>对称半正定矩阵</strong><h3 id="2-特征分解-1"><a href="#2-特征分解-1" class="headerlink" title="2. 特征分解"></a>2. 特征分解</h3>对 $L$ 进行特征分解：<script type="math/tex; mode=display">L = U \Lambda U^T</script>其中：</li><li>$\Lambda = \text{diag}(\lambda_1, \lambda_2, …, \lambda_n)$ 是特征值对角阵 ($0 \leq \lambda_1 \leq … \leq \lambda_n$)</li><li>$U = [\mathbf{u}_1, \mathbf{u}_2, …, \mathbf{u}_n]$ 是酉矩阵，每列是对应特征值的特征向量<h3 id="3-位置编码生成"><a href="#3-位置编码生成" class="headerlink" title="3. 位置编码生成"></a>3. 位置编码生成</h3>节点 $v$ 的位置编码为：<script type="math/tex; mode=display">PE(v) = [\mathbf{u}_2(v), \mathbf{u}_3(v), ..., \mathbf{u}_{d+1}(v)]</script>其中：</li><li>排除第一个特征向量 $\mathbf{u}_1$ (对应特征值 $\lambda_1=0$，所有元素均为常数)</li><li>取 $d$ 个最小非零特征值对应的特征向量分量</li></ul><blockquote><p><strong>为什么工作？</strong>：<br>Fiedler 定理表明第二特征向量 $\mathbf{u}_2$ (Fiedler 向量) 将图分割为两个连通分量的最优解，更高维特征向量提供更细粒度的空间位置信息。</p></blockquote><h2 id="特点分析"><a href="#特点分析" class="headerlink" title="特点分析"></a>特点分析</h2><div class="table-container"><table><thead><tr><th>性质</th><th>说明</th><th>影响</th></tr></thead><tbody><tr><td><strong>结构感知</strong></td><td>编码图的拓扑结构</td><td>区分环状图/网格图的对称节点</td></tr><tr><td><strong>正交性</strong></td><td>$\langle \mathbf{u}<em>i, \mathbf{u}_j \rangle=\delta</em>{ij}$</td><td>不同方向位置特征解耦</td></tr><tr><td><strong>排列不变性</strong></td><td>对节点重标号不变</td><td>满足GNN的置换不变性要求</td></tr><tr><td><strong>多尺度性</strong></td><td>小特征值对应全局结构</td><td>不同特征向量捕获不同尺度的位置关系</td></tr></tbody></table></div><h2 id="完整实现代码-PyTorch-PyG"><a href="#完整实现代码-PyTorch-PyG" class="headerlink" title="完整实现代码 (PyTorch+PyG)"></a>完整实现代码 (PyTorch+PyG)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> get_laplacian</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_laplace_pe</span>(<span class="params">edge_index, num_nodes, positive=<span class="literal">False</span>, k=<span class="number">8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算图的拉普拉斯位置编码</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        edge_index (Tensor): [2, num_edges] 边索引</span></span><br><span class="line"><span class="string">        num_nodes (int): 节点数量</span></span><br><span class="line"><span class="string">        positive (bool): 是否强制值均为正 (用于正定矩阵)</span></span><br><span class="line"><span class="string">        k (int): 使用的特征向量维度</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        pe (Tensor): [num_nodes, k] 位置编码矩阵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算归一化拉普拉斯矩阵</span></span><br><span class="line">    L = get_laplacian(edge_index, num_nodes=num_nodes, normalization=<span class="string">&#x27;sym&#x27;</span>)</span><br><span class="line">    L_sparse = sp.coo_matrix((L[<span class="number">1</span>].numpy(), L[<span class="number">0</span>].numpy()), shape=(num_nodes, num_nodes))</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 特征分解 (仅计算k+1个最小特征值/向量)</span></span><br><span class="line">    evals, evecs = sp.linalg.eigsh(L_sparse, k=k+<span class="number">1</span>, which=<span class="string">&#x27;SM&#x27;</span>)</span><br><span class="line">    <span class="comment"># 删除第一个特征向量(对应λ=0)</span></span><br><span class="line">    evecs = evecs[:, evals.argsort()][:, <span class="number">1</span>:<span class="number">1</span>+k] </span><br><span class="line">  </span><br><span class="line">    pe = torch.tensor(evecs).<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># 可选：变换为正值(使维度可解释)</span></span><br><span class="line">    <span class="keyword">if</span> positive:</span><br><span class="line">        pe = pe - pe.<span class="built_in">min</span>(<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> pe / pe.<span class="built_in">max</span>(<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> pe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：应用到分子图数据</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> ZINC</span><br><span class="line">dataset = ZINC(root=<span class="string">&#x27;/data/zinc&#x27;</span>, split=<span class="string">&#x27;train&#x27;</span>, transform=LaplacePEAdder(k=<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LaplacePEAdder</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;PyG数据转换器：自动加入位置编码&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k=<span class="number">8</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.k = k</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data: Data</span>):</span><br><span class="line">        edge_index, num_nodes = data.edge_index, data.num_nodes</span><br><span class="line">        pe = compute_laplace_pe(edge_index, num_nodes, k=<span class="variable language_">self</span>.k)</span><br><span class="line">        <span class="comment"># 与原始特征拼接</span></span><br><span class="line">        <span class="keyword">if</span> data.x <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data.x = pe</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data.x = torch.cat([data.x, pe], dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h2 id="关键优化技术"><a href="#关键优化技术" class="headerlink" title="关键优化技术"></a>关键优化技术</h2><ol><li><strong>GPU加速特征分解</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用cuSPARSE和cuSOLVER进行加速</span></span><br><span class="line"><span class="keyword">import</span> torch.sparse</span><br><span class="line">L_coo = get_laplacian(edge_index, normalization=<span class="string">&#x27;sym&#x27;</span>)</span><br><span class="line">L_indices = torch.vstack(L_coo)</span><br><span class="line">L_value = torch.ones(L_coo.shape[<span class="number">1</span>])</span><br><span class="line">L_sparse = torch.sparse_coo_tensor(L_indices, L_value, (num_nodes, num_nodes))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 截断特征分解</span></span><br><span class="line">evals, evecs = torch.lobpcg(L_sparse, k=k+<span class="number">1</span>, largest=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></li><li><strong>处理大规模图</strong><ul><li>Nystrom 近似法：对部分节点采样加速计算 (ICML 2023)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> graphgym.efeat.position <span class="keyword">import</span> nystrom_approximation</span><br><span class="line">pe = nystrom_approximation(L, sample_size=<span class="number">500</span>, dim=k)</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="GNN模型集成示例"><a href="#GNN模型集成示例" class="headerlink" title="GNN模型集成示例"></a>GNN模型集成示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GTPosModel</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;结合位置编码的图Transformer&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, pe_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.pe_proj = nn.Linear(pe_dim, in_dim)  <span class="comment"># 位置编码投影层</span></span><br><span class="line">        <span class="variable language_">self</span>.encoder = GATConv(in_dim, <span class="number">64</span>, heads=<span class="number">4</span>)</span><br><span class="line">        ...</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index, lap_pe</span>):</span><br><span class="line">        <span class="comment"># 融合原始特征和位置编码</span></span><br><span class="line">        fused_feat = x + <span class="variable language_">self</span>.pe_proj(lap_pe)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.encoder(fused_feat, edge_index)</span><br></pre></td></tr></table></figure><h2 id="应用场景比较"><a href="#应用场景比较" class="headerlink" title="应用场景比较"></a>应用场景比较</h2><div class="table-container"><table><thead><tr><th>图类型</th><th>适用性</th><th>解释</th></tr></thead><tbody><tr><td>环形/网格图</td><td>★★★</td><td>完美区分结构等价节点</td></tr><tr><td>小世界网络</td><td>★★☆</td><td>局部特征优于全局位置</td></tr><tr><td>低维点云图</td><td>★☆</td><td>欧式距离编码更有效</td></tr><tr><td>动态图</td><td>☆</td><td>需每次重新计算特征分解</td></tr></tbody></table></div><h2 id="前沿进展"><a href="#前沿进展" class="headerlink" title="前沿进展"></a>前沿进展</h2><ol><li><p><strong>复值编码</strong> (ICLR 2024突破)<br>使用复值特征向量拓展频谱信息：</p><script type="math/tex; mode=display">\mathcal{CR}PE(v) = e^{-i\theta}\mathbf{u}(v) \quad (\theta \sim \text{learnable})</script></li><li><p><strong>方向可区分编码</strong><br>在异质图中给特征向量赋予方向信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">directed_lap_pe</span>(<span class="params">edge_index, direction=<span class="string">&#x27;out&#x27;</span></span>):</span><br><span class="line">    L_out = D_out^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125; A D_out^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125;  <span class="comment"># 出度拉普拉斯</span></span><br><span class="line">    L_in = D_in^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125; A^T D_in^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125;   <span class="comment"># 入度拉普拉斯</span></span><br><span class="line">    <span class="keyword">return</span> (compute_pe(L_out), compute_pe(L_in))</span><br></pre></td></tr></table></figure></li><li><p><strong>自适应频谱选择</strong><br>基于learnable gating机制动态选择特征向量：</p><script type="math/tex; mode=display">\text{PE}(v) = \sum_{i=2}^k g_i(\mathcal{G}) \cdot \mathbf{u}_i(v)</script></li></ol><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><ul><li>Dwivedi et al. Benchmarking GNNs with Positional Encodings (ICLR 2023)</li><li>Kreuzer et al. Rethinking Graph Transformers with Spectral Attention (NeurIPS 2021)</li><li>Lim et al. Sign and Basis Invariant Networks for Spectral Graph Representation Learning (ICML 2023)</li></ul><blockquote><p><strong>最佳实践</strong>：</p><ul><li>对于&lt;50k节点的图直接计算全分解</li><li>大图使用Nyström近似或Lanczos迭代</li><li>与可学习PE结合（如Random Walk PE）效果更佳</li><li>Transformer架构比GCN/GAT更能利用频谱信息</li></ul></blockquote><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://epsilonzyj.github.io/posts/63fed347.html">图神经网络简介 | An Introduction to GNN</a></li><li><a href="https://www.bilibili.com/video/BV1Vw411R7Fj?spm_id_from=333.788.videopod.episodes&amp;vd_source=2e36fae16810615c2d859efc03aef1c4">图卷积神经网络（GCN）的数学原理详解——谱图理论和傅立叶变换初探-Bilibili</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用Mac远程连接Windows WSL</title>
      <link href="/posts/e4aef2ca.html"/>
      <url>/posts/e4aef2ca.html</url>
      
        <content type="html"><![CDATA[<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>Windows与MacBook，且处于同一局域网下。安装WSL2的过程略。</p><h2 id="WSL中的配置"><a href="#WSL中的配置" class="headerlink" title="WSL中的配置"></a>WSL中的配置</h2><h3 id="安装配置SSH服务"><a href="#安装配置SSH服务" class="headerlink" title="安装配置SSH服务"></a>安装配置SSH服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install openssh-server</span><br></pre></td></tr></table></figure><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure><p>将注释的内容全部取消注释：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Port 22</span><br><span class="line">AddressFamily any</span><br><span class="line">ListenAddress 0.0.0.0</span><br><span class="line">PasswordAuthentication yes</span><br></pre></td></tr></table></figure><h3 id="启动SSH服务"><a href="#启动SSH服务" class="headerlink" title="启动SSH服务"></a>启动SSH服务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> ssh-keygen -A</span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> /usr/sbin/service ssh start</span><br></pre></td></tr></table></figure><h2 id="Windows的配置"><a href="#Windows的配置" class="headerlink" title="Windows的配置"></a>Windows的配置</h2><p>由于电脑可能安装了杀毒软件，会导致Windows Defender中防火墙设置被篡改而使得部分功能变为灰色，从而不可用，因此使用Power Shell进行配置。注意，一定要使用管理员身份打开，否则会因为权限不足而无法完成操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">New-NetFirewallRule -Name sshd -DisplayName <span class="string">&#x27;sshd for WSL&#x27;</span> -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22</span><br></pre></td></tr></table></figure><h2 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h2><p>使用管理员身份在Power Shell中运行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">​​​​​​​netsh interface portproxy add v4tov4 listenaddress=0.0.0.0 listenport=[PORT] connectaddress=[IP] connectport=[PORT]</span><br><span class="line"><span class="comment"># PORT 为你设置的端口，我这里为3333</span></span><br><span class="line"><span class="comment"># IP地址为wls linux子系统的ip地址，可通过ifconfig查看</span></span><br></pre></td></tr></table></figure><h2 id="使用Mac远程连接"><a href="#使用Mac远程连接" class="headerlink" title="使用Mac远程连接"></a>使用Mac远程连接</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh xxx@xxx.xxx.xxx.xxx -p 22</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Env </category>
          
          <category> WSL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> WSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zotero：A great research assistant</title>
      <link href="/posts/2286d822.html"/>
      <url>/posts/2286d822.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Research </tag>
            
            <tag> Tools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ICS实验随笔</title>
      <link href="/posts/67ad26dd.html"/>
      <url>/posts/67ad26dd.html</url>
      
        <content type="html"><![CDATA[<h2 id="关于右移的问题"><a href="#关于右移的问题" class="headerlink" title="关于右移的问题"></a>关于右移的问题</h2><h3 id="问题发现"><a href="#问题发现" class="headerlink" title="问题发现"></a>问题发现</h3><p>在上机进行ICS实验中，有一个函数要求产生highbit到lowbit全为1的数字。一个相当简单的想法是直接将0xFFFFFFFF右移hinghbit+1位后再 移回来，再取反，便可以得到第0位到第highbit位的数字，然后再进行后续操作。</p><p>然而在这个问题中，遇到了一些问题，在此记录一下。</p><h4 id="左右移的位数为负数"><a href="#左右移的位数为负数" class="headerlink" title="左右移的位数为负数"></a>左右移的位数为负数</h4><p><strong>负数移位</strong>（如x &gt;&gt; -1）属于<strong>未定义行为</strong>，不同平台和编译器会产生不同结果，部分会在编译阶段报错，而在一些特定运算下，如x &gt;&gt; (m-n)中，可能会因为某些特殊赋值而出现负数，应当进行避免。</p><h4 id="右移溢出"><a href="#右移溢出" class="headerlink" title="右移溢出"></a>右移溢出</h4><p>根据上面函数所需要求，一开始写出如下的函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">bitMask</span><span class="params">(<span class="type">int</span> highbit, <span class="type">int</span> lowbit)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> high = ~((<span class="number">0xFFFFFFFF</span> &gt;&gt; (highbit + <span class="number">1</span>)) &lt;&lt; (highbit + <span class="number">1</span>));</span><br><span class="line">    <span class="type">int</span> low  = ((~<span class="number">0</span>) &lt;&lt; lowbit);</span><br><span class="line">    <span class="keyword">return</span> high &amp; low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然而，在测试调试时发现，当highbit==31时，函数值则会有问题。溯源后发现，highbit+1==32时，high的值一直为0xFFFFFFFF，并不符合预期的0x0。起初以为是自己逻辑有问题，于是进行了一下测试，首先把highbit+1替换为32：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">bitMask</span><span class="params">(<span class="type">int</span> highbit, <span class="type">int</span> lowbit)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> high = ~((<span class="number">0xFFFFFFFF</span> &gt;&gt; <span class="number">32</span>) &lt;&lt; <span class="number">32</span>);</span><br><span class="line">    <span class="type">int</span> low  = ((~<span class="number">0</span>) &lt;&lt; lowbit);</span><br><span class="line">    <span class="keyword">return</span> high &amp; low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然而出乎意料的是，此时high的值变为正常的0x0，此时也开始报了warning，但显然不看warning是一个好习惯（经典笑话，笑）。则考虑到32与highbit+1的差异性，一开始没考虑常量和变量的问题，以为是32是unsigned类型而另一个是int类型，由于数据类型的问题可能会存在一些区别，虽然感觉这种思路似乎很离谱，且并没有什么道理可言，但是还是测试了一下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">bitMask</span><span class="params">(<span class="type">int</span> highbit, <span class="type">int</span> lowbit)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> high = ~((<span class="number">0xFFFFFFFF</span> &gt;&gt; (<span class="type">unsigned</span>)(highbit + <span class="number">1</span>)) &lt;&lt; (<span class="type">unsigned</span>)(highbit + <span class="number">1</span>));</span><br><span class="line">    <span class="type">int</span> low  = ((~<span class="number">0</span>) &lt;&lt; lowbit);</span><br><span class="line">    <span class="keyword">return</span> high &amp; low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个时候high又变成了0xFFFFFFFF，这有些出乎意料，一时就没什么头绪，不知道有什么问题，于是就开始怀疑编译器是否有编译优化的问题了。</p><h5 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h5><p>经过查找资料，发现右移时右侧操作数大于或等于左侧操作数的位数是属于未定义运算，而编译时确实存在一些编译优化。对于未定义行为，在编译时，分别发生了以下两件事：</p><ul><li>常量表达式：编译器在编译阶段进行常量求值，依据标准未定义的情况下可能直接优化成 0。</li><li>变量表达式：运行时生成的移位指令通常只取移位数的低 5 位（对于 32 位整数而言），因而 32 的低 5 位为 0，实际移位相当于“右移 0 位”，结果保持原值 0xFFFFFFFF。</li></ul><p>当表达式写为 0xFFFFFFFF &gt;&gt; (highbit+1) 时，虽然 (highbit+1) 计算结果为 32，但由于其为运行时求值的变量表达式，编译器生成的汇编指令遵循硬件实际移位机制。</p><p>在许多 CPU 架构（例如 x86）中，用于右移操作的指令（如 SHR 指令）通常只取移位数的低 5 位（对于 32 位操作数），即实际移位数 = 给定移位数 mod 32。</p><p>当 (highbit+1) 等于 32 时，其低 5 位为 0，故实际移位操作相当于“右移 0 位”，因此结果仍为原值 0xFFFFFFFF。</p><p>这种处理方式与硬件实现有关，虽然在 C 语言标准中两种写法的行为都是未定义的，但实际运行时硬件指令的“模 32”特性使得结果不同。</p><p>因此，对于上述问题，一种解决办法就是分开写，即移两次位。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">bitMask</span><span class="params">(<span class="type">int</span> highbit, <span class="type">int</span> lowbit)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> high = ~((((<span class="number">0xFFFFFFFF</span> &gt;&gt; highbit) &gt;&gt; <span class="number">1</span>) &lt;&lt; highbit) &lt;&lt; <span class="number">1</span>);</span><br><span class="line">    <span class="type">int</span> low  = ((~<span class="number">0</span>) &lt;&lt; lowbit);</span><br><span class="line">    <span class="keyword">return</span> high &amp; low;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="寄存器保护"><a href="#寄存器保护" class="headerlink" title="寄存器保护"></a>寄存器保护</h2><h3 id="问题发现-1"><a href="#问题发现-1" class="headerlink" title="问题发现"></a>问题发现</h3><p>在某次实验中，根据实验要求，需要使用汇编语言编写其中的部分函数。当然这个实验主要的内容实在优化炫技（划掉），不过在实验中遇到了一个很奇怪的问题。</p><p><em>注意：实验环境为Visual Studio 2022，编译采用x86架，构。其中在生成依赖项时需要对项目进行设置，对项目名称右击后点击生成依赖项下的生成子定义，并勾选masm，这样可以实现汇编和C混合编程。其余均为默认设置。感兴趣的同学可以根据以上内容进行复现。</em></p><p>在实验中需要在Debug版本和Release版本下分别进行程序运行速度的比较，编译阶段并没有问题，Debug版本可以正常运行。但是在Release版本中，当运行即将退出主函数时，抛出了异常。（由于时间较久远，且笔者较懒，没有复现的图片，了解一下原理即可）</p><h3 id="问题解决-1"><a href="#问题解决-1" class="headerlink" title="问题解决"></a>问题解决</h3><p>根据反汇编调试，在return 0处打断点，在查看反汇编后，发现在退出主函数之前进行了一些安全检查，其中一项就是进行寄存器的检查。而在本次场景中，因为Release版本优化程度较高，在程序编译时默认不会使用到寄存器ebx，因而在程序退出时会检查ebx是否进行改动。很遗憾，笔者水平较差，在编写x86汇编的时候用到了ebx并且没有进行寄存器保护，因此由于篡改寄存器导致程序崩溃。</p><p>以下给出原始的代码（后期模拟出来的）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">.686P</span><br><span class="line">.model flat, c</span><br><span class="line">printf proto c :ptr sbyte, :vararg</span><br><span class="line">; includelib  libcmt.lib</span><br><span class="line">includelib  legacy_stdio_definitions.lib </span><br><span class="line"></span><br><span class="line">student  struct</span><br><span class="line">    sname   db   8 dup(0)</span><br><span class="line">    sid     db   11 dup(0)</span><br><span class="line">    align   2    ; 指明对齐方式，汇编语言默认是紧凑存放</span><br><span class="line">                 ; 可以实验一下，去掉对齐方式伪指令的结果</span><br><span class="line">    scores  dw   8  dup(0)</span><br><span class="line">    average dw   0</span><br><span class="line">student   ends</span><br><span class="line"></span><br><span class="line">.data</span><br><span class="line">   lpfmt  db &quot;%s %s %d %d&quot;,0dh,0ah,0</span><br><span class="line">   lpfmt_string  db &quot;%s  &quot;,0</span><br><span class="line">   lpfmt_num  db &quot;%d  &quot;,0</span><br><span class="line">   lpfmt_size    db  &quot;size of struct %d  &quot;,0dh,0ah,0</span><br><span class="line">   lpfmt_offset  db  0dh,0ah,&quot;offset of scores %d  &quot;,0dh,0ah,0</span><br><span class="line"></span><br><span class="line">.code</span><br><span class="line">;  显示学生信息</span><br><span class="line">;  sptr 学生数组的首地址</span><br><span class="line">;  num  学生人数</span><br><span class="line">;  注意， printf 中会用到一些寄存器，也没有保护</span><br><span class="line">;         即执行 printf前后，一个寄存器中的内容发生变化</span><br><span class="line"></span><br><span class="line">computeAverageScoreAsmOpt proc sptr: dword, num: dword</span><br><span class="line">    local s: dword</span><br><span class="line"></span><br><span class="line">    mov edx, sptr</span><br><span class="line">    mov eax, 0</span><br><span class="line">    mov ecx, 0</span><br><span class="line"></span><br><span class="line">LOOPI:</span><br><span class="line">                    ;int sum = 0</span><br><span class="line">    mov eax, 0</span><br><span class="line">    mov s, eax</span><br><span class="line">                    ;s[i].scores[0]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 014h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[1]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 016h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;s[i].scores[2]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 018h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx </span><br><span class="line">    </span><br><span class="line">                    ;s[i].scores[3]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Ah</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[4]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Ch</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[5]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Eh</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;s[i].scores[6]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 020h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx  </span><br><span class="line">    </span><br><span class="line">                    ;s[i].scores[7]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 022h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;sum / 8</span><br><span class="line">    mov eax, s</span><br><span class="line">    sar eax, 3</span><br><span class="line">                    ;s[i].average = sum/8</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    mov word ptr[edx+ebx+024h], ax</span><br><span class="line">                    ;i ++</span><br><span class="line">    inc ecx</span><br><span class="line">                    ;i == num ?</span><br><span class="line">    cmp ecx,num</span><br><span class="line">    jne LOOPI</span><br><span class="line"></span><br><span class="line">    ret</span><br><span class="line">computeAverageScoreAsmOpt endp</span><br><span class="line">end</span><br></pre></td></tr></table></figure><p>寄存器保护其实是一个非常简单非常常见的想法，但是由于在编写函数时，笔者原想要减少指令以换取（似乎）更快的速度，同时也是懒得写（划掉，怎么能把最重要的原因写出来），因此并没有做任何寄存器保护的办法。</p><p>接下来就简单讲一下寄存器保护思路：</p><ul><li>对于eax等寄存器，直接压入栈中即可</li><li>对于ebp，将ebp压入栈中，同时将esp赋值给ebp（即让ebp指向原始栈顶，方便后续esp和ebp等在函数返回时/后恢复原来的值）</li><li>对于esp，esp减少一部分值，即指向更小的地址，建立一个新栈</li></ul><p>而在实验中，由于并没有（直接）使用ebp、esp等寄存器，因而就对这两个不做特殊的保护了，而将其余寄存器全部压入栈中，在函数结束时再弹出。由于懒（划掉），笔者将所有的可能用到的寄存器均压入了栈中，而不是将此函数中用到的寄存器压入栈中（反正结果对了就行了，划掉）。</p><p>以下是修改后的代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line">.686P</span><br><span class="line">.model flat, c</span><br><span class="line">printf proto c :ptr sbyte, :vararg</span><br><span class="line">; includelib  libcmt.lib</span><br><span class="line">includelib  legacy_stdio_definitions.lib </span><br><span class="line"></span><br><span class="line">student  struct</span><br><span class="line">    sname   db   8 dup(0)</span><br><span class="line">    sid     db   11 dup(0)</span><br><span class="line">    align   2    ; 指明对齐方式，汇编语言默认是紧凑存放</span><br><span class="line">                 ; 可以实验一下，去掉对齐方式伪指令的结果</span><br><span class="line">    scores  dw   8  dup(0)</span><br><span class="line">    average dw   0</span><br><span class="line">student   ends</span><br><span class="line"></span><br><span class="line">.data</span><br><span class="line">   lpfmt  db &quot;%s %s %d %d&quot;,0dh,0ah,0</span><br><span class="line">   lpfmt_string  db &quot;%s  &quot;,0</span><br><span class="line">   lpfmt_num  db &quot;%d  &quot;,0</span><br><span class="line">   lpfmt_size    db  &quot;size of struct %d  &quot;,0dh,0ah,0</span><br><span class="line">   lpfmt_offset  db  0dh,0ah,&quot;offset of scores %d  &quot;,0dh,0ah,0</span><br><span class="line"></span><br><span class="line">.code</span><br><span class="line">;  显示学生信息</span><br><span class="line">;  sptr 学生数组的首地址</span><br><span class="line">;  num  学生人数</span><br><span class="line">;  注意， printf 中会用到一些寄存器，也没有保护</span><br><span class="line">;         即执行 printf前后，一个寄存器中的内容发生变化</span><br><span class="line"></span><br><span class="line">computeAverageScoreAsmOpt proc sptr: dword, num: dword</span><br><span class="line">    local s: dword</span><br><span class="line"></span><br><span class="line">    push eax</span><br><span class="line">    push ebx</span><br><span class="line">    push ecx</span><br><span class="line">    push edx</span><br><span class="line">    push esi</span><br><span class="line">    push edi</span><br><span class="line"></span><br><span class="line">    mov edx, sptr</span><br><span class="line">    mov eax, 0</span><br><span class="line">    mov ecx, 0</span><br><span class="line"></span><br><span class="line">LOOPI:</span><br><span class="line">                    ;int sum = 0</span><br><span class="line">    mov eax, 0</span><br><span class="line">    mov s, eax</span><br><span class="line">                    ;s[i].scores[0]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 014h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[1]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 016h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;s[i].scores[2]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 018h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx </span><br><span class="line">    </span><br><span class="line">                    ;s[i].scores[3]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Ah</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[4]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Ch</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line"></span><br><span class="line">                    ;s[i].scores[5]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 01Eh</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;s[i].scores[6]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 020h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx  </span><br><span class="line">    </span><br><span class="line">                    ;s[i].scores[7]</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    add ebx, 022h</span><br><span class="line">    movzx eax, word ptr[edx+ebx]</span><br><span class="line">                    ;sum = sum + s[i].scores[j]</span><br><span class="line">    mov ebx, s</span><br><span class="line">    add ebx, eax</span><br><span class="line">    mov s, ebx</span><br><span class="line">                    </span><br><span class="line">                    ;sum / 8</span><br><span class="line">    mov eax, s</span><br><span class="line">    sar eax, 3</span><br><span class="line">                    ;s[i].average = sum/8</span><br><span class="line">    mov ebx, 026h</span><br><span class="line">    imul ebx, ecx</span><br><span class="line">    mov word ptr[edx+ebx+024h], ax</span><br><span class="line">                    ;i ++</span><br><span class="line">    inc ecx</span><br><span class="line">                    ;i == num ?</span><br><span class="line">    cmp ecx,num</span><br><span class="line">    jne LOOPI</span><br><span class="line"></span><br><span class="line">    pop edi</span><br><span class="line">    pop esi</span><br><span class="line">    pop edx</span><br><span class="line">    pop ecx</span><br><span class="line">    pop ebx</span><br><span class="line">    pop eax</span><br><span class="line"></span><br><span class="line">    ret</span><br><span class="line">computeAverageScoreAsmOpt endp</span><br><span class="line">end</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Course </category>
          
          <category> ICS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HUST </tag>
            
            <tag> ICS </tag>
            
            <tag> C/C++ </tag>
            
            <tag> Assembly </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HUST仓库</title>
      <link href="/posts/c723aac6.html"/>
      <url>/posts/c723aac6.html</url>
      
        <content type="html"><![CDATA[<p>本博客用于记录作者本科时期的课程实验或课程设计。</p><ol><li><a href="https://github.com/EpsilonZYJ/HUST-Material/tree/main/计算机科学与技术/IAC语言程序设计/code">C语言程序设计实验</a></li><li><a href="https://github.com/EpsilonZYJ/HUST-Material/tree/main/计算机科学与技术/IA计算思维">计算思维</a></li><li><a href="https://github.com/EpsilonZYJ/DataStructureExp">数据结构实验</a></li><li><a href="https://github.com/EpsilonZYJ/Sudoku">基于SAT问题的数独求解（程序综合课程设计）</a></li><li><a href="https://github.com/EpsilonZYJ/AlgorithmExperiment">算法设计实验</a></li><li><a href="https://github.com/EpsilonZYJ/CppExperiement">C++实验</a></li><li><a href="https://github.com/EpsilonZYJ/Digital-Circuit-Experiment">数字电路与逻辑设计实验</a></li><li><a href="https://github.com/EpsilonZYJ/IntroductionToAI">人工智能导论课程作业</a></li><li><a href="https://github.com/EpsilonZYJ/DataBaseExperiement/tree/main">数据库系统原理实验</a></li><li><a href="https://github.com/EpsilonZYJ/Introduction-To-Machine-Learning/tree/main">机器学习导论实验与课设</a></li><li><a href="https://github.com/EpsilonZYJ/HUST-Java">Java实验</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> HUST </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HUST </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNN经典模型 | GNN Basic Models</title>
      <link href="/posts/4a93988c.html"/>
      <url>/posts/4a93988c.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> GNN </tag>
            
            <tag> GNN With Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图神经网络简介 | An Introduction to GNN</title>
      <link href="/posts/63fed347.html"/>
      <url>/posts/63fed347.html</url>
      
        <content type="html"><![CDATA[<h2 id="图的表示"><a href="#图的表示" class="headerlink" title="图的表示"></a>图的表示</h2><p>对于图，有</p><ul><li>V：Vertex(or node) attributes</li><li>E：Edge(or link) attributes and directions</li><li>U：Global(or master node) attributes</li></ul><p>分别可以使用向量embedding来进行表示。</p><h3 id="图片转化为图"><a href="#图片转化为图" class="headerlink" title="图片转化为图"></a>图片转化为图</h3><p>将第$(i, j)$位置的像素映射为第$(i, j)$位置的节点（可以将节点按照类似像素排序的规则排序，即每行每列个数均固定。对于图采用邻接矩阵进行存储。对于某个像素的邻居，为上下左右和对角线上至多8个节点，进而表示为图</p><h3 id="文本转化为图"><a href="#文本转化为图" class="headerlink" title="文本转化为图"></a>文本转化为图</h3><p>可以将每一个词表示为一个顶点，上一个词和下一个词之间有一个有向的边。</p><h3 id="其它问题转化为图"><a href="#其它问题转化为图" class="headerlink" title="其它问题转化为图"></a>其它问题转化为图</h3><h4 id="分子转化为图"><a href="#分子转化为图" class="headerlink" title="分子转化为图"></a>分子转化为图</h4><p>可以使每个原子表示一个节点，原子之间有边相连则表示一条边。</p><h4 id="社交网络图"><a href="#社交网络图" class="headerlink" title="社交网络图"></a>社交网络图</h4><p>如同一场景中出现过的人，可以将其对应的节点连一条边。</p><h4 id="引用图"><a href="#引用图" class="headerlink" title="引用图"></a>引用图</h4><p>如文章A引用文章B，则可以连接A指向B的有向边。</p><h3 id="图机器学习的任务"><a href="#图机器学习的任务" class="headerlink" title="图机器学习的任务"></a>图机器学习的任务</h3><ul><li>图层面的任务，如识别有几个环进而对图进行分类</li><li>顶点层面的任务，如对两个复杂的社交网络图，对其中以两个人为核心的两个不同阵营，判断每个人属于哪个阵营</li><li>边层面的任务，预测边的属性</li></ul><h3 id="机器学习用于图上的挑战"><a href="#机器学习用于图上的挑战" class="headerlink" title="机器学习用于图上的挑战"></a>机器学习用于图上的挑战</h3><p><em>（此处机器学习特指神经网络）</em></p><p>图上有四种信息：顶点的属性、边的属性、全局信息和连接性。前三种均可用向量表示，但连接性表示比较困难。</p><p>一种朴素想法是使用邻接矩阵，连接则用1表示，未连接用0表示。但是这种方法表示的矩阵会非常大。如果使用稀疏矩阵，在存储上可行，但要高效计算或者在GPU上计算较为困难。此外，由于交换任意行和任意列不会产生影响，这意味着交换任意行或任意列后的图放进神经网络，出来的结果应该与原先相同。</p><p>因此我们可以采用如下的形式。使用一个向量来表示节点，每个节点的属性使用一个标量来表示；用一个向量来表示边，每个边的属性也使用一个标量来表示；使用邻接链表来表示连接性。如下图所示：</p><p><img src="/img/GNN1.png" alt=""></p><h2 id="图神经网络"><a href="#图神经网络" class="headerlink" title="图神经网络"></a>图神经网络</h2><p>图神经网络是对图上所有的属性，包括顶点、边、上下文等，进行一个可以优化的变换，而这个变换可以保持住图的对称信息（顶点重新排序后结果不变）。此处采用信息传递的神经网络。图神经网络输入为图，输出也是图，对图的顶点、边和全局上下文进行变换，但不对连接性产生改变。</p><h3 id="最简单的GNN"><a href="#最简单的GNN" class="headerlink" title="最简单的GNN"></a>最简单的GNN</h3><p>使用上文所提出的数据结构，对全局上下问信息、顶点和边分别建立多层感知机，从而获得一个新的图。</p><h3 id="GNN-Predictions-by-Pooling-Information"><a href="#GNN-Predictions-by-Pooling-Information" class="headerlink" title="GNN Predictions by Pooling Information"></a>GNN Predictions by Pooling Information</h3><p>若没有顶点点向量，则使用汇聚/池化（Pooling）来得到节点向量。将与该节点的边的向量和全局向量一起相加得到新的向量（此处假设全局向量和边的向量维度相同，如果不同则需要进行投影），得到的新的向量作为节点的向量。最后进入全连接层得到顶点的输出。</p><p><img src="/img/GNN2.png" alt=""></p><p>同样的，如果只有顶点向量和全局向量，则将顶点向量和全局向量汇聚到边上，然后进入边向量的输出层，最后得到边的输出。</p><p>如果没有全局向量，则可以把所有的顶点向量加起来得到一个全局向量，并进入全局的输出层得到全局的输出。</p><p>因此最简单的GNN为如下的结构：给定输入的图，进入一系列的GNN层，每个层有三个MLP对应三种不同的属性。最后输出得到保持整个图结构的输出，但里面所有的属性发生了变化，而根据要对哪个属性做预测则添加合适的输出层，如果有信息缺失的话则加入合适的汇聚层即可。这样就可以完成一个简单的预测。</p><p><img src="/img/GNN3.png" alt=""></p><p>然而这种方式有所欠缺，因为将三种属性割裂开，并不能有效地融合和利用整个图的信息，顶点与边分开单独计算。因此需要一种其它方式。</p><h3 id="信息传递"><a href="#信息传递" class="headerlink" title="信息传递"></a>信息传递</h3><p>在顶点输入MLP时，不再只是单纯输入顶点向量，而是采用将顶点向量与此顶点连接的顶点的向量相加组成的向量输入MLP进行顶点的更新，即聚合步与更新步。当叠加很多层，可以实现顶点信息长距离的传递。</p><p>其中顶点周围距离为1的邻居成为1-近邻。上述步骤即$\rho_{V_n \rightarrow V_n}$</p><p><img src="/img/GNN4.png" alt=""></p><h3 id="Learning-edge-representation"><a href="#Learning-edge-representation" class="headerlink" title="Learning edge representation"></a>Learning edge representation</h3><p>对于如何将顶点的信息传递给边，将边的信息传递给顶点，有如下的方式：</p><ul><li><p>首先通过$\rho_{V_n \rightarrow E_n}$将顶点的向量传递给边，若维度不同则进行投影再传递或使用concat将两个向量并在一起。</p></li><li><p>然后再进行$\rho_{E_n \rightarrow V_n}$将边的信息再传递给顶点。</p></li></ul><p>也可以反过来：</p><ul><li><p>先做顶点的更新$\rho_{E_n \rightarrow V_n}$</p></li><li><p>再做边的更新$\rho_{V_n \rightarrow E_n}$</p></li></ul><p>以上两种方法会出现不同的结果，且没有孰优孰劣之分。此外还可以进行交替更新。</p><p><img src="/img/GNN5.png" alt=""></p><h3 id="Adding-global-representations"><a href="#Adding-global-representations" class="headerlink" title="Adding global representations"></a>Adding global representations</h3><p><em>全局信息的更新</em></p><p>可以增加一个虚拟的顶点，称为<strong>master node</strong>或<strong>context vector</strong>，这个顶点与所有的V和E里面的内容均相连。当把顶点的信息汇聚给边的时候，会把U的信息也汇聚过来；当汇聚顶点时，也会把U汇聚过来；当汇聚U的时候，会把顶点和边的信息一起汇聚到U上，再做更新。</p><p><img src="/img/GNN6.png" alt=""></p><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>GNN对超参数较为敏感，通常参数有四种：网络有多少层，每个属性的嵌入（embedding）维度有多高，汇聚（pooling）的操作是什么类型（最大值、均值等），怎么做信息传递（是否做信息传递，哪些属性之间做信息传递）。</p><h2 id="相关技术"><a href="#相关技术" class="headerlink" title="相关技术"></a>相关技术</h2><h3 id="采样（batching）"><a href="#采样（batching）" class="headerlink" title="采样（batching）"></a>采样（batching）</h3><p>如果对整个图进行计算，可能最终中间结果会非常大，因而要进行采样。常见的采样方法如下：</p><ol><li>随机采样一些点，将这些点点最近的邻居找出来，在计算时在这个子图上进行计算；</li><li>随机游走：随机在图上找一条边，沿着这条边走到下一个节点，沿着这个图随机走，规定最多随机走多少步，从而得到一个子图；</li><li>结合上面两种，随机走三步，然后把这三步中的每个邻居的节点全部找出来；</li><li>随机选一个点，找出第1近邻，2近邻…k近邻，即做宽度遍历得到子图。</li></ol><h3 id="Inductive-bias"><a href="#Inductive-bias" class="headerlink" title="Inductive bias"></a>Inductive bias</h3><p>此模型假设了在神经网络中保持了图的对称性。</p><h3 id="汇聚操作的比较"><a href="#汇聚操作的比较" class="headerlink" title="汇聚操作的比较"></a>汇聚操作的比较</h3><p>汇聚操作可以求和、求平均、求最大值，然而并没有哪种特别理想。</p><hr><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://distill.pub/2021/gnn-intro/">Sanchez-Lengeling, et al., “A Gentle Introduction to Graph Neural Networks”, Distill, 2021.</a></li><li><a href="https://www.bilibili.com/video/BV1iT4y1d7zP">零基础多图详解图神经网络</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
          <category> GNN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
            <tag> GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS224W | Machine Learning with Graphs</title>
      <link href="/posts/c6b8d3b6.html"/>
      <url>/posts/c6b8d3b6.html</url>
      
        <content type="html"><![CDATA[<h2 id="传统基于特征的方法｜Traditional-Feature-base-Methods"><a href="#传统基于特征的方法｜Traditional-Feature-base-Methods" class="headerlink" title="传统基于特征的方法｜Traditional Feature-base Methods"></a>传统基于特征的方法｜Traditional Feature-base Methods</h2><h3 id="节点中心性｜Node-Centrality"><a href="#节点中心性｜Node-Centrality" class="headerlink" title="节点中心性｜Node Centrality"></a>节点中心性｜Node Centrality</h3><h4 id="特征向量中心度｜Eigenvector-centrality"><a href="#特征向量中心度｜Eigenvector-centrality" class="headerlink" title="特征向量中心度｜Eigenvector centrality"></a>特征向量中心度｜Eigenvector centrality</h4><p>衡量节点重要性的一种中心性指标，不仅考虑节点的直接连接数量，还考虑其相邻节点的重要性。特征向量中心性通过计算图的邻接矩阵的主导特征向量（最大特征值对应的特征向量）来确定，每个节点的中心性得分与其邻居的得分成正比。这种方法可用于识别网络中影响力较大的节点，如社交网络中的关键人物或传播网络中的核心节点。</p><p>思想：对于节点v，如果v被重要的邻居节点$u\in N(v)$包围，那么这个节点就相对重要</p><script type="math/tex; mode=display">c_v = \frac{1}{\lambda} \sum_{u \in N(v)}c_u \longleftrightarrow \lambda \mathbf{c} = \mathbf{Ac}</script><p>其中：</p><ul><li>$\lambda$是某个正常量</li><li>A是邻接矩阵，且若$u\in N(v), A_{uv} = 1$</li><li>c为中心性向量(Centrality vector)</li></ul><p>最大的特征值$\lambda_{max}$总是正数且唯一</p><p>主导特征向量 $C_max$用于衡量图的中心性。</p><h4 id="中介中心性｜Betweenness-Centrality"><a href="#中介中心性｜Betweenness-Centrality" class="headerlink" title="中介中心性｜Betweenness Centrality"></a>中介中心性｜Betweenness Centrality</h4><p>衡量一个节点在图中充当其他节点之间“桥梁”作用的程度。具体而言，它表示该节点出现在所有最短路径中的频率，数值越高，说明该节点在信息传递或网络流动中的重要性越大。</p><p>思想：如果许多的最短路径都经过这个节点，那么这个节点就相对重要</p><p>公式具体如下：</p><script type="math/tex; mode=display">c_v = \sum_{s\neq v \neq t}\frac{在s和t之间包含节点v的最短路径数}{在s和t中的最短路径数}</script><h4 id="接近中心性｜Closeness-Centrality"><a href="#接近中心性｜Closeness-Centrality" class="headerlink" title="接近中心性｜Closeness Centrality"></a>接近中心性｜Closeness Centrality</h4><p>衡量一个节点与图中所有其他节点的平均最短路径距离的倒数。数值越高，表示该节点更容易接触到图中的其他节点，信息传播效率更高，通常用于评估节点在网络中的传播能力。</p><p>思想：如果一个节点到所有的节点的距离最小，那么这个节点相对重要</p><p>公式如下：</p><script type="math/tex; mode=display">c_v = \frac{1}{\sum_{u\neq v}u和v之间最短路径的长度}</script><h4 id="聚类系数｜Clustering-Coefficient"><a href="#聚类系数｜Clustering-Coefficient" class="headerlink" title="聚类系数｜Clustering Coefficient"></a>聚类系数｜Clustering Coefficient</h4><p>针对单个节点，定义为该节点的邻居之间实际存在的边数与可能存在的最大边数之比</p><p>公式：</p><script type="math/tex; mode=display">e_v = \frac{v节点的邻居节点之间的边数}{C_{k_v}^{2}}</script><p>其中，分母表示节点v的邻居节点两两相连得到的边数。</p><h4 id="图元频率向量｜Graphlet-Degree-Vector"><a href="#图元频率向量｜Graphlet-Degree-Vector" class="headerlink" title="图元频率向量｜Graphlet Degree Vector"></a>图元频率向量｜Graphlet Degree Vector</h4><h5 id="图元"><a href="#图元" class="headerlink" title="图元"></a>图元</h5><p>图元（Graphlets）：指小规模的、无方向或有方向的连通子图，通常用于分析复杂网络的局部结构。图元可以帮助识别网络的模式、节点的结构角色，并用于特征提取、网络比较和生物网络分析。</p><ul><li>度数计算的是节点接触多少条边</li><li>聚类系数计算的是节点接触多少个三角形</li><li>GDV计算的是节点接触多少个图元</li></ul><h5 id="图元度向量的作用"><a href="#图元度向量的作用" class="headerlink" title="图元度向量的作用"></a>图元度向量的作用</h5><p>考虑由2到5个节点组成的图元时：</p><ul><li>通过分析2到5个节点的所有可能连通子图，构建一个包含73维度的向量，该向量被视为节点的特征签名，用于描述其局部拓扑结构。</li><li>该向量不仅考虑节点的直接邻居，还能捕捉其在最多4跳范围内的互连关系</li><li>图元度向量提供了比单纯的节点度（Degree）或聚类系数（Clustering Coefficient）更丰富的结构信息</li></ul><h3 id="链接级预测任务｜Link-Level-Prediction-Task"><a href="#链接级预测任务｜Link-Level-Prediction-Task" class="headerlink" title="链接级预测任务｜Link-Level Prediction Task"></a>链接级预测任务｜Link-Level Prediction Task</h3><p>在此任务中，是基于现有的链接预测新的链接。在测试阶段，对所有的未连接节点对进行排序，并且预测最高的K个节点对。<strong>关键是设计一对节点的特征</strong>。</p><p>两种链接预测的形式：</p><ul><li>随机链接缺失边：随机移除一些链接，并且尝试去预测它们</li><li>随时间进行链接：<ul><li>对于给定的图$G[t_0,t_0’]$，图的边在时间$t_0’$之前，需要产生一个对在原图中不存在的链接的排序的表，其中这些链接是被预测在$G[t_1,t_1’]$中出现</li><li>评估：<ul><li>$n=|E_{new}|$：在测试阶段$[t_1,t_1’]$新出现的边</li><li>取出L中前n个元素并且计算正确的边数</li></ul></li></ul></li></ul><h4 id="通过相似性的链接预测"><a href="#通过相似性的链接预测" class="headerlink" title="通过相似性的链接预测"></a>通过相似性的链接预测</h4><p>方法：</p><ol><li>对于每一对节点$(x,y)$，计算相似性分数$c(x,y)$<ul><li>例如，可以计算相同的邻居数目</li></ul></li><li>按照相似性分数降序排列节点对</li><li>预测分数最高的n对作为新的链接</li><li>查看这些链接中哪些真实存在于图$G[t_1,t_1’]$中</li></ol><h4 id="基于距离的特征｜Distance-Based-Features"><a href="#基于距离的特征｜Distance-Based-Features" class="headerlink" title="基于距离的特征｜Distance-Based Features"></a>基于距离的特征｜Distance-Based Features</h4><p>使用两个节点之间最短路径的长度</p><p>缺陷：不能捕获领域重叠的信息</p><h4 id="局部邻域重叠｜Local-Neighborhood-Overlap"><a href="#局部邻域重叠｜Local-Neighborhood-Overlap" class="headerlink" title="局部邻域重叠｜Local Neighborhood Overlap"></a>局部邻域重叠｜Local Neighborhood Overlap</h4><p>捕获两个节点$v_1,v_2$之间共享的邻居节点</p><ul><li>Common neighbors: $|N(v_1)\cap N(v_2)|$</li><li>Jaccard’s coefficient: $\frac{|N(v_1)\cap N(v_2)|}{|N(v_1)\cup N(v_2)|}$</li><li>Adamic-Adar index: $\sum_{u\in N(v_1)\cap N(v_2)}\frac{1}{log(k_u)}, k_u: degrees\quad of\quad node\quad u$</li></ul><p>缺陷：当两个节点没有任何公共邻居时总为0，但是这两个节点在未来仍有可能被链接</p><h4 id="全局邻域重叠｜Global-Neighborhood-Overlap"><a href="#全局邻域重叠｜Global-Neighborhood-Overlap" class="headerlink" title="全局邻域重叠｜Global Neighborhood Overlap"></a>全局邻域重叠｜Global Neighborhood Overlap</h4><p>Katz index：计算一个给定的节点对中所有长度的路径的数目</p><p>方法：<strong>使用邻接矩阵的幂可以计算各种长度的路径数</strong></p><ul><li>$A_{uv}$表示节点u和v之间长度为1的路径</li><li>$A_{uv}^{l}$表示节点u和v之间长度为l的路径</li></ul><p>对于$v_1,v_2$的Katz index计算如下：</p><script type="math/tex; mode=display">S_{v_1v_2} = \sum_{l=1}^{\infty}\beta^{l}A_{v_1v_2}^{l}, 0<\beta<1:discount\quad factor</script><p>Katz index矩阵闭式计算：</p><script type="math/tex; mode=display">\mathbf{S} = \sum_{i=1}^{\infty}\beta^i\mathbf{A}^i = (\mathbf{I} - \beta\mathbf{A})^{-1}-\mathbf{I}</script><h3 id="图级别的特征｜Graph-Level-Features"><a href="#图级别的特征｜Graph-Level-Features" class="headerlink" title="图级别的特征｜Graph-Level Features"></a>图级别的特征｜Graph-Level Features</h3><h4 id="背景：核方法｜Kernel-Methods"><a href="#背景：核方法｜Kernel-Methods" class="headerlink" title="背景：核方法｜Kernel Methods"></a>背景：核方法｜Kernel Methods</h4><p>核方法被广泛应用于传统机器学习中的图级别预测任务。</p><p>核心思想: 设计核函数而非特征向量</p><ul><li>核函数$K(G, G’)\in R$衡量数据之间的相似性</li><li>核矩阵$K=(K(G, G’))_{G,G’}$必须始终保持半正定(即具有非负特征值)</li><li>存在特征表示$\Phi(·)$使得$K(G,G’)=\Phi(G)^T\Phi(G’)$</li><li>一旦定义好核函数，就可以直接使用现成的机器学习模型(如核支持向量机)进行预测</li></ul><h4 id="图核｜Graph-Kernels"><a href="#图核｜Graph-Kernels" class="headerlink" title="图核｜Graph Kernels"></a>图核｜Graph Kernels</h4><p>核心思想是设计核函数来衡量图之间的相似性，而不是直接使用特征向量。图核方法允许在不显式构造高维特征向量的情况下，利用核函数将图映射到一个高维特征空间，并应用标准的机器学习模型（如支持向量机 SVM）进行预测。</p><ul><li><a href="#图元核graphlet-kernel">Graphlet Kernel</a></li><li><a href="#weisfeiler-lehman-kernel">Weisfeiler-Lehman Kernel</a></li><li>Random-walk kernel</li><li>Shortest-path graph kernel</li></ul><h4 id="词袋｜Bag-of-Words"><a href="#词袋｜Bag-of-Words" class="headerlink" title="词袋｜Bag-of-Words"></a>词袋｜Bag-of-Words</h4><p>为图设计特征向量$\phi (G)$，一种方法就是设计词袋（Bag-of-Words，BoW）。</p><p>词袋（BoW）：对于文本，直接对出现的单词进行计数并作为其特征，其中并没有考虑顺序的因素。</p><p>对于拓展到图上的朴素的思想就是将节点视作单词。</p><p>e.g.对于向量[1, 4, 0]，可以表示为度为1，2，3的节点分别有1，4，0个。</p><h4 id="图元核｜Graphlet-Kernel"><a href="#图元核｜Graphlet-Kernel" class="headerlink" title="图元核｜Graphlet Kernel"></a>图元核｜Graphlet Kernel</h4><p>核心思想：计算在图中的不同图元的数目，将得到的特征向量记为$\mathbf{f}_G$</p><p>对给定的图$G$，以及一个图元表</p><script type="math/tex; mode=display">G_{k}=(g_{1}, g_{2},...,g_{n_k})</script><p>我们将图元计数得到的向量$\mathbf{f}_{G}\in R^{n_k}$定义为</p><script type="math/tex; mode=display">(\mathbf{f}_G)_i = (g_i \subseteq G),i = 1,2,...,n_k</script><p>对于给定的两个图G,G’，图元核可以通过以下的方式进行计算：</p><script type="math/tex; mode=display">K(G,G') = \mathbf{f}_{G}^{T}\mathbf{f}_{G'}</script><p><strong>问题：</strong>如果G和G’拥有不同的大小，那么值将会有偏移</p><p><strong>解决方法：</strong>将每个特征向量进行归一化</p><script type="math/tex; mode=display">\mathbf{h}_{G} = \frac{\mathbf{f}_{G}}{Sum(\mathbf{f}_{G})}</script><script type="math/tex; mode=display">K(G, G') = \mathbf{h}_{G}^{T}\mathbf{h}_{G'}</script><p><strong>缺陷：</strong>计算图元开销很大。对于计算一个大小为n的图中大小为k的图元，使用枚举法需要$n^k$次。计算某图是否是另一个图的子图是NP难问题。但对于节点度数上限为$d$的图，计算大小为k的图元数目，现在存在一个$O(nd^{k-1})$的算法。</p><h4 id="Weisfeiler-Lehman-Kernel"><a href="#Weisfeiler-Lehman-Kernel" class="headerlink" title="Weisfeiler-Lehman Kernel"></a>Weisfeiler-Lehman Kernel</h4><p>思想：使用领域的结构来丰富节点的表示。</p><p>从Bag of node degrees提取出的信息是1-邻域的信息，使用算法Color refinement可以提取多领域信息。</p><h5 id="颜色细化｜Color-Refinement"><a href="#颜色细化｜Color-Refinement" class="headerlink" title="颜色细化｜Color Refinement"></a>颜色细化｜Color Refinement</h5><p>输入：图G和节点集合V</p><ul><li>对于每个节点v，给定一个初试颜色$c^{(0)}(v)$</li><li>通过以下公式迭代更新节点颜色，其中HASH将不同的输入映射到不同颜色：</li></ul><script type="math/tex; mode=display">c^{(k+1)}(v) = HASH(\{c^{(k)}(v),\{c^{(k)}(u)\}_{u\in N(v)}\})</script><ul><li>通过K步颜色更新，$c^{K}(v)$将提取出K邻域的结构信息</li></ul><h5 id="WL-Kernel的优势"><a href="#WL-Kernel的优势" class="headerlink" title="WL Kernel的优势"></a>WL Kernel的优势</h5><p>WL kernel计算效率很高，因为每次更新的时间复杂度都是线性的。而计算核值的时候，只有同时出现在两个图中的颜色才会被追踪。因此，颜色数目最多不会超过节点数目。计算颜色的数目的时间复杂度为线性的。因此，总的时间复杂度为线性的。</p><h2 id="节点嵌入｜Node-Embedding"><a href="#节点嵌入｜Node-Embedding" class="headerlink" title="节点嵌入｜Node Embedding"></a>节点嵌入｜Node Embedding</h2><p>假设目前拥有一个图$G$，其中</p><ul><li>$V$是节点集</li><li>$A$是邻接矩阵（假设为0-1邻接矩阵）</li><li>为了简便起见，假设没有节点信息和额外信息</li><li>假设是无向图</li></ul><p>目标：在原始网络中的相似性<script type="math/tex">similarity(u, v)\approx\mathbf{z_{v}^{T}z_{u}}</script></p><p>节点嵌入学习：</p><ol><li>编码器将节点映射为嵌入</li><li>定义节点相似性函数（例如用于衡量原始网络中的相似性）</li><li>解码器DEC将嵌入映射为相似性分数</li><li>优化编码器的参数使得<script type="math/tex">similarity(u, v)\approx\mathbf{z_{v}^{T}z_{u}}</script></li></ol><h3 id="编码器｜Encoder"><a href="#编码器｜Encoder" class="headerlink" title="编码器｜Encoder"></a>编码器｜Encoder</h3><p>将每个节点映射到一个低维向量</p><script type="math/tex; mode=display">ENC(v) = \mathbf{z}_v</script><h4 id="最简单的编码"><a href="#最简单的编码" class="headerlink" title="最简单的编码"></a>最简单的编码</h4><p>最简单的编码方法：编码仅为一个嵌入的查找</p><script type="math/tex; mode=display">ENC(v) = \mathbf{z}_{v} = \mathbf{Z}\cdot v</script><script type="math/tex; mode=display">\mathbf{Z}\in R^{d\times |V|}：矩阵，每一列是一个节点嵌入（我们需要学习/优化的目标）</script><script type="math/tex; mode=display">v\in \mathrm{II}^{|V|}：指示向量，在一列中只有0和1，用于指示节点v</script><p>缺陷：参数过多，矩阵大小与节点数成正比。节点数较多的情况下运算很慢。</p><h3 id="相似性函数｜Similarity-function"><a href="#相似性函数｜Similarity-function" class="headerlink" title="相似性函数｜Similarity function"></a>相似性函数｜Similarity function</h3><p>指定在向量空间中的关系如何映射到原始网络中的关系</p><script type="math/tex; mode=display">similarity(u,v)\approx\mathbf{z}_{v}^{T}\mathbf{z}_{u}</script><h3 id="随机游走嵌入｜Random-Walk-Embedding"><a href="#随机游走嵌入｜Random-Walk-Embedding" class="headerlink" title="随机游走嵌入｜Random-Walk Embedding"></a>随机游走嵌入｜Random-Walk Embedding</h3><ol><li>估计使用随机游走策略的决策$R$，从节点$u$出发访问节点$v$的概率</li><li>优化嵌入方式来编码这些随机游走的概率</li></ol><p>优化的特征学习：</p><ul><li>给定图$G=(V,E)$</li><li>目标是学习一个映射$f:u\rightarrow R^{d}: f(u) = z_{u}$</li><li>对数相似性目标：<script type="math/tex; mode=display"> max_{f}\sum_{u\in V}logP(N_{R}(u)|\mathbf{z}_{u}),N_{R}(u)是使用策略R的节点u的一个邻居</script></li></ul><p>对于给定的节点u，我们想要学习在随机游走的邻域$N_{R}(u)$中可预测的节点的特征表示。</p><h4 id="随机游走优化算法"><a href="#随机游走优化算法" class="headerlink" title="随机游走优化算法"></a>随机游走优化算法</h4><ol><li>从每个节点u开始在图中使用随机游走策略R走固定长度的短路径</li><li>对于每个节点u得到可重集合$N_{R}(u)$（记录使用从u开始的随机游走策略访问的节点）</li><li>根据给定节点$u$预测邻域$N_{R}(u)$来优化嵌入</li></ol><p>等价的，优化目标变为</p><script type="math/tex; mode=display">L = \sum_{u\in V}\sum_{v\in N_{R}(u)}-log(P(v|\mathbf{z}_u))</script><p>目标：优化嵌入$z_u$以最大化随机游走的可能性</p><p>使用softmax参数化$P(v|\mathbf{z}_u)$:</p><script type="math/tex; mode=display">P(v|\mathbf{z}_u) = \frac{exp(\mathbf{z}_{u}^{T}\mathbf{z}_{v})}{\sum_{n\in V}exp(\mathbf{z}_{u}^{T}\mathbf{z}_{n})}</script><p>因此，最终的优化的目标为（时间复杂度为$O(|V|^{2})）$：</p><script type="math/tex; mode=display">L = \sum_{u\in V}\sum_{v\in N_{R}(u)}-log(\frac{exp(\mathbf{z}_{u}^{T}\mathbf{z}_{v})}{\sum_{n\in V}exp(\mathbf{z}_{u}^{T}\mathbf{z}_{n})})</script><h4 id="负采样｜Negative-Sampling"><a href="#负采样｜Negative-Sampling" class="headerlink" title="负采样｜Negative Sampling"></a>负采样｜Negative Sampling</h4><p>由于原来需要优化的目标时间复杂度过高，需要对目标进近似，此处采用负采样的方法：</p><script type="math/tex; mode=display">log(\frac{exp(\mathbf{z}_{u}^{T}\mathbf{z}_{v})}{\sum_{n\in V}exp(\mathbf{z}_{u}^{T}\mathbf{z}_{n})}) \\approx log(\sigma(\mathbf{z}_{u}^{T}\mathbf{z}_{v})) - \sum_{i=1}^{k}log(\sigma(\mathbf{z}_{u}^{T}\mathbf{z_{n_{i}}})),n_{i}\sim P_{V}</script><p>在此过程中，对于每个探测随机采样k个负节点</p><p>其中更大的k给出的估计越具有鲁棒性，同时也会在负样例中给出更高的偏移。</p><p>实际中k取5到20。</p><p>优化方法使用<strong>随机梯度下降法</strong>。</p><hr><h2 id="参考文献｜References"><a href="#参考文献｜References" class="headerlink" title="参考文献｜References"></a>参考文献｜References</h2><ol><li>CS224W-Video:<a href="https://www.bilibili.com/video/BV1RZ4y1c7Co">CN</a>,<a href="https://www.youtube.com/watch?v=JAB_plj2rbA">EN</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
          <category> Graph ML </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AI </tag>
            
            <tag> Graph ML </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>软件与工具集 | Fancy Tools</title>
      <link href="/posts/ebcd0e10.html"/>
      <url>/posts/ebcd0e10.html</url>
      
        <content type="html"><![CDATA[<h2 id="跨平台工具"><a href="#跨平台工具" class="headerlink" title="跨平台工具"></a>跨平台工具</h2><h3 id="AI工具"><a href="#AI工具" class="headerlink" title="AI工具"></a>AI工具</h3><h4 id="API中转"><a href="#API中转" class="headerlink" title="API中转"></a>API中转</h4><ol><li><a href="https://cloud.siliconflow.cn/models">SiliconFlow</a>：国产厂商，优势在于没有汇率等影响而相对较便宜，缺点就是不含国外模型厂商的API，当需要使用Claude等在某些场景下表现更好的国外模型时有明显缺陷</li><li><a href="https://openrouter.ai">OpenRouter</a>：国外大模型API中转平台，可免费调用一些比较好的模型，但因为有汇率因素导致部分模型价格对学生等群体来说比较高</li></ol><h4 id="AI工具及模型"><a href="#AI工具及模型" class="headerlink" title="AI工具及模型"></a>AI工具及模型</h4><p><em>写在前面：如果是用于做研究或者是考虑深入某一领域等，国产大模型很多似乎都表现得比较拉垮，因此笔者也懒得去尝试一些模型。就身边的同学等使用体验来看，对于国产大模型，在下文中提到的相对比较高质量，其它的模型甚至BAT的似乎更多的是提供情绪价值，并没有多少辅助工作学习的实际作用。当然，考虑到国产大模型其实免费的偏多，并且可以不依赖镜像站等直接访问，相对来说还是有优势的。因此，如果要深入某一领域，还是需要自行寻找一下比较好的模型，从而达到事半功倍的效果。</em></p><ol><li><a href="https://iflow.cn">心流AI</a>：可用于查找论文，阅读论文（论文翻译）等</li><li><a href="https://ai-bot.cn">AI工具集</a>：比较全的AI工具集，查找一些想要的AI工具在这个平台上都能找到</li><li><a href="https://claude.ai/">Claude</a>：写代码全靠Claude捞😋</li><li><a href="https://chatgpt.com">ChatGPT</a>：通用模型，特殊领域表现并不如其它模型</li><li><a href="https://chat.deepseek.com">DeepSeek</a>：数学推理等比较强，可以作为通用模型，文本处理比较厉害，多模态（如图片识别之类的任务）能力较弱，写代码能力还可以。当然，建议使用深度求索公司直接提供的模型，其它厂商自己训练的模型由于数据集等问题，训练效果良莠不齐。</li><li><a href="https://www.kimi.com">Kimi AI</a>：能力还算可以，可以用于当作通用模型，可用于搜索一些内容，多模态能力比较强</li><li><a href="https://manus.im/app">Manus</a>：校友产品支持一波～～可以进行一些复杂任务</li></ol><p><em>注：当前国产AI对于学术和开发友好的模型，笔者及周围测试下来觉得不错的有DeepSeek R1-0528，Kimi K2，Qwen3 Coder.</em></p><h4 id="AI杂项-前端"><a href="#AI杂项-前端" class="headerlink" title="AI杂项/前端"></a>AI杂项/前端</h4><ol><li><a href="https://github.com/CherryHQ/cherry-studio?tab=readme-ov-file">Cherry Studio</a>：可以集成多种大语言模型的客户端</li></ol><h3 id="计算机学术工具"><a href="#计算机学术工具" class="headerlink" title="计算机学术工具"></a>计算机学术工具</h3><ol><li><a href="https://arxiv.org">arXiv</a>：未发表或已发表的文章均有，可以查找最新的科研进展</li><li><a href="https://dblp.org">dblp</a>：CS论文</li><li><a href="https://scholar.google.com">Google Scholar</a>：各种论文</li><li><a href="https://paperswithcode.com">Paper with code</a>：主要是关于机器学习和数据科学的论文和开源代码</li><li><a href="https://snip.mathpix.com/home">Mathpix</a></li><li><a href="https://simpletex.cn/ai/latex_ocr">Simpleletex</a>：Mathpix的平替</li><li><a href="https://app.diagrams.net">Draw IO</a>：在线绘图工具（流程图等），<a href="https://github.com/jgraph/drawio-desktop/tree/v26.2.15">客户端</a></li><li><a href="https://typora.io">Typora</a>：Markdown编辑器</li><li><a href="https://obsidian.md">Obsidian</a>：类似Markdown Pro，用于整理知识、笔记等内容，同时有助于一些使用Markdown进行博客部署的框架进行博客的快速部署</li><li><a href="https://www.zotero.org">Zotero</a>：文献管理</li></ol><h3 id="服务器等"><a href="#服务器等" class="headerlink" title="服务器等"></a>服务器等</h3><ol><li><a href="https://www.autodl.com/home">AutoDL</a>：深度学习租卡网站</li></ol><h3 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h3><ol><li><a href="https://github.com/Eugeny/tabby">Tabby终端</a>：开源免费的终端</li></ol><h3 id="IDE-编辑器"><a href="#IDE-编辑器" class="headerlink" title="IDE/编辑器"></a>IDE/编辑器</h3><ol><li><a href="https://code.visualstudio.com">VS Code</a></li><li><a href="https://www.jetbrains.com/zh-cn/">Jetbrains全家桶</a></li><li><a href="https://www.cursor.com">Cursor</a>：AI编辑器</li><li><a href="https://kiro.dev">Kiro</a>：AI编辑器，由AWS开发</li></ol><h2 id="macOS"><a href="#macOS" class="headerlink" title="macOS"></a>macOS</h2><h3 id="必推"><a href="#必推" class="headerlink" title="必推"></a>必推</h3><ol><li><a href="https://github.com/Homebrew/brew/releases">HomeBrew</a>：macOS上（或许）最好的软件包管理器</li><li><a href="https://github.com/iina/iina/tree/v1.4.0-beta1">IINA播放器</a>：macOS上较好的播放器</li><li><a href="https://pilotmoon.com/scrollreverser/">Scroll Reverser</a>：macOS上鼠标滚轮反向，不使用鼠标则无需使用，<a href="https://github.com/pilotmoon/Scroll-Reverser">源码</a></li><li><a href="https://iterm2.com">iTerm2</a>：macOS上最好的终端（认真）。之前用过一段时间Tabby，但后来改用iTerm2后才知道有多强。配置方法直接参照知乎上的大佬配置就行了，<a href="https://zhuanlan.zhihu.com/p/550022490">文章链接</a>。</li></ol><h3 id="开发"><a href="#开发" class="headerlink" title="开发"></a>开发</h3><ol><li><a href="https://developer.apple.com/xcode/">XCode</a>：macOS上的开发工具，iOS开发必备</li><li><a href="https://github.com/nicklockwood/SwiftFormat">SwiftFormat for Xcode</a>：Swift代码格式化工具</li><li><a href="https://apps.apple.com/us/app/devcleaner-for-xcode/id1388020431">DevCleaner</a>：macOS上的垃圾清理工具</li><li><a href="https://github.com/github/copilot-extension">Github Copilot for Xcode</a>：Xcode上的Github Copilot插件，虽然不是很好用，但是能用就行</li></ol><h3 id="系统工具-杂项"><a href="#系统工具-杂项" class="headerlink" title="系统工具/杂项"></a>系统工具/杂项</h3><p>得益于Mac强大的社区，我们总是可以找到一些很有意思的工具或者是插件。此部分很多东西都来源于Github，在此也需要感谢每一位无私用心付出的开源社区作者。</p><ol><li><a href="https://www.parallels.cn/products/desktop/">Parallels Desktop</a>：macOS上的虚拟机，可以运行Windows，还有很多附加的工具，虽然不是很好用，但是也还算可以</li><li><a href="https://apps.apple.com/us/app/hidden-bar/id1452453066">Hidden Bar</a>：macOS上隐藏菜单栏的工具</li><li><a href="https://cleanmymac.com">CleanMyMac</a>：macOS上的垃圾清理工具，很贵但很好用</li><li><a href="https://www.macbartender.com">Bartender</a>：和Hidden Bar类似，但是功能更加强大，可以隐藏菜单栏，Dock栏，Finder栏等，但是很贵</li><li><a href="https://theunarchiver.com">The Unarchiver</a>：macOS自带解压，但对于一些除了zip之外其它的压缩包格式并不支持，而这个软件支持几乎所有压缩包格式的解压，而且免费</li><li><a href="https://theboring.name">boringNotch</a>：没什么比较大的实际用处，只是将MacBook上的摄像头的一部分变为和iPhone一样的灵动岛，装饰使用</li><li><a href="https://icemenubar.app">IceMenubar</a>：和Hidden Bar类似，开源，免费，功能强大，比较好用</li><li><a href="https://apps.apple.com/cn/app/amphetamine/id937984704?mt=12">Amphetamine</a>：用于设置防止系统睡眠，适合开发、编译、进行深度学习等需要不熄屏的场景，并且可以个性化设置，无需将整个系统设置为不熄屏</li><li><a href="https://www.keka.io/en/">Keka</a>：Mac上最强大的压缩软件之一，可以去除Mac自带的系统文件。在官网上可以免费下载，但有条件可以在App Store上购买支持良心作者。</li><li><a href="https://apps.apple.com/us/app/pixelstyle-photo-editor/id1244649277?mt=12">PixelStyle</a>：Mac上比较好的图片编辑软件，相比Adobe Photoshop等的优势就是免费</li><li><a href="https://apps.apple.com/cn/app/irightmenu-右键新建文件菜单/id1542347829?mt=12">iRightMenu</a>：为macOS创造类似于Windows系统的右键菜单</li></ol><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p><del>Windows没有必要推荐工具。</del>笔者太懒了，以后再来写吧。如果一定要推荐，那就推荐WSL吧。</p><ol><li><a href="https://learn.microsoft.com/en-us/windows/wsl/install">WSL文档</a>：<del>不知道放什么，就放个文档链接吧。</del>既想用Linux又想用Windows的用户的福音，同时共享同一个文件系统，当然还可以直接用来做深度学习。</li></ol>]]></content>
      
      
      <categories>
          
          <category> Tools </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Java环境配置</title>
      <link href="/posts/f7539049.html"/>
      <url>/posts/f7539049.html</url>
      
        <content type="html"><![CDATA[<h2 id="MacOS"><a href="#MacOS" class="headerlink" title="MacOS"></a>MacOS</h2><h3 id="使用Homebrew安装JDK"><a href="#使用Homebrew安装JDK" class="headerlink" title="使用Homebrew安装JDK"></a>使用Homebrew安装JDK</h3><ul><li>配置Homebrew</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)&quot;</span><br></pre></td></tr></table></figure><h4 id="安装OpenJDK"><a href="#安装OpenJDK" class="headerlink" title="安装OpenJDK"></a>安装OpenJDK</h4><p>查询jdk版本信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew search jdk</span><br></pre></td></tr></table></figure><p>安装特定版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install openjdk@17</span><br></pre></td></tr></table></figure><h4 id="配置JDK"><a href="#配置JDK" class="headerlink" title="配置JDK"></a>配置JDK</h4><p>注意，运行完以上命令后，终端会出现如下的信息：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">For the system Java wrappers to find this JDK, symlink it with</span><br><span class="line">  sudo ln -sfn /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-17.jdk</span><br><span class="line"></span><br><span class="line">openjdk@17 is keg-only, which means it was not symlinked into /opt/homebrew,</span><br><span class="line">because this is an alternate version of another formula.</span><br><span class="line"></span><br><span class="line">If you need to have openjdk@17 first in your PATH, run:</span><br><span class="line">  echo &#x27;export PATH=&quot;/opt/homebrew/opt/openjdk@17/bin:$PATH&quot;&#x27; &gt;&gt; ~/.zshrc</span><br><span class="line"></span><br><span class="line">For compilers to find openjdk@17 you may need to set:</span><br><span class="line">  export CPPFLAGS=&quot;-I/opt/homebrew/opt/openjdk@17/include&quot;</span><br><span class="line">==&gt; Summary</span><br><span class="line">🍺  /opt/homebrew/Cellar/openjdk@17/17.0.14: 636 files, 304.3MB</span><br><span class="line">==&gt; Running `brew cleanup openjdk@17`...</span><br><span class="line">Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.</span><br><span class="line">Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).</span><br></pre></td></tr></table></figure><p>根据指示，运行相应的命令。首先运行如下命令使得系统可以找到当前下载的JDK：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo ln -sfn /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk /Library/Java/JavaVirtualMachines/openjdk-17.jdk</span><br></pre></td></tr></table></figure><p>可以通过tree命令来检查是否成功。</p><ul><li>若没有安装过tree，则运行以下命令：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install tree</span><br></pre></td></tr></table></figure><p>检查是否成功</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tree /Library/Java</span><br></pre></td></tr></table></figure><h4 id="检查当前JDK以及Java环境"><a href="#检查当前JDK以及Java环境" class="headerlink" title="检查当前JDK以及Java环境"></a>检查当前JDK以及Java环境</h4><p>执行以下命令可以查看当前系统使用的JDK版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/libexec/java_home</span><br></pre></td></tr></table></figure><p>执行以下命令可查看当前系统使用的Java版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java --version</span><br></pre></td></tr></table></figure><h4 id="多版本JDK管理"><a href="#多版本JDK管理" class="headerlink" title="多版本JDK管理"></a>多版本JDK管理</h4><p>先要查找到JDK的地址，采用如下的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/libexec/java_home -V</span><br></pre></td></tr></table></figure><p>若没有建过.bash_profile文件，则在根目录下建此配置文件，并打开此配置文件。如已经有，则添加即可。其中地址均使用上面命令查找出来的地址。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#配置JDK路径</span><br><span class="line">export JAVA_11_HOME=/Library/Java/JavaVirtualMachines/jdk-11.jdk/Contents/Home</span><br><span class="line">export JAVA_17_HOME=/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home</span><br><span class="line"> </span><br><span class="line"># 设置默认JDK版本，默认使用 JDK17</span><br><span class="line">export JAVA_HOME=$JAVA_17_HOME</span><br><span class="line">CLASSPATH=$JAVA_HOME/lib/tools.jar:$JAVA_HOME/lib/dt.jar:.</span><br><span class="line"> </span><br><span class="line"># 配置alias命令动态切换JDK版本  </span><br><span class="line">alias jdk11=&quot;export JAVA_HOME=$JAVA_11_HOME&quot;</span><br><span class="line">alias jdk17=&quot;export JAVA_HOME=$JAVA_17_HOME&quot;</span><br><span class="line"> </span><br><span class="line">export JAVA_HOME</span><br><span class="line">export CLASSPATH</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>若嫌麻烦可以跳过查看地址那一步，直接在上述.bash_profile中编辑：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=$(/usr/libexec/java_home -v11)</span><br><span class="line">export JAVA_8_HOME=$(/usr/libexec/java_home -v1.8)</span><br><span class="line">export JAVA_11_HOME=$(/usr/libexec/java_home -v11)</span><br><span class="line"></span><br><span class="line">alias java8=&#x27;export JAVA_HOME=$JAVA_8_HOME&#x27;</span><br><span class="line">alias java11=&#x27;export JAVA_HOME=$JAVA_11_HOME&#x27;</span><br></pre></td></tr></table></figure><p>保存配置文件，在终端中输出如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source .bash_profile</span><br></pre></td></tr></table></figure><p>可以通过如下命令查看是否配置成功：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME</span><br></pre></td></tr></table></figure><h4 id="JDK版本切换"><a href="#JDK版本切换" class="headerlink" title="JDK版本切换"></a>JDK版本切换</h4><p>在终端中输入命令：jdk/java版本号 即可，如</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdk17</span><br></pre></td></tr></table></figure><p>或</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java17</span><br></pre></td></tr></table></figure><p>注意看清楚编辑时alias后面的命令到底是jdk还是java</p><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><h3 id="下载并安装JDK"><a href="#下载并安装JDK" class="headerlink" title="下载并安装JDK"></a>下载并安装JDK</h3><p>上<a href="https://www.oracle.com/java/technologies/downloads/?er=221886">官网</a>下载所需的JDK，运行相应的安装程序即可完成安装。若从未注册过账号，需要在官网注册账号后才能下载。</p><h3 id="配置环境变量"><a href="#配置环境变量" class="headerlink" title="配置环境变量"></a>配置环境变量</h3><p>将以上的JDK目录，在系统变量中，配置为<strong>JAVA_HOME</strong>，路径为JDK路径，如：C:\Program Files\Java\jdk1.8.0_191。</p><p>然后，在Path中添加两个路径，分别为</p><ul><li><p><strong>%JAVA_HOME%\bin</strong></p></li><li><p><strong>%JAVA_HOME%\jre\bin</strong></p></li></ul><p>此外，还需要配置<strong>CLASSPATH</strong>变量。若本来存在这个变量，则进行编辑，若无则新建。变量值为</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;</span><br></pre></td></tr></table></figure><p>可以通过以下命令来检查是否安装成功：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java</span><br></pre></td></tr></table></figure><h2 id="Java运行"><a href="#Java运行" class="headerlink" title="Java运行"></a>Java运行</h2><p>最方便和最简单的当然是直接拿IDEA一键运行啦，当然稍微麻烦点的就是配置VSCode。但如果除去这两个，就需要依靠运行脚本来运行Java程序了。</p><p>下面将展示脚本编写示例。</p><h3 id="Windows脚本"><a href="#Windows脚本" class="headerlink" title="Windows脚本"></a>Windows脚本</h3><p>在当前工程目录下，创建run.bat脚本文件（文件名是什么随便起就行，不一定要为run.bat）。假设我们的工程目录是如下的情况，我们可以在脚本文件中对应编辑如下内容：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">JavaDemo</span><br><span class="line">├── .idea</span><br><span class="line">├── bin</span><br><span class="line">│   └── production</span><br><span class="line">│       └── JavaDemo</span><br><span class="line">│           └── hust</span><br><span class="line">│               └── cs</span><br><span class="line">│                   └── javacourse</span><br><span class="line">│                       └── ch1</span><br><span class="line">│                           └── HelloWorld.class</span><br><span class="line">├── src</span><br><span class="line">│   └── hust.cs.javacourse.ch1</span><br><span class="line">│       └── HelloWorld.java</span><br><span class="line">└── JavaDemo.iml</span><br></pre></td></tr></table></figure><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">set</span> JAVA_HOME=D:\jdk1.<span class="number">8</span>.<span class="number">0</span>_231_64bit</span><br><span class="line"><span class="built_in">set</span> PROJECT_HOME=D:\IdeaWorkspace\JavaDemo</span><br><span class="line"><span class="built_in">set</span> <span class="built_in">path</span>=<span class="variable">%path%</span>;<span class="variable">%JAVA_HOME%</span>\bin</span><br><span class="line"><span class="built_in">set</span> classpath=<span class="variable">%classpath%</span>;<span class="variable">%PROJECT_HOME%</span>\bin\production\JavaDemo</span><br><span class="line"></span><br><span class="line">java -classpath <span class="variable">%classpath%</span> hust.cs.javacourse.ch1.HelloWorld</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li><p>JAVA_HOME设置JAVA_HOME环境变量</p></li><li><p>PROJECT_HOME设置PROJECT_HOME环境变量</p></li><li><p>path设置把JAVA_HOME目录的子目录bin加到环境变量PATH</p></li><li><p>classpath把PROJECT_HOME目录的子目录bin\production\JavaDemo加到环境变量CLASSPATH，这个目录是类HelloWorld所属包的顶级目录</p></li><li><p>最后一行为运行指令，启动类时，用类的完全限定名（带包名限定），并且带-classspath选项</p></li></ul><p>运行时直接命令行输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./run.bat</span><br></pre></td></tr></table></figure><hr><p>参考资料：</p><ol><li><p><a href="https://blog.csdn.net/Jarvs/article/details/134669580">Mac JDK环境变量配置 及 JDK多版本切换</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/298535991">新 Mac 如何优雅地配置 Java 开发环境</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> Env </category>
          
          <category> Programming Language </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Env </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello Hexo</title>
      <link href="/posts/4a17b156.html"/>
      <url>/posts/4a17b156.html</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><h2 id="More"><a href="#More" class="headerlink" title="More"></a>More</h2><p>可以参考安知鱼的<a href="https://blog.anheyu.com/posts/sdxhu.html#配置自定义-css">博客</a>和<a href="https://www.bilibili.com/video/BV1CG41157fr?spm_id_from=333.788.player.switch&amp;vd_source=2e36fae16810615c2d859efc03aef1c4">Bilibili</a></p>]]></content>
      
      
      <categories>
          
          <category> 本站搭建 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title></title>
      <link href="/google7e7b55ce6b603fc5.html"/>
      <url>/google7e7b55ce6b603fc5.html</url>
      
        <content type="html"><![CDATA[google-site-verification: google7e7b55ce6b603fc5.html]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/manifest.json"/>
      <url>/manifest.json</url>
      
        <content type="html"><![CDATA[{"name":"EpsilonZ `Blog","short_name":"EpsilonZ","theme_color":"#3b70fc","background_color":"#3b70fc","display":"standalone","scope":"/","start_url":"/","icons":[{"src":"/img/siteicon/16.png","sizes":"16x16","type":"image/png"},{"src":"/img/siteicon/32.png","sizes":"32x32","type":"image/png"},{"src":"/img/siteicon/48.png","sizes":"48x48","type":"image/png"},{"src":"/img/siteicon/64.png","sizes":"64x64","type":"image/png"},{"src":"/img/siteicon/128.png","sizes":"128x128","type":"image/png"},{"src":"/img/siteicon/144.png","sizes":"144x144","type":"image/png"},{"src":"/img/siteicon/512.png","sizes":"512x512","type":"image/png"}],"splash_pages":null}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>简 介 ｜ Who am I</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h2 id="关于我-｜-About-me"><a href="#关于我-｜-About-me" class="headerlink" title="关于我 ｜ About me"></a>关于我 ｜ About me</h2><p>目前就读于华中科技大学计算机科学与技术学院，喜欢的方向很杂，做做机器学习，偶尔也做做系统。</p><p>I am currently an undergraduate student in Huazhong University of Science and Technology, majoring in computer science and technology. I am interested in various fields, including machine learning and computer system, especially in deep learning.</p><hr><h2 id="兴趣领域-｜-Interests"><a href="#兴趣领域-｜-Interests" class="headerlink" title="兴趣领域 ｜ Interests"></a>兴趣领域 ｜ Interests</h2><p>当下研究方向为图神经网络，同时也做AI4Science，并应用图神经网络。空余时间会进行基于Swift的iOS应用开发。</p><p>I am now studying about Graph Neural Network, in detail GNN with Transformer. Besides, I also try AI for Science, where GNN can be widely applied.</p><hr><h2 id="项目-｜-Projects"><a href="#项目-｜-Projects" class="headerlink" title="项目 ｜ Projects"></a>项目 ｜ Projects</h2><ul><li><p>AI辅助新材料的发现(GNN, ReactJS, AI4Science)</p><ul><li>使用<strong>图神经网络</strong>开发了一个模型，用于辅助新材料的发现</li><li>采用<strong>ReactJS</strong>框架搭建前端，用于输入和可视化等</li><li>创建<strong>分布式相似性检索系统</strong>，用于搜索相似的材料分子</li></ul></li><li><p>AI-Assisted New Material Discovery(GNN, ReactJS, AI4Science)</p><ul><li>Develop a model to assist in the discovery of new materials by applying <strong>Graph Neural Network</strong>.</li><li>Develop a web application for the front development, namely, the inputs and visualization of the model with <strong>ReactJS</strong>.</li><li>Create <strong>a distributed similarity search system</strong> of searching for material molecules.</li></ul></li></ul><hr><h2 id="技能-｜-Skills"><a href="#技能-｜-Skills" class="headerlink" title="技能 ｜ Skills"></a>技能 ｜ Skills</h2><ul><li>编程语言：C/C++, Java, SQL, python, Swift, JavaScript</li><li><p>技能标签：深度学习, 机器学习, iOS开发, ReactJS</p></li><li><p>Programming language: C/C++, Java, SQL, python, Swift, JavaScript</p></li><li>Skill tags: Deep Learning, Machine Learning, iOS App Development, ReactJS</li></ul>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类 ｜ Categories</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* @font-face {  font-family: Candyhome;  src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/Candyhome.ttf);  font-display: swap;  font-weight: lighter;} */@font-face {    font-family: ZhuZiAYuanJWD;    src: url(https://npm.elemecdn.com/anzhiyu-blog@1.1.6/fonts/ZhuZiAWan.woff2);    font-display: swap;    font-weight: lighter;}div#menus {    font-family: "ZhuZiAYuanJWD";}h1#site-title {    font-family: ZhuZiAYuanJWD;    font-size: 3em !important;}a.article-title,a.blog-slider__title,a.categoryBar-list-link,h1.post-title {    font-family: ZhuZiAYuanJWD;}.iconfont {    font-family: "iconfont" !important;    font-size: 3em;    /* 可以定义图标大小 */    font-style: normal;    -webkit-font-smoothing: antialiased;    -moz-osx-font-smoothing: grayscale;}/* 时间轴生肖icon */svg.icon {    /* 这里定义svg.icon，避免和Butterfly自带的note标签冲突 */    width: 1em;    height: 1em;    /* width和height定义图标的默认宽度和高度*/    vertical-align: -0.15em;    fill: currentColor;    overflow: hidden;}.icon-zhongbiao::before {    color: #f7c768;}/* bilibli番剧插件 */#article-container .bangumi-tab.bangumi-active {    background: var(--anzhiyu-theme);    color: var(--anzhiyu-ahoverbg);    border-radius: 10px;}a.bangumi-tab:hover {    text-decoration: none !important;}.bangumi-button:hover {    background: var(--anzhiyu-theme) !important;    border-radius: 10px !important;    color: var(--anzhiyu-ahoverbg) !important;}a.bangumi-button.bangumi-nextpage:hover {    text-decoration: none !important;}.bangumi-button {    padding: 5px 10px !important;}a.bangumi-tab {    padding: 5px 10px !important;}svg.icon.faa-tada {    font-size: 1.1em;}.bangumi-info-item {    border-right: 1px solid #f2b94b;}.bangumi-info-item span {    color: #f2b94b;}.bangumi-info-item em {    color: #f2b94b;}/* 解决artitalk的图标问题 */#uploadSource>svg {    width: 1.19em;    height: 1.5em;}/*top-img黑色透明玻璃效果移除，不建议加，除非你执着于完全一图流或者背景图对比色明显 */#page-header:not(.not-top-img):before {    background-color: transparent !important;}/* 首页文章卡片 */#recent-posts>.recent-post-item {    background: rgba(255, 255, 255, 0.9);}/* 首页侧栏卡片 */#aside-content .card-widget {    background: rgba(255, 255, 255, 0.9);}/* 文章页面正文背景 */div#post {    background: rgba(255, 255, 255, 0.9);}/* 分页页面 */div#page {    background: rgba(255, 255, 255, 0.9);}/* 归档页面 */div#archive {    background: rgba(255, 255, 255, 0.9);}/* 标签页面 */div#tag {    background: rgba(255, 255, 255, 0.9);}/* 分类页面 */div#category {    background: rgba(255, 255, 255, 0.9);}/*夜间模式伪类遮罩层透明*/[data-theme="dark"] #recent-posts>.recent-post-item {    background: #121212;}[data-theme="dark"] .card-widget {    background: #121212 !important;}[data-theme="dark"] div#post {    background: #121212 !important;}[data-theme="dark"] div#tag {    background: #121212 !important;}[data-theme="dark"] div#archive {    background: #121212 !important;}[data-theme="dark"] div#page {    background: #121212 !important;}[data-theme="dark"] div#category {    background: #121212 !important;}[data-theme="dark"] div#category {    background: transparent !important;}/* 页脚透明 */#footer {    background: transparent !important;}/* 头图透明 */#page-header {    background: transparent !important;}#rightside>div>button {    border-radius: 5px;}/* 滚动条 */::-webkit-scrollbar {    width: 10px;    height: 10px;}::-webkit-scrollbar-thumb {    background-color: #3b70fc;    border-radius: 2em;}::-webkit-scrollbar-corner {    background-color: transparent;}::-moz-selection {    color: #fff;    background-color: #3b70fc;}/* 音乐播放器 *//* .aplayer .aplayer-lrc {  display: none !important;} */.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {    left: -66px !important;    transition: all 0.3s;    /* 默认情况下缩进左侧66px，只留一点箭头部分 */}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {    left: 0 !important;    transition: all 0.3s;    /* 鼠标悬停是左侧缩进归零，完全显示按钮 */}.aplayer.aplayer-fixed {    z-index: 999999 !important;}/* 评论框  */.vwrap {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 30px 0px;}/* 设置评论框 */.vcard {    box-shadow: 2px 2px 5px #bbb;    background: rgba(255, 255, 255, 0.3);    border-radius: 8px;    padding: 30px;    margin: 30px 0px 0px 0px;}/* md网站下划线 */#article-container a:hover {    text-decoration: none !important;}#article-container #hpp_talk p img {    display: inline;}/* 404页面 */#error-wrap {    position: absolute;    top: 40%;    right: 0;    left: 0;    margin: 0 auto;    padding: 0 1rem;    max-width: 1000px;    transform: translate(0, -50%);}#error-wrap .error-content {    display: flex;    flex-direction: row;    justify-content: center;    align-items: center;    margin: 0 1rem;    height: 18rem;    border-radius: 8px;    background: var(--card-bg);    box-shadow: var(--card-box-shadow);    transition: all 0.3s;}#error-wrap .error-content .error-img {    box-flex: 1;    flex: 1;    height: 100%;    border-top-left-radius: 8px;    border-bottom-left-radius: 8px;    background-color: #3b70fc;    background-position: center;    background-size: cover;}#error-wrap .error-content .error-info {    box-flex: 1;    flex: 1;    padding: 0.5rem;    text-align: center;    font-size: 14px;    font-family: Titillium Web, "PingFang SC", "Hiragino Sans GB", "Microsoft JhengHei", "Microsoft YaHei", sans-serif;}#error-wrap .error-content .error-info .error_title {    margin-top: -4rem;    font-size: 9em;}#error-wrap .error-content .error-info .error_subtitle {    margin-top: -3.5rem;    word-break: break-word;    font-size: 1.6em;}#error-wrap .error-content .error-info a {    display: inline-block;    margin-top: 0.5rem;    padding: 0.3rem 1.5rem;    background: var(--btn-bg);    color: var(--btn-color);}#body-wrap.error .aside-list {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    bottom: 0px;    position: absolute;    padding: 1rem;    width: 100%;    overflow: scroll;}#body-wrap.error .aside-list .aside-list-group {    display: flex;    flex-direction: row;    flex-wrap: nowrap;    max-width: 1200px;    margin: 0 auto;}#body-wrap.error .aside-list .aside-list-item {    padding: 0.5rem;}#body-wrap.error .aside-list .aside-list-item img {    width: 100%;    object-fit: cover;    border-radius: 12px;}#body-wrap.error .aside-list .aside-list-item .thumbnail {    overflow: hidden;    width: 230px;    height: 143px;    background: var(--anzhiyu-card-bg);    display: flex;}#body-wrap.error .aside-list .aside-list-item .content .title {    -webkit-line-clamp: 2;    overflow: hidden;    display: -webkit-box;    -webkit-box-orient: vertical;    line-height: 1.5;    justify-content: center;    align-items: flex-end;    align-content: center;    padding-top: 0.5rem;    color: white;}#body-wrap.error .aside-list .aside-list-item .content time {    display: none;}/* 代码框主题 */#article-container figure.highlight {    border-radius: 10px;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>标签 | Tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>

<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>谱域图神经网络 ｜ Spectral Graph Neural Network | EpsilonZ's Blog</title><meta name="author" content="EpsilonZ"><meta name="copyright" content="EpsilonZ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="谱域图神经网络不同于常见的消息传递图神经网络，采用图信号的傅立叶变换进行拓展，本文则简要介绍何为谱域图神经网络。"><meta property="og:type" content="article"><meta property="og:title" content="谱域图神经网络 ｜ Spectral Graph Neural Network"><meta property="og:url" content="https://epsilonzyj.github.io/posts/3539d4b8.html"><meta property="og:site_name" content="EpsilonZ&#39;s Blog"><meta property="og:description" content="谱域图神经网络不同于常见的消息传递图神经网络，采用图信号的傅立叶变换进行拓展，本文则简要介绍何为谱域图神经网络。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://epsilonzyj.github.io/img/GNNCover.png"><meta property="article:published_time" content="2025-10-08T13:23:35.000Z"><meta property="article:modified_time" content="2025-10-23T12:46:07.252Z"><meta property="article:author" content="EpsilonZ"><meta property="article:tag" content="AI"><meta property="article:tag" content="Graph ML"><meta property="article:tag" content="GNN"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://epsilonzyj.github.io/img/GNNCover.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "谱域图神经网络 ｜ Spectral Graph Neural Network",
  "url": "https://epsilonzyj.github.io/posts/3539d4b8.html",
  "image": "https://epsilonzyj.github.io/img/GNNCover.png",
  "datePublished": "2025-10-08T13:23:35.000Z",
  "dateModified": "2025-10-23T12:46:07.252Z",
  "author": [
    {
      "@type": "Person",
      "name": "EpsilonZ",
      "url": "https://epsilonzyj.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/128.ico"><link rel="canonical" href="https://epsilonzyj.github.io/posts/3539d4b8.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/manifest.json"><meta name="msapplication-TileColor" content="#3b70fc"><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"谱域图神经网络 ｜ Spectral Graph Neural Network",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="EpsilonZ's Blog" type="application/atom+xml"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background-image:url(/img/IMG_3821.jpg)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IMG_2179.JPG" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i> <span>关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/GNNCover.png)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">EpsilonZ's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">谱域图神经网络 ｜ Spectral Graph Neural Network</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i> <span>关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">谱域图神经网络 ｜ Spectral Graph Neural Network</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-08T13:23:35.000Z" title="发表于 2025-10-08 21:23:35">2025-10-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-23T12:46:07.252Z" title="更新于 2025-10-23 20:46:07">2025-10-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Graph-ML/">Graph ML</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Graph-ML/GNN/">GNN</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>19分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="谱域图神经网络简介"><a href="#谱域图神经网络简介" class="headerlink" title="谱域图神经网络简介"></a>谱域图神经网络简介</h1><p>谱域图神经网络（<strong>Spectral Graph Neural Networks</strong>）是一类基于<strong>图谱理论</strong>（Graph Spectral Theory）的图学习方法，通过在图信号的<strong>傅里叶域</strong>定义卷积操作实现特征提取。其核心思想是将传统CNN的频域卷积推广到非欧几里得图结构。</p><hr><h1 id="谱域图神经网络直观理解"><a href="#谱域图神经网络直观理解" class="headerlink" title="谱域图神经网络直观理解"></a>谱域图神经网络直观理解</h1><h2 id="第一步：理解核心目标-给图做”CT扫描”"><a href="#第一步：理解核心目标-给图做”CT扫描”" class="headerlink" title="第一步：理解核心目标 = 给图做”CT扫描”"></a>第一步：理解核心目标 = 给图做”CT扫描”</h2><p>想象医院给人体做CT扫描：</p><ul><li><strong>CT扫描</strong>：把复杂的3D人<strong>分解成不同的频率成分</strong>（X射线穿透不同组织）</li><li><strong>谱GNN</strong>：把复杂的图结构<strong>分解成不同的”振动模式”</strong>（频谱分析）</li></ul><p>核心：把图 <strong>“翻译” 到频域</strong>（frequency domain）来分析内在结构</p><h2 id="第二步：关键工具-图拉普拉斯矩阵"><a href="#第二步：关键工具-图拉普拉斯矩阵" class="headerlink" title="第二步：关键工具 = 图拉普拉斯矩阵"></a>第二步：关键工具 = 图拉普拉斯矩阵</h2><p>这类似于CT扫描仪的核心设备：<br></p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    graph LR
    A[图结构] --&gt;|表示成| B[拉普拉斯矩阵L]
    B --&gt;|特征分解| C[特征向量U和特征值Λ]
  </pre></div><p></p><p><strong>为什么需要这个矩阵？</strong></p><ul><li>定义图的”振动模式”：<ul><li>小特征值 → “缓慢振动”（低频：体现整体结构）</li><li>大特征值 → “剧烈抖动”（高频：体现局部细节）</li></ul></li></ul><p>就像弹簧系统：</p><ul><li>λ=0 → 所有节点一起移动（整体平移）</li><li>λ变大 → 相邻节点反向运动（高频振动）</li></ul><h2 id="第三步：卷积在图上怎么做？-滤波操作"><a href="#第三步：卷积在图上怎么做？-滤波操作" class="headerlink" title="第三步：卷积在图上怎么做？ = 滤波操作"></a>第三步：卷积在图上怎么做？ = 滤波操作</h2><p>在图像处理中：<br></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">原图 → FFT变换到频域 → 应用滤镜（如模糊/锐化） → 逆变换得到结果图</span><br></pre></td></tr></table></figure><p></p><p>在图上完全类似：</p><ol><li><p><strong>图傅里叶变换</strong>：<br>✨ 把节点特征投影到“频谱基座”上</p><script type="math/tex;mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x}</script></li><li><p><strong>应用滤镜</strong>：<br>🧪 <strong>乘上滤镜函数</strong> $g(\lambda)$ 过滤特定频率</p><script type="math/tex;mode=display">\widehat{\mathbf{y}} = g(\lambda) \widehat{\mathbf{x}}</script></li><li><p><strong>逆变换</strong>：<br>📈 <strong>转回原始空间</strong>得到新特征</p><script type="math/tex;mode=display">\mathbf{y} = \mathbf{U} \widehat{\mathbf{y}}</script></li></ol><blockquote><p><strong>滤镜的例子</strong>：</p><ul><li>低通滤波（保留低频）：让相邻节点特征更平滑</li><li>高通滤波（保留高频）：突出节点间的差异</li></ul></blockquote><h2 id="第四步：为什么这么麻烦？实际案例说明"><a href="#第四步：为什么这么麻烦？实际案例说明" class="headerlink" title="第四步：为什么这么麻烦？实际案例说明"></a>第四步：为什么这么麻烦？实际案例说明</h2><p><strong>场景</strong>：识别蛋白质结构中的功能区（节点分类）<br></p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    graph TB
    A[蛋白质结构图] 
    --&gt; B[传统方法只看邻居]
    B --&gt; C[忽略全局，无法区分远端结构]
  
    A --&gt; D[谱方法]
    D --&gt; E[分解出低频分量]
    E --&gt; F[捕捉整个蛋白质螺旋结构]
  </pre></div><p></p><p><strong>频谱分析的优势</strong>：</p><ol><li><strong>全局关联</strong>：低频信号捕获全图结构（如蛋白质骨架）</li><li><strong>噪声免疫</strong>：可过滤掉不重要的高频噪声（如个别原子偏差）</li><li><strong>物理意义</strong>：对应真实系统的振动模式（分子动力学验证）</li></ol><h2 id="第五步：生活中的类比-音乐混音台🎛️"><a href="#第五步：生活中的类比-音乐混音台🎛️" class="headerlink" title="第五步：生活中的类比 - 音乐混音台🎛️"></a>第五步：生活中的类比 - 音乐混音台🎛️</h2><p>想象你是个DJ在调音：</p><ul><li><strong>原始音乐</strong> = 图结构（混合着不同乐器的声音）</li><li><strong>均衡器滑块</strong> = 谱GNN的滤波器（控制高/中/低频）</li><li><strong>混音结果</strong> = GNN的输出（突出人声，弱化鼓声）</li></ul><p>谱GNN就是<strong>图的混音师</strong>：通过调节频带权重，突出重要信息！</p><h2 id="第六步：技术优化的突破-避免数学计算困难"><a href="#第六步：技术优化的突破-避免数学计算困难" class="headerlink" title="第六步：技术优化的突破 = 避免数学计算困难"></a>第六步：技术优化的突破 = 避免数学计算困难</h2><p>早期问题：精确计算特征分解需要 (O(n^3)) 时间（太慢！）</p><p><strong>现代解决方案</strong>：<br></p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    graph LR
    A[切比雪夫多项式] --&gt; B[用K阶逼近代替精确解]
    B --&gt; C[速度提升1000倍]
  </pre></div><p></p><p>公式近似：</p><script type="math/tex;mode=display">g(\lambda) \approx \sum_{k=0}^K \theta_k T_k(\lambda)</script><p>（$T_k$是预设的多项式基函数，$\theta_k$是可学习参数）</p><blockquote><p>比如GCN模型：只用一阶近似就达到很好效果！</p></blockquote><h2 id="第七步：真实代码演示（PyG简化版）"><a href="#第七步：真实代码演示（PyG简化版）" class="headerlink" title="第七步：真实代码演示（PyG简化版）"></a>第七步：真实代码演示（PyG简化版）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建简单图: 3个相互连接的节点</span></span><br><span class="line">x = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])  <span class="comment"># 节点特征 [1,2,3]</span></span><br><span class="line">edge_index = torch.tensor([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>],       <span class="comment"># 边链接：0-1-2</span></span><br><span class="line">                          [<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>]]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立谱GNN（三阶近似）</span></span><br><span class="line">conv = ChebConv(in_channels=<span class="number">1</span>, out_channels=<span class="number">1</span>, K=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播过程等效为：</span></span><br><span class="line"><span class="comment"># 1. 计算拉普拉斯矩阵L</span></span><br><span class="line"><span class="comment"># 2. 用切比雪夫多项式逼近频域操作</span></span><br><span class="line"><span class="comment"># 3. 返回滤波后特征</span></span><br><span class="line">output = conv(x, edge_index) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;输入特征:&quot;</span>, x.flatten())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;谱滤波后:&quot;</span>, output.flatten())</span><br></pre></td></tr></table></figure><p><strong>输出示例</strong>：<br></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">输入特征: [1, 2, 3]</span><br><span class="line">谱滤波后: [0.32, 1.48, 2.78]   # 低频增强后更平滑</span><br></pre></td></tr></table></figure><br>（实践中最常用ChebConv/GCNConv，隐藏了底层频谱计算）<p></p><h2 id="核心总结一句话"><a href="#核心总结一句话" class="headerlink" title="核心总结一句话"></a>核心总结一句话</h2><blockquote><p>谱GNN是在<strong>图的频谱空间</strong>（由拉普拉斯矩阵定义）中进行<strong>滤波操作</strong>的神经网络，<br>就像给图结构做”CT扫描+美颜滤镜”来提取关键特征。</p></blockquote><p><strong>学习建议路径</strong>：</p><ol><li>先理解谱聚类 → 2. 尝试GCN代码 → 3. 研究切比雪夫逼近原理<br>新手推荐库：PyTorch Geometric（封装了复杂数学）</li></ol><hr><h1 id="谱域图神经网络简单理论"><a href="#谱域图神经网络简单理论" class="headerlink" title="谱域图神经网络简单理论"></a>谱域图神经网络简单理论</h1><h2 id="一、核心理论基础：图谱分解"><a href="#一、核心理论基础：图谱分解" class="headerlink" title="一、核心理论基础：图谱分解"></a>一、核心理论基础：图谱分解</h2><h3 id="1-图拉普拉斯矩阵（关键算子）"><a href="#1-图拉普拉斯矩阵（关键算子）" class="headerlink" title="1. 图拉普拉斯矩阵（关键算子）"></a>1. 图拉普拉斯矩阵（关键算子）</h3><p>定义：</p><script type="math/tex;mode=display">\mathbf{L} = \mathbf{D} - \mathbf{A}</script><ul><li>$\mathbf{A}$：邻接矩阵</li><li>$\mathbf{D}$：度矩阵（对角阵，$D<em>{ii} = \sum_j A</em>{ij}$）</li></ul><p><strong>归一化形式</strong>（常用）：</p><script type="math/tex;mode=display">\mathbf{L} = \mathbf{I} - \mathbf{D}^{-1/2} \mathbf{A} \mathbf{D}^{-1/2}</script><h3 id="2-特征分解"><a href="#2-特征分解" class="headerlink" title="2. 特征分解"></a>2. 特征分解</h3><p>将拉普拉斯矩阵分解为：</p><script type="math/tex;mode=display">\mathbf{L} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^\top</script><ul><li>$\mathbf{U} = [\mathbf{u}_1, \cdots, \mathbf{u}_N]$：特征向量矩阵（称为<strong>图傅里叶基</strong>）</li><li>$\mathbf{\Lambda} = \text{diag}(\lambda_1, \cdots, \lambda_N)$：特征值对角阵（$\lambda_i$表示频谱频率）</li></ul><h2 id="二、图信号谱域变换"><a href="#二、图信号谱域变换" class="headerlink" title="二、图信号谱域变换"></a>二、图信号谱域变换</h2><h3 id="1-图傅里叶变换（Graph-Fourier-Transform）"><a href="#1-图傅里叶变换（Graph-Fourier-Transform）" class="headerlink" title="1. 图傅里叶变换（Graph Fourier Transform）"></a>1. 图傅里叶变换（Graph Fourier Transform）</h3><p>对节点特征 $\mathbf{x} \in \mathbb{R}^N$ 的变换：</p><script type="math/tex;mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x} \quad \text{(时域→频域)}</script><p>逆变换：</p><script type="math/tex;mode=display">\mathbf{x} = \mathbf{U} \widehat{\mathbf{x}} \quad \text{(频域→时域)}</script><h3 id="2-图卷积定理"><a href="#2-图卷积定理" class="headerlink" title="2. 图卷积定理"></a>2. 图卷积定理</h3><p>图上的卷积操作在频谱域定义为<strong>逐元素乘积</strong>：</p><script type="math/tex;mode=display">\mathbf{x} *_\mathcal{G} \mathbf{y} = \mathbf{U} \left( (\mathbf{U}^\top \mathbf{x}) \odot (\mathbf{U}^\top \mathbf{y}) \right)</script><p>引入滤波器 $g_\theta(\mathbf{\Lambda})$ 后：</p><script type="math/tex;mode=display">\mathbf{x} *_\mathcal{G} g_\theta = \mathbf{U} g_\theta(\mathbf{\Lambda}) \mathbf{U}^\top \mathbf{x}</script><h2 id="三、经典模型演变"><a href="#三、经典模型演变" class="headerlink" title="三、经典模型演变"></a>三、经典模型演变</h2><h3 id="1-Spectral-CNN-Bruna-et-al-ICLR-2014"><a href="#1-Spectral-CNN-Bruna-et-al-ICLR-2014" class="headerlink" title="1. Spectral CNN (Bruna et al., ICLR 2014)"></a>1. Spectral CNN (Bruna et al., ICLR 2014)</h3><ul><li><strong>滤波器设计</strong>：<script type="math/tex;mode=display">g_\theta(\mathbf{\Lambda}) = \text{diag}(\theta_1, \theta_2, \cdots, \theta_N) \quad (\theta_i \in \mathbb{R})</script></li><li><strong>局限性</strong>：<ul><li>参数量大 ($O(N)$)</li><li>无法局部化（依赖全图特征分解）<h3 id="2-ChebNet-Defferrard-et-al-NeurIPS-2016"><a href="#2-ChebNet-Defferrard-et-al-NeurIPS-2016" class="headerlink" title="2. ChebNet (Defferrard et al., NeurIPS 2016)"></a>2. ChebNet (Defferrard et al., NeurIPS 2016)</h3>用<strong>切比雪夫多项式</strong>近似滤波器：<script type="math/tex;mode=display">g_\theta(\mathbf{\Lambda}) = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{\Lambda}})</script></li></ul></li><li>$\tilde{\mathbf{\Lambda}} = \frac{2\mathbf{\Lambda}}{\lambda_{\max}} - \mathbf{I}$（缩放至$[-1,1]$）</li><li>$T<em>k(\cdot)$：切比雪夫多项式（递归定义：$T_0=1, T_1=x, T_k=2xT</em>{k-1}-T_{k-2}$）</li></ul><p><strong>卷积操作</strong>：</p><script type="math/tex;mode=display">\mathbf{x} *_\mathcal{G} g_\theta = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{L}}) \mathbf{x}</script><p>其中 $\tilde{\mathbf{L}} = \frac{2\mathbf{L}}{\lambda_{\max}} - \mathbf{I}$（无需特征分解！）</p><h3 id="3-GCN-Kipf-amp-Welling-ICLR-2017"><a href="#3-GCN-Kipf-amp-Welling-ICLR-2017" class="headerlink" title="3. GCN (Kipf &amp; Welling, ICLR 2017)"></a>3. GCN (Kipf &amp; Welling, ICLR 2017)</h3><p>ChebNet 的<strong>一阶近似</strong>（$K=2$）：</p><script type="math/tex;mode=display">\mathbf{H}^{(l+1)} = \sigma \left( \hat{\mathbf{A}} \mathbf{H}^{(l)} \mathbf{W}^{(l)} \right) \quad \text{其中} \quad \hat{\mathbf{A}} = \tilde{\mathbf{D}}^{-1/2} \tilde{\mathbf{A}} \tilde{\mathbf{D}}^{-1/2}</script><ul><li>仅聚合一阶邻居（高效且可扩展）</li></ul><h2 id="四、关键优势与局限性"><a href="#四、关键优势与局限性" class="headerlink" title="四、关键优势与局限性"></a>四、关键优势与局限性</h2><div class="table-container"><table><thead><tr><th><strong>优势</strong></th><th><strong>局限性</strong></th></tr></thead><tbody><tr><td>⭐ 理论基础严密（信号处理可解释性强）</td><td>⚠️ 计算成本高（需特征分解或多项式逼近）</td></tr><tr><td>⭐ 全局信息捕获能力强</td><td>⚠️ 对图结构变化敏感（固定图假设）</td></tr><tr><td>⭐ 频域滤波提供灵活特征选择</td><td>⚠️ 无法直接处理异构图</td></tr></tbody></table></div><h2 id="五、代码实现（PyTorch-Geometric）"><a href="#五、代码实现（PyTorch-Geometric）" class="headerlink" title="五、代码实现（PyTorch Geometric）"></a>五、代码实现（PyTorch Geometric）</h2><h3 id="ChebNet-示例："><a href="#ChebNet-示例：" class="headerlink" title="ChebNet 示例："></a>ChebNet 示例：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChebNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, K=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = ChebConv(in_dim, hidden_dim, K)  <span class="comment"># K阶切比雪夫近似</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = ChebConv(hidden_dim, out_dim, K)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x, edge_index))    <span class="comment"># 第一层（自动计算拉普拉斯）</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)                <span class="comment"># 第二层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line">model = ChebNet(in_dim=<span class="number">16</span>, hidden_dim=<span class="number">32</span>, out_dim=<span class="number">8</span>, K=<span class="number">3</span>)</span><br><span class="line">output = model(data)  <span class="comment"># 输入图数据</span></span><br></pre></td></tr></table></figure><h2 id="六、新一代谱方法研究（2023-2024）"><a href="#六、新一代谱方法研究（2023-2024）" class="headerlink" title="六、新一代谱方法研究（2023-2024）"></a>六、新一代谱方法研究（2023-2024）</h2><ol><li><p><strong>自适应谱滤波器</strong></p><ul><li><strong>GPR-GNN</strong> (ICLR 2021)：广义PageRank系数优化<script type="math/tex;mode=display">\mathbf{H} = \sum_{k=0}^K \gamma_k \hat{\mathbf{A}}^k \mathbf{X} \mathbf{W}</script><ul><li>$\gamma_k$ 作为可学习参数，自适应不同阶数重要性</li></ul></li></ul></li><li><p><strong>无需特征分解的谱学习</strong></p><ul><li><strong>BernNet</strong> (NeurIPS 2021)：用Bernstein多项式拟合任意滤波器：<script type="math/tex;mode=display">g(\lambda) = \sum_{k=0}^K \theta_k B_k(\lambda; K)</script><ul><li>$B_k$ 为Bernstein基函数，保证滤波器平滑性</li></ul></li></ul></li><li><p><strong>图小波神经网络</strong></p><ul><li><strong>GWNN</strong> (ICML 2023)：用图小波基取代傅里叶基<script type="math/tex;mode=display">\mathbf{\Psi}_s = \mathbf{U} e^{-\varepsilon s \mathbf{\Lambda}} \mathbf{U}^\top</script><ul><li>$s$ 为尺度参数，实现多分辨率分析</li></ul></li></ul></li></ol><h2 id="七、总结与应用场景"><a href="#七、总结与应用场景" class="headerlink" title="七、总结与应用场景"></a>七、总结与应用场景</h2><p><strong>核心适用领域</strong>：</p><ul><li>图信号处理（节点分类、图分类）</li><li>物理系统建模（分子动力学、流体模拟）</li><li>推荐系统（用户-商品图谱分析）<blockquote><p><strong>工具推荐</strong>：</p><ul><li><code>torch_geometric.nn.ChebConv</code></li><li>DGL的 <code>ChebConv</code> 模块</li><li><a target="_blank" rel="noopener" href="https://github.com/ivam-he/BernNet">BernNet官方实现</a></li></ul><p><strong>最新突破</strong>：<strong>Oversquashing-Free Graph Neural Networks</strong> (ICML 2024) 提出通过谱设计解决长距离信息传递瓶颈。</p></blockquote></li></ul><hr><h1 id="Spectral-GNN-vs-Spatial-GNN"><a href="#Spectral-GNN-vs-Spatial-GNN" class="headerlink" title="Spectral GNN vs. Spatial GNN"></a>Spectral GNN vs. Spatial GNN</h1><p>以下是对空间图神经网络（Spatial GNN）和谱图神经网络（Spectral GNN）的全面对比解析，涵盖理论、模型和应用差异：</p><h2 id="一、核心理念对比"><a href="#一、核心理念对比" class="headerlink" title="一、核心理念对比"></a>一、核心理念对比</h2><div class="table-container"><table><thead><tr><th><strong>维度</strong></th><th>Spatial GNN (空间方法)</th><th>Spectral GNN (谱方法)</th></tr></thead><tbody><tr><td><strong>基本思想</strong></td><td>通过局部邻居聚合传播信息</td><td>在图傅里叶域定义卷积操作</td></tr><tr><td><strong>图定义域</strong></td><td>顶点域 (Vertex Domain)</td><td>谱域 (Spectral Domain)</td></tr><tr><td><strong>理论基础</strong></td><td>消息传递机制</td><td>图谱理论（拉普拉斯矩阵分解）</td></tr><tr><td><strong>计算范式</strong></td><td>图结构拓扑操作</td><td>频域信号处理</td></tr></tbody></table></div><h2 id="二、技术原理详解"><a href="#二、技术原理详解" class="headerlink" title="二、技术原理详解"></a>二、技术原理详解</h2><h3 id="Spatial-GNN-空间方法"><a href="#Spatial-GNN-空间方法" class="headerlink" title="Spatial GNN (空间方法)"></a>Spatial GNN (空间方法)</h3><p><strong>核心机制：消息传递 (Message Passing)</strong></p><ol><li><p><strong>聚合 (Aggregate)</strong>：</p><script type="math/tex;mode=display">\mathbf{m}_i^{(l)} = \text{AGGREGATE}^{(l)} \left( \{ \mathbf{h}_j^{(l-1)} \mid j \in \mathcal{N}(i) \} \right)</script><ul><li>邻居特征聚合（sum/mean/max）</li></ul></li><li><p><strong>更新 (Update)</strong>：</p><script type="math/tex;mode=display">\mathbf{h}_i^{(l)} = \text{UPDATE}^{(l)} \left( \mathbf{h}_i^{(l-1)}, \mathbf{m}_i^{(l)} \right)</script><ul><li>结合自身特征与聚合信息</li></ul></li></ol><p><strong>代表模型</strong>：<br></p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    graph LR
  GCN --&gt; GraphSAGE
  GraphSAGE --&gt; GAT[GAT]
  GAT --&gt; GIN[GIN]
  GraphSAGE --&gt; PNA[PNA]
  </pre></div><p></p><h3 id="Spectral-GNN-谱方法"><a href="#Spectral-GNN-谱方法" class="headerlink" title="Spectral GNN (谱方法)"></a>Spectral GNN (谱方法)</h3><p><strong>核心机制：频域卷积</strong></p><ol><li><p><strong>图傅里叶变换</strong>：</p><script type="math/tex;mode=display">\widehat{\mathbf{x}} = \mathbf{U}^\top \mathbf{x}\tag{1}</script></li><li><p><strong>频域滤波</strong>：</p><script type="math/tex;mode=display">\widehat{\mathbf{y}} = g_\theta(\mathbf{\Lambda}) \widehat{\mathbf{x}}\tag{2}</script></li><li><p><strong>逆变换</strong>：</p><script type="math/tex;mode=display">\mathbf{y} = \mathbf{U} \widehat{\mathbf{y}} = \mathbf{U} g_\theta(\mathbf{\Lambda}) \mathbf{U}^\top \mathbf{x}\tag{3}</script></li></ol><blockquote><p>通俗易懂地说，公式(1)的操作是将$\mathbf{x}$映射到频率空间中；公式(2)是对映射到频率空间中的内容进行一些操作，如图卷积操作等；公式(3)是将频率空间中得到的内容再逆变换映射会原空间中。而公式(2)中的函数，为我们需要学习的函数。</p></blockquote><p><strong>代表模型进化</strong>：<br></p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
    graph LR
  SpectralCNN --&gt; ChebNet
  ChebNet --&gt; GCN
  ChebNet --&gt; ARMA[ARMA Net]
  SpectralCNN --&gt; GWNN
  </pre></div><p></p><h2 id="三、模型特性对比"><a href="#三、模型特性对比" class="headerlink" title="三、模型特性对比"></a>三、模型特性对比</h2><h3 id="1-计算效率"><a href="#1-计算效率" class="headerlink" title="1. 计算效率"></a>1. 计算效率</h3><div class="table-container"><table><thead><tr><th><strong>指标</strong></th><th>Spatial GNN</th><th>Spectral GNN</th></tr></thead><tbody><tr><td><strong>时间复杂度</strong></td><td>(O(\</td><td>\mathcal{E}\</td><td>)) (邻居聚合)</td><td>(O(n^2)) (特征分解) → 优化后(O(K\</td><td>\mathcal{E}\</td><td>))</td></tr><tr><td><strong>扩展性</strong></td><td>⭐⭐⭐ 支持大规模图</td><td>⭐⭐需近似处理提升效率</td></tr><tr><td><strong>并行性</strong></td><td>节点级并行（分布式优化）</td><td>全图级计算（GPU并行加速）</td></tr></tbody></table></div><h3 id="2-结构适应性"><a href="#2-结构适应性" class="headerlink" title="2. 结构适应性"></a>2. 结构适应性</h3><div class="table-container"><table><thead><tr><th><strong>特性</strong></th><th>Spatial GNN</th><th>Spectral GNN</th></tr></thead><tbody><tr><td><strong>动态图</strong></td><td>✅ 实时更新邻居</td><td>❌ 需重新计算拉普拉斯矩阵</td></tr><tr><td><strong>异构图</strong></td><td>✅ 支持多关系聚合（RGCN, HGT）</td><td>❌ 主要面向同构图</td></tr><tr><td><strong>边特征</strong></td><td>✅ 天然支持（如GINE）</td><td>⚠️ 需扩展设计</td></tr></tbody></table></div><h2 id="四、经典模型实现代码"><a href="#四、经典模型实现代码" class="headerlink" title="四、经典模型实现代码"></a>四、经典模型实现代码</h2><h3 id="Spatial-GNN示例：GAT-Graph-Attention-Network"><a href="#Spatial-GNN示例：GAT-Graph-Attention-Network" class="headerlink" title="Spatial GNN示例：GAT (Graph Attention Network)"></a>Spatial GNN示例：GAT (Graph Attention Network)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GAT</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, heads=<span class="number">8</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = GATConv(in_dim, hidden_dim, heads=heads)  <span class="comment"># 多头注意力</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = GATConv(hidden_dim*heads, out_dim, heads=<span class="number">1</span>) <span class="comment"># 单头输出</span></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = torch.relu(<span class="variable language_">self</span>.conv1(x, edge_index))  <span class="comment"># 聚合：加权邻居特征</span></span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)              <span class="comment"># 输出层</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>空间聚合核心</strong>：注意力权重计算</p><script type="math/tex;mode=display">\alpha_{ij} = \frac{ \exp(\text{LeakyReLU}(\mathbf{a}^\top [\mathbf{W}\mathbf{h}_i \| \mathbf{W}\mathbf{h}_j])) } { \sum_{k \in \mathcal{N}(i)} \exp(\text{LeakyReLU}(\mathbf{a}^\top [\mathbf{W}\mathbf{h}_i \| \mathbf{W}\mathbf{h}_k])) }</script><h3 id="Spectral-GNN示例：ChebNet-切比雪夫网络"><a href="#Spectral-GNN示例：ChebNet-切比雪夫网络" class="headerlink" title="Spectral GNN示例：ChebNet (切比雪夫网络)"></a>Spectral GNN示例：ChebNet (切比雪夫网络)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> ChebConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ChebNet</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, hidden_dim, out_dim, k=<span class="number">3</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = ChebConv(in_dim, hidden_dim, K=k)  <span class="comment"># K阶近似</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = ChebConv(hidden_dim, out_dim, K=k)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        x, edge_index = data.x, data.edge_index</span><br><span class="line">        x = <span class="variable language_">self</span>.conv1(x, edge_index)  <span class="comment"># 频域卷积：切比雪夫多项式逼近</span></span><br><span class="line">        x = torch.relu(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.conv2(x, edge_index)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p><strong>谱滤波核心</strong>：(K)阶多项式展开</p><script type="math/tex;mode=display">g_\theta(\mathbf{L}) = \sum_{k=0}^{K-1} \theta_k T_k(\tilde{\mathbf{L}})</script><h2 id="五、性能对比与适用场景"><a href="#五、性能对比与适用场景" class="headerlink" title="五、性能对比与适用场景"></a>五、性能对比与适用场景</h2><div class="table-container"><table><thead><tr><th><strong>任务类型</strong></th><th>推荐模型类型</th><th>原因说明</th></tr></thead><tbody><tr><td>大规模图节点分类</td><td>Spatial GNN</td><td>邻居采样高效（GraphSAGE）</td></tr><tr><td>图结构分析</td><td>Spectral GNN</td><td>捕获全局结构特征（谱聚类）</td></tr><tr><td>动态图预测</td><td>Spatial GNN</td><td>增量更新邻居（EvolveGCN）</td></tr><tr><td>分子性质预测</td><td>Spectral GNN</td><td>物理系统能量状态建模</td></tr><tr><td>推荐系统</td><td>Spatial GNN</td><td>多重关系建模（LightGCN）</td></tr></tbody></table></div><h2 id="六、前沿研究进展（2023-2024）"><a href="#六、前沿研究进展（2023-2024）" class="headerlink" title="六、前沿研究进展（2023-2024）"></a>六、前沿研究进展（2023-2024）</h2><h3 id="Spatial-GNN最新方向："><a href="#Spatial-GNN最新方向：" class="headerlink" title="Spatial GNN最新方向："></a>Spatial GNN最新方向：</h3><ol><li><p><strong>长距离依赖优化</strong></p><ul><li><strong>CRaWl</strong> (ICML 2023)：随机游走增强信息传播<script type="math/tex;mode=display">\mathbf{m}_i = \text{ATTN} \left( \{ \text{RW}_k(i) \mid k=1,\dots,K \} \right)</script><ul><li>解决过平滑（Over-smoothing）问题</li></ul></li></ul></li><li><p><strong>3D几何图学习</strong></p><ul><li><strong>Equivariant GNN</strong> (Nature 2024)：<script type="math/tex;mode=display">\mathbf{h}_i^{(l)} = f( \| \mathbf{x}_i - \mathbf{x}_j \|, \mathbf{h}_j ) \quad (SE(3)-\text{不变})</script><ul><li>应用于蛋白质结构预测</li></ul></li></ul></li></ol><h3 id="Spectral-GNN最新方向："><a href="#Spectral-GNN最新方向：" class="headerlink" title="Spectral GNN最新方向："></a>Spectral GNN最新方向：</h3><ol><li><p><strong>自适应谱滤波器</strong></p><ul><li><strong>FreqGNN</strong> (ICLR 2024)：可学习频带选择<script type="math/tex;mode=display">g_\theta(\lambda) = \sum_{k=1}^K \theta_k \cdot \text{bandpass}_k(\lambda)</script></li></ul></li><li><p><strong>无拉普拉斯方法</strong></p><ul><li><strong>AdaGNN</strong> (KDD 2023)：利用图扩散算子<script type="math/tex;mode=display">\mathbf{H} = \sum_{t=0}^T \alpha_t \mathbf{P}^t \mathbf{X} \mathbf{W}_t</script><ul><li>$\mathbf{P} = \mathbf{A}\mathbf{D}^{-1}$为转移矩阵</li></ul></li></ul></li></ol><h2 id="七、混合架构趋势"><a href="#七、混合架构趋势" class="headerlink" title="七、混合架构趋势"></a>七、混合架构趋势</h2><p><strong>SPAGAN</strong> (NeurIPS 2023)：空间-谱双路径融合<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 空间路径</span></span><br><span class="line">h_spatial = GATConv(x, edge_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 谱路径</span></span><br><span class="line">h_spectral = ChebConv(x, edge_index)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自适应融合 (门控机制)</span></span><br><span class="line">gate = σ(Linear([h_spatial || h_spectral]))</span><br><span class="line">output = gate * h_spatial + (<span class="number">1</span>-gate) * h_spectral</span><br></pre></td></tr></table></figure><br><strong>优势</strong>：在OGB Large-scale挑战赛中实现SOTA<p></p><blockquote><p><strong>最佳实践选择</strong>：</p><ul><li>优先<strong>Spatial GNN</strong>：工业级应用（推荐系统、欺诈检测）</li><li>选用<strong>Spectral GNN</strong>：科学计算任务（计算化学、物理模拟）</li><li><strong>Hybrid 模型</strong>：对精度要求极高的场景（如药物发现）</li></ul></blockquote><h1 id="Laplacian-Positional-Encoding"><a href="#Laplacian-Positional-Encoding" class="headerlink" title="Laplacian Positional Encoding"></a>Laplacian Positional Encoding</h1><p>拉普拉斯位置编码是图神经网络中一种基于<strong>图谱理论</strong>的位置表示方法，主要用于解决传统 GNN 无法区分<strong>结构等价节点</strong>的问题（如环形图中的对称节点）。它是位置编码（PE）在图数据上的扩展，通过图的拉普拉斯矩阵特征向量提供全局位置信息。</p><h2 id="核心数学原理"><a href="#核心数学原理" class="headerlink" title="核心数学原理"></a>核心数学原理</h2><h3 id="1-图拉普拉斯矩阵"><a href="#1-图拉普拉斯矩阵" class="headerlink" title="1. 图拉普拉斯矩阵"></a>1. 图拉普拉斯矩阵</h3><p>对于一个无向图 $G=(V,E)$，其归一化拉普拉斯矩阵定义为：</p><script type="math/tex;mode=display">L = I - D^{-1/2}AD^{-1/2}</script><p>其中：</p><ul><li>$A \in \mathbb{R}^{n\times n}$ 为邻接矩阵</li><li>$D$ 为度对角矩阵，$D<em>{ii} = \sum_j A</em>{ij}$</li><li>$L$ 是<strong>对称半正定矩阵</strong><h3 id="2-特征分解-1"><a href="#2-特征分解-1" class="headerlink" title="2. 特征分解"></a>2. 特征分解</h3>对 $L$ 进行特征分解：<script type="math/tex;mode=display">L = U \Lambda U^T</script>其中：</li><li>$\Lambda = \text{diag}(\lambda_1, \lambda_2, …, \lambda_n)$ 是特征值对角阵 ($0 \leq \lambda_1 \leq … \leq \lambda_n$)</li><li>$U = [\mathbf{u}_1, \mathbf{u}_2, …, \mathbf{u}_n]$ 是酉矩阵，每列是对应特征值的特征向量<h3 id="3-位置编码生成"><a href="#3-位置编码生成" class="headerlink" title="3. 位置编码生成"></a>3. 位置编码生成</h3>节点 $v$ 的位置编码为：<script type="math/tex;mode=display">PE(v) = [\mathbf{u}_2(v), \mathbf{u}_3(v), ..., \mathbf{u}_{d+1}(v)]</script>其中：</li><li>排除第一个特征向量 $\mathbf{u}_1$ (对应特征值 $\lambda_1=0$，所有元素均为常数)</li><li>取 $d$ 个最小非零特征值对应的特征向量分量</li></ul><blockquote><p><strong>为什么工作？</strong>：<br>Fiedler 定理表明第二特征向量 $\mathbf{u}_2$ (Fiedler 向量) 将图分割为两个连通分量的最优解，更高维特征向量提供更细粒度的空间位置信息。</p></blockquote><h2 id="特点分析"><a href="#特点分析" class="headerlink" title="特点分析"></a>特点分析</h2><div class="table-container"><table><thead><tr><th>性质</th><th>说明</th><th>影响</th></tr></thead><tbody><tr><td><strong>结构感知</strong></td><td>编码图的拓扑结构</td><td>区分环状图/网格图的对称节点</td></tr><tr><td><strong>正交性</strong></td><td>$\langle \mathbf{u}<em>i, \mathbf{u}_j \rangle=\delta</em>{ij}$</td><td>不同方向位置特征解耦</td></tr><tr><td><strong>排列不变性</strong></td><td>对节点重标号不变</td><td>满足GNN的置换不变性要求</td></tr><tr><td><strong>多尺度性</strong></td><td>小特征值对应全局结构</td><td>不同特征向量捕获不同尺度的位置关系</td></tr></tbody></table></div><h2 id="完整实现代码-PyTorch-PyG"><a href="#完整实现代码-PyTorch-PyG" class="headerlink" title="完整实现代码 (PyTorch+PyG)"></a>完整实现代码 (PyTorch+PyG)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy.sparse <span class="keyword">as</span> sp</span><br><span class="line"><span class="keyword">from</span> torch_geometric.data <span class="keyword">import</span> Data</span><br><span class="line"><span class="keyword">from</span> torch_geometric.utils <span class="keyword">import</span> get_laplacian</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_laplace_pe</span>(<span class="params">edge_index, num_nodes, positive=<span class="literal">False</span>, k=<span class="number">8</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算图的拉普拉斯位置编码</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        edge_index (Tensor): [2, num_edges] 边索引</span></span><br><span class="line"><span class="string">        num_nodes (int): 节点数量</span></span><br><span class="line"><span class="string">        positive (bool): 是否强制值均为正 (用于正定矩阵)</span></span><br><span class="line"><span class="string">        k (int): 使用的特征向量维度</span></span><br><span class="line"><span class="string">      </span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        pe (Tensor): [num_nodes, k] 位置编码矩阵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 计算归一化拉普拉斯矩阵</span></span><br><span class="line">    L = get_laplacian(edge_index, num_nodes=num_nodes, normalization=<span class="string">&#x27;sym&#x27;</span>)</span><br><span class="line">    L_sparse = sp.coo_matrix((L[<span class="number">1</span>].numpy(), L[<span class="number">0</span>].numpy()), shape=(num_nodes, num_nodes))</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 特征分解 (仅计算k+1个最小特征值/向量)</span></span><br><span class="line">    evals, evecs = sp.linalg.eigsh(L_sparse, k=k+<span class="number">1</span>, which=<span class="string">&#x27;SM&#x27;</span>)</span><br><span class="line">    <span class="comment"># 删除第一个特征向量(对应λ=0)</span></span><br><span class="line">    evecs = evecs[:, evals.argsort()][:, <span class="number">1</span>:<span class="number">1</span>+k] </span><br><span class="line">  </span><br><span class="line">    pe = torch.tensor(evecs).<span class="built_in">float</span>()</span><br><span class="line">    <span class="comment"># 可选：变换为正值(使维度可解释)</span></span><br><span class="line">    <span class="keyword">if</span> positive:</span><br><span class="line">        pe = pe - pe.<span class="built_in">min</span>(<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">return</span> pe / pe.<span class="built_in">max</span>(<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> pe</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例：应用到分子图数据</span></span><br><span class="line"><span class="keyword">from</span> torch_geometric.datasets <span class="keyword">import</span> ZINC</span><br><span class="line">dataset = ZINC(root=<span class="string">&#x27;/data/zinc&#x27;</span>, split=<span class="string">&#x27;train&#x27;</span>, transform=LaplacePEAdder(k=<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LaplacePEAdder</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;PyG数据转换器：自动加入位置编码&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, k=<span class="number">8</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.k = k</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, data: Data</span>):</span><br><span class="line">        edge_index, num_nodes = data.edge_index, data.num_nodes</span><br><span class="line">        pe = compute_laplace_pe(edge_index, num_nodes, k=<span class="variable language_">self</span>.k)</span><br><span class="line">        <span class="comment"># 与原始特征拼接</span></span><br><span class="line">        <span class="keyword">if</span> data.x <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            data.x = pe</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            data.x = torch.cat([data.x, pe], dim=-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h2 id="关键优化技术"><a href="#关键优化技术" class="headerlink" title="关键优化技术"></a>关键优化技术</h2><ol><li><strong>GPU加速特征分解</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用cuSPARSE和cuSOLVER进行加速</span></span><br><span class="line"><span class="keyword">import</span> torch.sparse</span><br><span class="line">L_coo = get_laplacian(edge_index, normalization=<span class="string">&#x27;sym&#x27;</span>)</span><br><span class="line">L_indices = torch.vstack(L_coo)</span><br><span class="line">L_value = torch.ones(L_coo.shape[<span class="number">1</span>])</span><br><span class="line">L_sparse = torch.sparse_coo_tensor(L_indices, L_value, (num_nodes, num_nodes))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 截断特征分解</span></span><br><span class="line">evals, evecs = torch.lobpcg(L_sparse, k=k+<span class="number">1</span>, largest=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure></li><li><strong>处理大规模图</strong><ul><li>Nystrom 近似法：对部分节点采样加速计算 (ICML 2023)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> graphgym.efeat.position <span class="keyword">import</span> nystrom_approximation</span><br><span class="line">pe = nystrom_approximation(L, sample_size=<span class="number">500</span>, dim=k)</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="GNN模型集成示例"><a href="#GNN模型集成示例" class="headerlink" title="GNN模型集成示例"></a>GNN模型集成示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GTPosModel</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;结合位置编码的图Transformer&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, pe_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.pe_proj = nn.Linear(pe_dim, in_dim)  <span class="comment"># 位置编码投影层</span></span><br><span class="line">        <span class="variable language_">self</span>.encoder = GATConv(in_dim, <span class="number">64</span>, heads=<span class="number">4</span>)</span><br><span class="line">        ...</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, edge_index, lap_pe</span>):</span><br><span class="line">        <span class="comment"># 融合原始特征和位置编码</span></span><br><span class="line">        fused_feat = x + <span class="variable language_">self</span>.pe_proj(lap_pe)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.encoder(fused_feat, edge_index)</span><br></pre></td></tr></table></figure><h2 id="应用场景比较"><a href="#应用场景比较" class="headerlink" title="应用场景比较"></a>应用场景比较</h2><div class="table-container"><table><thead><tr><th>图类型</th><th>适用性</th><th>解释</th></tr></thead><tbody><tr><td>环形/网格图</td><td>★★★</td><td>完美区分结构等价节点</td></tr><tr><td>小世界网络</td><td>★★☆</td><td>局部特征优于全局位置</td></tr><tr><td>低维点云图</td><td>★☆</td><td>欧式距离编码更有效</td></tr><tr><td>动态图</td><td>☆</td><td>需每次重新计算特征分解</td></tr></tbody></table></div><h2 id="前沿进展"><a href="#前沿进展" class="headerlink" title="前沿进展"></a>前沿进展</h2><ol><li><p><strong>复值编码</strong> (ICLR 2024突破)<br>使用复值特征向量拓展频谱信息：</p><script type="math/tex;mode=display">\mathcal{CR}PE(v) = e^{-i\theta}\mathbf{u}(v) \quad (\theta \sim \text{learnable})</script></li><li><p><strong>方向可区分编码</strong><br>在异质图中给特征向量赋予方向信息：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">directed_lap_pe</span>(<span class="params">edge_index, direction=<span class="string">&#x27;out&#x27;</span></span>):</span><br><span class="line">    L_out = D_out^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125; A D_out^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125;  <span class="comment"># 出度拉普拉斯</span></span><br><span class="line">    L_in = D_in^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125; A^T D_in^&#123;-<span class="number">1</span>/<span class="number">2</span>&#125;   <span class="comment"># 入度拉普拉斯</span></span><br><span class="line">    <span class="keyword">return</span> (compute_pe(L_out), compute_pe(L_in))</span><br></pre></td></tr></table></figure></li><li><p><strong>自适应频谱选择</strong><br>基于learnable gating机制动态选择特征向量：</p><script type="math/tex;mode=display">\text{PE}(v) = \sum_{i=2}^k g_i(\mathcal{G}) \cdot \mathbf{u}_i(v)</script></li></ol><h2 id="参考论文"><a href="#参考论文" class="headerlink" title="参考论文"></a>参考论文</h2><ul><li>Dwivedi et al. Benchmarking GNNs with Positional Encodings (ICLR 2023)</li><li>Kreuzer et al. Rethinking Graph Transformers with Spectral Attention (NeurIPS 2021)</li><li>Lim et al. Sign and Basis Invariant Networks for Spectral Graph Representation Learning (ICML 2023)</li></ul><blockquote><p><strong>最佳实践</strong>：</p><ul><li>对于&lt;50k节点的图直接计算全分解</li><li>大图使用Nyström近似或Lanczos迭代</li><li>与可学习PE结合（如Random Walk PE）效果更佳</li><li>Transformer架构比GCN/GAT更能利用频谱信息</li></ul></blockquote><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://epsilonzyj.github.io/posts/63fed347.html">图神经网络简介 | An Introduction to GNN</a></li><li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Vw411R7Fj?spm_id_from=333.788.videopod.episodes&amp;vd_source=2e36fae16810615c2d859efc03aef1c4">图卷积神经网络（GCN）的数学原理详解——谱图理论和傅立叶变换初探-Bilibili</a></li></ol></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://epsilonzyj.github.io">EpsilonZ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://epsilonzyj.github.io/posts/3539d4b8.html">https://epsilonzyj.github.io/posts/3539d4b8.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://epsilonzyj.github.io" target="_blank">EpsilonZ's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/Graph-ML/">Graph ML</a><a class="post-meta__tags" href="/tags/GNN/">GNN</a></div><div class="post-share"><div class="social-share" data-image="/img/GNNCover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/e4aef2ca.html" title="使用Mac远程连接Windows WSL"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IMG_3174.PNG" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">使用Mac远程连接Windows WSL</div></div><div class="info-2"><div class="info-item-1">Windows与MacBook双持的情况下，远程连接WSL使用Linux环境的方法。</div></div></div></a><a class="pagination-related" href="/posts/641ba8fa.html" title="同质图与异质图 ｜ Homogeneous Graph &amp; Heterogeneous Graph"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">同质图与异质图 ｜ Homogeneous Graph & Heterogeneous Graph</div></div><div class="info-2"><div class="info-item-1">在Graph ML中关于图的类型的一些基础知识的补充</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related no-desc" href="/posts/4a93988c.html" title="GNN经典模型 | GNN Basic Models"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-02</div><div class="info-item-2">GNN经典模型 | GNN Basic Models</div></div></div></a><a class="pagination-related" href="/posts/63fed347.html" title="图神经网络简介 | An Introduction to GNN"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-27</div><div class="info-item-2">图神经网络简介 | An Introduction to GNN</div></div><div class="info-2"><div class="info-item-1">对图神经网络的简要介绍和入门</div></div></div></a><a class="pagination-related" href="/posts/c6b8d3b6.html" title="CS224W | Machine Learning with Graphs"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-27</div><div class="info-item-2">CS224W | Machine Learning with Graphs</div></div><div class="info-2"><div class="info-item-1">本文基于Stanford的CS224W中一些理论内容，介绍有关图机器学习的手段与方法</div></div></div></a><a class="pagination-related" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-22</div><div class="info-item-2">论文阅读：DUALFormer</div></div><div class="info-2"><div class="info-item-1">DUALFormer:Dual Graph Transformer</div></div></div></a><a class="pagination-related" href="/posts/641ba8fa.html" title="同质图与异质图 ｜ Homogeneous Graph &amp; Heterogeneous Graph"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-09</div><div class="info-item-2">同质图与异质图 ｜ Homogeneous Graph &amp; Heterogeneous Graph</div></div><div class="info-2"><div class="info-item-1">在Graph ML中关于图的类型的一些基础知识的补充</div></div></div></a><a class="pagination-related" href="/posts/NAGphormer.html" title="论文阅读：NAGphormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-17</div><div class="info-item-2">论文阅读：NAGphormer</div></div><div class="info-2"><div class="info-item-1">NAGphormer:A Tokenized Graph Transformer For Node Classification In Large Graphs</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IMG_2179.JPG" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">EpsilonZ</div><div class="author-info-description">To sleep, or to research, that is the question.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">22</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">18</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/EpsilonZYJ"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/EpsilonZYJ" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:biopic.tweeter_2u@icloud.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Research everyday!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B0%B1%E5%9F%9F%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B"><span class="toc-number">1.</span> <span class="toc-text">谱域图神经网络简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B0%B1%E5%9F%9F%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3"><span class="toc-number">2.</span> <span class="toc-text">谱域图神经网络直观理解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E7%90%86%E8%A7%A3%E6%A0%B8%E5%BF%83%E7%9B%AE%E6%A0%87-%E7%BB%99%E5%9B%BE%E5%81%9A%E2%80%9DCT%E6%89%AB%E6%8F%8F%E2%80%9D"><span class="toc-number">2.1.</span> <span class="toc-text">第一步：理解核心目标 &#x3D; 给图做”CT扫描”</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E5%85%B3%E9%94%AE%E5%B7%A5%E5%85%B7-%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5"><span class="toc-number">2.2.</span> <span class="toc-text">第二步：关键工具 &#x3D; 图拉普拉斯矩阵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E5%8D%B7%E7%A7%AF%E5%9C%A8%E5%9B%BE%E4%B8%8A%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F-%E6%BB%A4%E6%B3%A2%E6%93%8D%E4%BD%9C"><span class="toc-number">2.3.</span> <span class="toc-text">第三步：卷积在图上怎么做？ &#x3D; 滤波操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E9%BA%BB%E7%83%A6%EF%BC%9F%E5%AE%9E%E9%99%85%E6%A1%88%E4%BE%8B%E8%AF%B4%E6%98%8E"><span class="toc-number">2.4.</span> <span class="toc-text">第四步：为什么这么麻烦？实际案例说明</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E7%94%9F%E6%B4%BB%E4%B8%AD%E7%9A%84%E7%B1%BB%E6%AF%94-%E9%9F%B3%E4%B9%90%E6%B7%B7%E9%9F%B3%E5%8F%B0%F0%9F%8E%9B%EF%B8%8F"><span class="toc-number">2.5.</span> <span class="toc-text">第五步：生活中的类比 - 音乐混音台🎛️</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5%EF%BC%9A%E6%8A%80%E6%9C%AF%E4%BC%98%E5%8C%96%E7%9A%84%E7%AA%81%E7%A0%B4-%E9%81%BF%E5%85%8D%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%9B%B0%E9%9A%BE"><span class="toc-number">2.6.</span> <span class="toc-text">第六步：技术优化的突破 &#x3D; 避免数学计算困难</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E6%AD%A5%EF%BC%9A%E7%9C%9F%E5%AE%9E%E4%BB%A3%E7%A0%81%E6%BC%94%E7%A4%BA%EF%BC%88PyG%E7%AE%80%E5%8C%96%E7%89%88%EF%BC%89"><span class="toc-number">2.7.</span> <span class="toc-text">第七步：真实代码演示（PyG简化版）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93%E4%B8%80%E5%8F%A5%E8%AF%9D"><span class="toc-number">2.8.</span> <span class="toc-text">核心总结一句话</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%B0%B1%E5%9F%9F%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E5%8D%95%E7%90%86%E8%AE%BA"><span class="toc-number">3.</span> <span class="toc-text">谱域图神经网络简单理论</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A0%B8%E5%BF%83%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80%EF%BC%9A%E5%9B%BE%E8%B0%B1%E5%88%86%E8%A7%A3"><span class="toc-number">3.1.</span> <span class="toc-text">一、核心理论基础：图谱分解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5%EF%BC%88%E5%85%B3%E9%94%AE%E7%AE%97%E5%AD%90%EF%BC%89"><span class="toc-number">3.1.1.</span> <span class="toc-text">1. 图拉普拉斯矩阵（关键算子）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3"><span class="toc-number">3.1.2.</span> <span class="toc-text">2. 特征分解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%9B%BE%E4%BF%A1%E5%8F%B7%E8%B0%B1%E5%9F%9F%E5%8F%98%E6%8D%A2"><span class="toc-number">3.2.</span> <span class="toc-text">二、图信号谱域变换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9B%BE%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%EF%BC%88Graph-Fourier-Transform%EF%BC%89"><span class="toc-number">3.2.1.</span> <span class="toc-text">1. 图傅里叶变换（Graph Fourier Transform）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%9B%BE%E5%8D%B7%E7%A7%AF%E5%AE%9A%E7%90%86"><span class="toc-number">3.2.2.</span> <span class="toc-text">2. 图卷积定理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E6%BC%94%E5%8F%98"><span class="toc-number">3.3.</span> <span class="toc-text">三、经典模型演变</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-Spectral-CNN-Bruna-et-al-ICLR-2014"><span class="toc-number">3.3.1.</span> <span class="toc-text">1. Spectral CNN (Bruna et al., ICLR 2014)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-ChebNet-Defferrard-et-al-NeurIPS-2016"><span class="toc-number">3.3.2.</span> <span class="toc-text">2. ChebNet (Defferrard et al., NeurIPS 2016)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-GCN-Kipf-amp-Welling-ICLR-2017"><span class="toc-number">3.3.3.</span> <span class="toc-text">3. GCN (Kipf &amp; Welling, ICLR 2017)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%85%B3%E9%94%AE%E4%BC%98%E5%8A%BF%E4%B8%8E%E5%B1%80%E9%99%90%E6%80%A7"><span class="toc-number">3.4.</span> <span class="toc-text">四、关键优势与局限性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0%EF%BC%88PyTorch-Geometric%EF%BC%89"><span class="toc-number">3.5.</span> <span class="toc-text">五、代码实现（PyTorch Geometric）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ChebNet-%E7%A4%BA%E4%BE%8B%EF%BC%9A"><span class="toc-number">3.5.1.</span> <span class="toc-text">ChebNet 示例：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E6%96%B0%E4%B8%80%E4%BB%A3%E8%B0%B1%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6%EF%BC%882023-2024%EF%BC%89"><span class="toc-number">3.6.</span> <span class="toc-text">六、新一代谱方法研究（2023-2024）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%80%BB%E7%BB%93%E4%B8%8E%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">3.7.</span> <span class="toc-text">七、总结与应用场景</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Spectral-GNN-vs-Spatial-GNN"><span class="toc-number">4.</span> <span class="toc-text">Spectral GNN vs. Spatial GNN</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%A0%B8%E5%BF%83%E7%90%86%E5%BF%B5%E5%AF%B9%E6%AF%94"><span class="toc-number">4.1.</span> <span class="toc-text">一、核心理念对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3"><span class="toc-number">4.2.</span> <span class="toc-text">二、技术原理详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spatial-GNN-%E7%A9%BA%E9%97%B4%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.1.</span> <span class="toc-text">Spatial GNN (空间方法)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spectral-GNN-%E8%B0%B1%E6%96%B9%E6%B3%95"><span class="toc-number">4.2.2.</span> <span class="toc-text">Spectral GNN (谱方法)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%A8%A1%E5%9E%8B%E7%89%B9%E6%80%A7%E5%AF%B9%E6%AF%94"><span class="toc-number">4.3.</span> <span class="toc-text">三、模型特性对比</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E8%AE%A1%E7%AE%97%E6%95%88%E7%8E%87"><span class="toc-number">4.3.1.</span> <span class="toc-text">1. 计算效率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%BB%93%E6%9E%84%E9%80%82%E5%BA%94%E6%80%A7"><span class="toc-number">4.3.2.</span> <span class="toc-text">2. 结构适应性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E7%BB%8F%E5%85%B8%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81"><span class="toc-number">4.4.</span> <span class="toc-text">四、经典模型实现代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spatial-GNN%E7%A4%BA%E4%BE%8B%EF%BC%9AGAT-Graph-Attention-Network"><span class="toc-number">4.4.1.</span> <span class="toc-text">Spatial GNN示例：GAT (Graph Attention Network)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spectral-GNN%E7%A4%BA%E4%BE%8B%EF%BC%9AChebNet-%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E7%BD%91%E7%BB%9C"><span class="toc-number">4.4.2.</span> <span class="toc-text">Spectral GNN示例：ChebNet (切比雪夫网络)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E4%B8%8E%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">4.5.</span> <span class="toc-text">五、性能对比与适用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81%E5%89%8D%E6%B2%BF%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95%EF%BC%882023-2024%EF%BC%89"><span class="toc-number">4.6.</span> <span class="toc-text">六、前沿研究进展（2023-2024）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spatial-GNN%E6%9C%80%E6%96%B0%E6%96%B9%E5%90%91%EF%BC%9A"><span class="toc-number">4.6.1.</span> <span class="toc-text">Spatial GNN最新方向：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spectral-GNN%E6%9C%80%E6%96%B0%E6%96%B9%E5%90%91%EF%BC%9A"><span class="toc-number">4.6.2.</span> <span class="toc-text">Spectral GNN最新方向：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81%E6%B7%B7%E5%90%88%E6%9E%B6%E6%9E%84%E8%B6%8B%E5%8A%BF"><span class="toc-number">4.7.</span> <span class="toc-text">七、混合架构趋势</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Laplacian-Positional-Encoding"><span class="toc-number">5.</span> <span class="toc-text">Laplacian Positional Encoding</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-number">5.1.</span> <span class="toc-text">核心数学原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%9F%A9%E9%98%B5"><span class="toc-number">5.1.1.</span> <span class="toc-text">1. 图拉普拉斯矩阵</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3-1"><span class="toc-number">5.1.2.</span> <span class="toc-text">2. 特征分解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81%E7%94%9F%E6%88%90"><span class="toc-number">5.1.3.</span> <span class="toc-text">3. 位置编码生成</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%89%B9%E7%82%B9%E5%88%86%E6%9E%90"><span class="toc-number">5.2.</span> <span class="toc-text">特点分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81-PyTorch-PyG"><span class="toc-number">5.3.</span> <span class="toc-text">完整实现代码 (PyTorch+PyG)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF"><span class="toc-number">5.4.</span> <span class="toc-text">关键优化技术</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#GNN%E6%A8%A1%E5%9E%8B%E9%9B%86%E6%88%90%E7%A4%BA%E4%BE%8B"><span class="toc-number">5.5.</span> <span class="toc-text">GNN模型集成示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E6%AF%94%E8%BE%83"><span class="toc-number">5.6.</span> <span class="toc-text">应用场景比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E6%B2%BF%E8%BF%9B%E5%B1%95"><span class="toc-number">5.7.</span> <span class="toc-text">前沿进展</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%AE%BA%E6%96%87"><span class="toc-number">5.8.</span> <span class="toc-text">参考论文</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-number">6.</span> <span class="toc-text">附录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">6.1.</span> <span class="toc-text">Reference</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/3374f76a.html" title="Graph Transformer中的问题 ｜ Problems With Graph Transformers"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Graph Transformer中的问题 ｜ Problems With Graph Transformers"></a><div class="content"><a class="title" href="/posts/3374f76a.html" title="Graph Transformer中的问题 ｜ Problems With Graph Transformers">Graph Transformer中的问题 ｜ Problems With Graph Transformers</a><time datetime="2025-10-23T11:49:46.000Z" title="发表于 2025-10-23 19:49:46">2025-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：DUALFormer"></a><div class="content"><a class="title" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer">论文阅读：DUALFormer</a><time datetime="2025-10-22T02:12:34.000Z" title="发表于 2025-10-22 10:12:34">2025-10-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/NTFormer.html" title="论文阅读：NTFormer"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：NTFormer"></a><div class="content"><a class="title" href="/posts/NTFormer.html" title="论文阅读：NTFormer">论文阅读：NTFormer</a><time datetime="2025-10-21T10:11:58.000Z" title="发表于 2025-10-21 18:11:58">2025-10-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Vcr-Graphormer.html" title="论文阅读：Vcr-Graphormer"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：Vcr-Graphormer"></a><div class="content"><a class="title" href="/posts/Vcr-Graphormer.html" title="论文阅读：Vcr-Graphormer">论文阅读：Vcr-Graphormer</a><time datetime="2025-10-20T17:10:41.000Z" title="发表于 2025-10-21 01:10:41">2025-10-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/page-rank.html" title="Page Rank算法"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Page Rank算法"></a><div class="content"><a class="title" href="/posts/page-rank.html" title="Page Rank算法">Page Rank算法</a><time datetime="2025-10-20T11:39:16.000Z" title="发表于 2025-10-20 19:39:16">2025-10-20</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/GNNCover.png)"><div id="footer-wrap"><div class="copyright">&copy;2025 By EpsilonZ</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><div class="app-refresh" id="app-refresh" style="position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease"><div class="app-refresh-wrap" style="display:flex;color:#fff;height:100%;align-items:center;justify-content:center"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color:#fff;text-decoration:underline;cursor:pointer">偷偷看一看 👀</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#3b70fc' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>function butterfly_footer_beautify_injector_config(){var t=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),t.insertAdjacentHTML("beforeend",'<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a></p>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_footer_beautify_injector_config():epage===cpage&&butterfly_footer_beautify_injector_config()</script><script async src="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.js"></script><script async src="/js/ali_font.js"></script><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset","30"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("article-sort-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__slideInRight"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script></body></html>
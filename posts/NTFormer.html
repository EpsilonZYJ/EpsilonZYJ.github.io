<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>论文阅读：NTFormer | EpsilonZ's Blog</title><meta name="author" content="EpsilonZ"><meta name="copyright" content="EpsilonZ"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="NTFormer:A Composite Node Tokenized Graph  Transformer for Node Classification"><meta property="og:type" content="article"><meta property="og:title" content="论文阅读：NTFormer"><meta property="og:url" content="https://epsilonzyj.github.io/posts/NTFormer.html"><meta property="og:site_name" content="EpsilonZ&#39;s Blog"><meta property="og:description" content="NTFormer:A Composite Node Tokenized Graph  Transformer for Node Classification"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://epsilonzyj.github.io/img/GNNCover.png"><meta property="article:published_time" content="2025-10-21T10:11:58.000Z"><meta property="article:modified_time" content="2025-10-29T13:48:29.808Z"><meta property="article:author" content="EpsilonZ"><meta property="article:tag" content="AI"><meta property="article:tag" content="Graph ML"><meta property="article:tag" content="Graph Transformer"><meta property="article:tag" content="Tokenizing"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://epsilonzyj.github.io/img/GNNCover.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "论文阅读：NTFormer",
  "url": "https://epsilonzyj.github.io/posts/NTFormer.html",
  "image": "https://epsilonzyj.github.io/img/GNNCover.png",
  "datePublished": "2025-10-21T10:11:58.000Z",
  "dateModified": "2025-10-29T13:48:29.808Z",
  "author": [
    {
      "@type": "Person",
      "name": "EpsilonZ",
      "url": "https://epsilonzyj.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/128.ico"><link rel="canonical" href="https://epsilonzyj.github.io/posts/NTFormer.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="manifest" href="/manifest.json"><meta name="msapplication-TileColor" content="#3b70fc"><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicon/128.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicon/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicon/16.png"><link rel="mask-icon" href="/img/siteicon/128.png" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":3,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"论文阅读：NTFormer",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><link rel="stylesheet" href="/css/custom.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload='this.media="all"'><script src="https://cdn.cbd.int/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload='this.media="screen"'><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="EpsilonZ's Blog" type="application/atom+xml"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div id="web_bg" style="background-image:url(/img/IMG_3821.jpg)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IMG_2179.JPG" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i> <span>关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/img/GNNCover.png)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">EpsilonZ's Blog</span></a><a class="nav-page-title" href="/"><span class="site-name">论文阅读：NTFormer</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i> <span>分类</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>归档</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user"></i> <span>关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">论文阅读：NTFormer</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-10-21T10:11:58.000Z" title="发表于 2025-10-21 18:11:58">2025-10-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-29T13:48:29.808Z" title="更新于 2025-10-29 21:48:29">2025-10-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Graph-ML/">Graph ML</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Graph-ML/Graph-Transformer/">Graph Transformer</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Graph-ML/Graph-Transformer/Tokenizing/">Tokenizing</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>9分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><hr><h4 id="Metadata"><a href="#Metadata" class="headerlink" title="Metadata"></a>Metadata</h4><ul><li>作者: Jinsong Chen, Siyu Jiang, Kun He</li><li>出处: IEEE Transactions on Big Data</li><li>PDF: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2406.19249">http://arxiv.org/abs/2406.19249</a></li></ul><hr><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>摘要—近年来，新兴的图Transformer在图节点分类任务上取得了显著进展。在大多数图Transformer中，一个关键步骤是将输入图转换为令牌序列(token sequences)作为模型输入，使Transformer能够有效学习节点表示。然而，我们观察到现有方法仅通过单类型令牌生成表达节点的部分图信息。因此，它们需要定制化的策略将额外的图特定特征编码到Transformer中，以确保节点表示学习的质量，这限制了模型处理多样化图的灵活性。为此，我们提出了一种新的图Transformer称为NTFormer来解决这个问题。NTFormer引入了一种新颖的令牌生成器Node2Par，它使用不同的令牌元素为每个节点构建各种令牌序列。这种灵活性使Node2Par能够从不同角度生成有价值的令牌序列，确保丰富图特征的全面表达。受益于Node2Par的优势，NTFormer仅利用基于Transformer的主干结构，无需图特定修改即可学习节点表示，消除了对图特定修改的需求。在包含不同规模同配性和异配性图的多种基准数据集上进行的大量实验证明，NTFormer在节点分类任务上优于代表性的图Transformer和图神经网络。</p><h1 id="研究问题"><a href="#研究问题" class="headerlink" title="研究问题"></a>研究问题</h1><p>本论文主要研究的问题是<strong>图神经网络中节点分类任务面临的token序列构建不全面的问题</strong>。具体来说，当前大多数图Transformer方法在将输入图转换为token序列作为模型输入时，仅使用单类型token生成来表达节点的部分图信息，这导致了以下局限性：</p><ol><li><strong>信息表达不完整</strong>：现有方法只能表达节点的部分图信息，无法全面捕捉复杂的图特征。</li><li><strong>需要额外定制策略</strong>：为弥补上述不足，这些方法需要设计特定策略将额外图特征编码到Transformer架构中，以确保节点表示学习的质量。</li><li><strong>模型灵活性受限</strong>：这些定制化的处理方式限制了模型处理多样化图结构的能力，无法灵活适应不同类型的图数据。<br>从论文摘要和引言可以看出，作者观察到”现有方法仅通过单类型token生成表达节点的部分图信息”，因此研究目标是通过设计更全面的token生成机制，使模型能够自然地表达丰富的图特征，而无需依赖特定的图结构修改或额外的编码策略。</li></ol><p>作者提出的解决方案是NTFormer模型，该模型引入了名为Node2Par的新token生成器，能够为每个节点构建多种token序列，从不同角度表达图特征，从而解决了传统方法中的局限性问题。</p><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="NTFormer方法详解"><a href="#NTFormer方法详解" class="headerlink" title="NTFormer方法详解"></a>NTFormer方法详解</h2><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="NTFormer/NTFormer.png" alt=""></p><h3 id="一、Node2Par标记序列生成器"><a href="#一、Node2Par标记序列生成器" class="headerlink" title="一、Node2Par标记序列生成器"></a>一、Node2Par标记序列生成器</h3><p>Node2Par是一个创新的标记序列生成器，从拓扑和属性两个视图为每个节点构建两种类型的标记序列：邻域标记序列和节点标记序列。</p><h4 id="1-1-邻域标记生成器"><a href="#1-1-邻域标记生成器" class="headerlink" title="1.1 邻域标记生成器"></a>1.1 邻域标记生成器</h4><p>邻域是描述目标节点周围连接的重要元素。作者首先提出邻域特征聚合的通用形式：</p><script type="math/tex;mode=display">X_i^{N,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{(k)} \cdot X_j</script><p>其中：</p><ul><li><script type="math/tex">\mathcal{N}_i^{(k)}</script>表示节点<script type="math/tex">v_i</script>的<script type="math/tex">k</script>跳邻域</li><li><script type="math/tex">W_{ij}^{(k)}</script>表示节点<script type="math/tex">v_j</script>在邻域中的聚合权重</li><li><script type="math/tex">X_j</script>表示节点<script type="math/tex">v_j</script>的属性特征</li><li><script type="math/tex">X_i^{N,(0)} = X_i</script>表示节点本身视为<script type="math/tex">0</script>跳邻域</li></ul><p>为全面表达邻域信息，作者从拓扑和属性两个视图构建邻域标记：</p><script type="math/tex;mode=display">X_i^{t,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{t,(k)} \cdot X_j</script><script type="math/tex;mode=display">X_i^{a,(k)} = \sum_{v_j \in \mathcal{N}_i^{(k)}} W_{ij}^{a,(k)} \cdot X_j</script><p>对应的权重计算为：</p><script type="math/tex;mode=display">W_{ij}^{t,(k)} = A_{ij}^{t,(k)}, \quad A^{t,(k)} = \hat{A}^k</script><script type="math/tex;mode=display">W_{ij}^{a,(k)} = A_{ij}^{a,(k)}, \quad A^{a,(k)} = (A \odot A_s)^k</script><p>其中：</p><ul><li><script type="math/tex">\hat{A}</script>是带自环的归一化邻接矩阵</li><li><script type="math/tex">A_s</script>是通过余弦相似度(<script type="math/tex">\text{Cosine}(X_i, X_j^T)</script>)计算的属性相似性矩阵</li><li><script type="math/tex">A</script>是邻接矩阵</li><li><script type="math/tex">\odot</script>表示元素级乘积(哈达玛积)</li></ul><p>最终生成两种邻域标记序列：拓扑视图<script type="math/tex">S_i^{NE,t} = \{X_i^{t,(0)}, \ldots, X_i^{t,(K)}\}</script>和属性视图<script type="math/tex">S_i^{NE,a} = \{X_i^{a,(0)}, \ldots, X_i^{a,(K)}\}</script>。</p><h4 id="1-2-节点标记生成器"><a href="#1-2-节点标记生成器" class="headerlink" title="1.2 节点标记生成器"></a>1.2 节点标记生成器</h4><p>为解决邻域标记在捕获节点级信息(如长距离依赖)方面的局限，作者引入节点标记生成器，采用两步策略：</p><ol><li>测量节点相似度分数</li><li>选择最相似的节点构建标记序列</li></ol><script type="math/tex;mode=display">S_i^{NO} = \{X_j | v_j \in \text{Top}(M_i)\}</script><p>其中：</p><ul><li><script type="math/tex">M \in \mathbb{R}^{n \times n}</script>是所有节点对的评分矩阵</li><li><script type="math/tex">\text{Top}(\cdot)</script>选择具有最高相似度分数的<script type="math/tex">n_k</script>个节点</li></ul><p>作者从两个视图计算评分矩阵：<br><strong>拓扑视图(<script type="math/tex">M_t</script>)</strong>：采用个性化PageRank(PPR)方法</p><script type="math/tex;mode=display">s_i^{(l)} = r \cdot \hat{A} s_i^{(l-1)} + (1-r) \cdot s_i^0</script><p>其中：</p><ul><li><script type="math/tex">s_i^{(l)}</script>表示第<script type="math/tex">l</script>次传播步骤的PageRank分数</li><li><script type="math/tex">s_i^{(0)} = \hat{A}_i</script>(<script type="math/tex">\hat{A}</script>的第<script type="math/tex">i</script>列)</li><li><script type="math/tex">r</script>是阻尼常数因子</li><li><script type="math/tex">s_i^0</script>是个性化one-hot向量</li></ul><p><strong>属性视图(<script type="math/tex">M_a</script>)</strong>：直接应用余弦相似度计算节点属性相似性。</p><h3 id="二、基于Transformer层的主干网络"><a href="#二、基于Transformer层的主干网络" class="headerlink" title="二、基于Transformer层的主干网络"></a>二、基于Transformer层的主干网络</h3><p>获得四个标记序列(<script type="math/tex">\{S_i^{NE,t}, S_i^{NE,a}, S_i^{NO,t}, S_i^{NO,a}\}</script>)后，作者提出Transformer主干网络。</p><h4 id="2-1-Transformer层输入投影"><a href="#2-1-Transformer层输入投影" class="headerlink" title="2.1 Transformer层输入投影"></a>2.1 Transformer层输入投影</h4><p>以邻域标记<script type="math/tex">S_i^{NE,t}</script>为例，首先进行特征投影：</p><script type="math/tex;mode=display">H_i^{NE,t,(0)} = [X_i^{t,(0)} W_p, \ldots, X_i^{t,(K)} W_p]</script><p>其中<script type="math/tex">W_p \in \mathbb{R}^{d \times d^{(0)}}</script>是投影矩阵。</p><h4 id="2-2-Transformer层处理"><a href="#2-2-Transformer层处理" class="headerlink" title="2.2 Transformer层处理"></a>2.2 Transformer层处理</h4><p>应用标准Transformer层学习节点表示：</p><script type="math/tex;mode=display">H_i^{NE,t,(l)'} = \text{MSA}(H_i^{NE,t,(l)}) + H_i^{NE,t,(l)}</script><script type="math/tex;mode=display">H_i^{NE,t,(l+1)} = \text{FFN}(H_i^{NE,t,(l)'}) + H_i^{NE,t,(l)'}</script><p>其中<script type="math/tex">MSA</script>是多头自注意力机制，<script type="math/tex">FFN</script>是前馈网络。从输出<script type="math/tex">H_i^{NE,t} \in \mathbb{R}^{(K+1) \times d_o}</script>中提取第一行作为节点表示<script type="math/tex">Z_i^{NE,t} \in \mathbb{R}^{1 \times d_o}</script>。<br>同理获得其他表示<script type="math/tex">Z_i^{NE,a}, Z_i^{NO,t}, Z_i^{NO,a}</script>。</p><h4 id="2-3-自适应特征融合"><a href="#2-3-自适应特征融合" class="headerlink" title="2.3 自适应特征融合"></a>2.3 自适应特征融合</h4><p>提出自适应融合模块获取最终节点表示，首先计算各特征的融合权重：</p><script type="math/tex;mode=display">\alpha_i^{NE,t} = \sigma(Z_i^{NE,t} \cdot W_{f_0}) \cdot W_{f_1}</script><p>其中：</p><ul><li><script type="math/tex">W_{f_0} \in \mathbb{R}^{d_o \times d_f}</script>和<script type="math/tex">W_{f_1} \in \mathbb{R}^{d_f \times 1}</script>是可学习参数矩阵</li><li><script type="math/tex">\sigma(\cdot)</script>是激活函数对各权重进行<script type="math/tex">softmax</script>归一化后，加权融合得到最终表示：</li></ul><script type="math/tex;mode=display">Z_i = \alpha_i^{NE,t} \cdot Z_i^{NE,t} + \alpha_i^{NE,a} \cdot Z_i^{NE,a} + \alpha_i^{NO,t} \cdot Z_i^{NO,t} + \alpha_i^{NO,a} \cdot Z_i^{NO,a}</script><h4 id="2-4-预测器与损失函数"><a href="#2-4-预测器与损失函数" class="headerlink" title="2.4 预测器与损失函数"></a>2.4 预测器与损失函数</h4><p>节点分类任务使用MLP预测标签并采用交叉熵损失：</p><script type="math/tex;mode=display">\mathcal{L} = -\sum_{i \in \mathcal{V}_l} Y_i^T \ln \hat{Y}_i, \quad \hat{Y} = \text{MLP}(Z)</script><p>其中<script type="math/tex">\mathcal{V}_l</script>是已知标签节点的集合。</p><h3 id="三、方法创新点与优势"><a href="#三、方法创新点与优势" class="headerlink" title="三、方法创新点与优势"></a>三、方法创新点与优势</h3><ol><li><strong>多视图标记生成</strong>：Node2Par从拓扑和属性两个视图分别生成邻域级和节点级标记序列，全面表达图信息，解决了先前方法仅使用单一类型标记的局限性。</li><li><strong>无需图特定修改</strong>：得益于Node2Par提供的丰富信息，NTFormer仅需标准Transformer层即可学习节点表示，无需特定的位置编码或注意力偏向，增强了模型处理不同类型图的灵活性。</li><li><strong>自适应特征融合</strong>：通过学习自适应权重融合不同类型的标记序列表示，使模型能够根据图的特性(同配性/异配性)灵活调整不同标记的贡献度。<br>实验表明，NTFormer在各种规模的基准数据集上均优于代表性图神经网络和图Transformer方法，特别在异配图上表现突出，验证了其有效性和通用性。</li></ol><hr><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><h2 id="1-PPR计算方法详解"><a href="#1-PPR计算方法详解" class="headerlink" title="1.PPR计算方法详解"></a>1.PPR计算方法详解</h2><p>在NTFormer论文中，PPR（Personalized PageRank）用于计算节点之间的相似度矩阵以生成基于拓扑的节点标记序列。PPR计算的具体方法在论文的IV.B节”Node-based Token Generator”中有详细描述。可以对比<a href="https://epsilonzyj.github.io/posts/Vcr-Graphormer.html">VCR-Graphormer</a>进行理解。</p><h3 id="PPR计算公式"><a href="#PPR计算公式" class="headerlink" title="PPR计算公式"></a>PPR计算公式</h3><p>论文中给出的PPR计算公式如下：</p><script type="math/tex;mode=display">s^{(l)}_i = r \cdot \hat{A}^T s^{(l-1)}_i + (1 - r) \cdot s^0_i</script><p>其中：</p><ul><li><script type="math/tex">s^{(l)}_i \in R^{n \times 1}</script>表示从目标节点<script type="math/tex">v_i</script>在第<script type="math/tex">l</script>次传播步骤的所有节点的PPR分数</li><li><script type="math/tex">s^{(0)}_i = \hat{A}_i</script>表示初始状态</li><li><script type="math/tex">r</script>是阻尼常数因子</li><li><script type="math/tex">s^0_i \in R^{n \times 1}</script>是one-hot个性化向量，其中目标节点对应的元素等于1，其他为0</li></ul><h3 id="计算步骤"><a href="#计算步骤" class="headerlink" title="计算步骤"></a>计算步骤</h3><ol><li><strong>初始化</strong>：对于目标节点<script type="math/tex">v_i</script>，创建一个one-hot向量<script type="math/tex">s^0_i</script>，其中目标节点对应的元素为1，其他为0。</li><li><strong>迭代计算</strong>：使用给定公式进行l次迭代计算PPR分数。每次迭代都考虑当前分数与阻尼因子。</li><li><strong>实际实现</strong>：根据论文描述，在实践中采用了两步传播来估计节点的PPR分数，即进行两次迭代计算。</li><li><strong>构建相似度矩阵</strong>：最终，所有节点对某个目标节点的PPR分数构成相似度矩阵<script type="math/tex">M_t</script>。</li></ol><h3 id="拓扑矩阵A"><a href="#拓扑矩阵A" class="headerlink" title="拓扑矩阵Â"></a>拓扑矩阵Â</h3><p>公式中使用的<script type="math/tex">\hat{A}</script>是归一化的邻接矩阵加上自环，定义为：</p><script type="math/tex;mode=display">\hat{A} = (D + I)^{-1/2}(A + I)(D + I)^{-1/2}</script><p>其中：</p><ul><li>A 是原始邻接矩阵</li><li>D 是对角度矩阵<script type="math/tex;mode=display">D_{ii}=\sum_{j=1}^nA_{ij}</script></li><li>I 是单位矩阵</li></ul><p>这种归一化处理使得PPR计算能够考虑节点的度数信息，更好地反映节点在图中的重要性。<br>通过这种方法，NTFormer能够量化节点间的拓扑关系，为后续生成拓扑视图的节点标记序列提供基础。</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol><li><a href="https://epsilonzyj.github.io/posts/NAGphormer.html">NAGphormer: A Tokenized Graph Transformer For Node Classification In Large Graphs</a></li></ol></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者:</span> <span class="post-copyright-info"><a href="https://epsilonzyj.github.io">EpsilonZ</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接:</span> <span class="post-copyright-info"><a href="https://epsilonzyj.github.io/posts/NTFormer.html">https://epsilonzyj.github.io/posts/NTFormer.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://epsilonzyj.github.io" target="_blank">EpsilonZ's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/Graph-ML/">Graph ML</a><a class="post-meta__tags" href="/tags/Graph-Transformer/">Graph Transformer</a><a class="post-meta__tags" href="/tags/Tokenizing/">Tokenizing</a></div><div class="post-share"><div class="social-share" data-image="/img/GNNCover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/posts/Vcr-Graphormer.html" title="论文阅读：Vcr-Graphormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">论文阅读：Vcr-Graphormer</div></div><div class="info-2"><div class="info-item-1">Vcr-graphormer:A mini-batch graph transformer via virtual connections</div></div></div></a><a class="pagination-related" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">论文阅读：DUALFormer</div></div><div class="info-2"><div class="info-item-1">DUALFormer:Dual Graph Transformer</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/posts/NAGphormer.html" title="论文阅读：NAGphormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-17</div><div class="info-item-2">论文阅读：NAGphormer</div></div><div class="info-2"><div class="info-item-1">NAGphormer:A Tokenized Graph Transformer For Node Classification In Large Graphs</div></div></div></a><a class="pagination-related" href="/posts/SPSE.html" title="论文阅读：Simple Path Structural Encoding"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-27</div><div class="info-item-2">论文阅读：Simple Path Structural Encoding</div></div><div class="info-2"><div class="info-item-1">Simple Path Structural Encoding for Graph Transformers</div></div></div></a><a class="pagination-related" href="/posts/Vcr-Graphormer.html" title="论文阅读：Vcr-Graphormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-21</div><div class="info-item-2">论文阅读：Vcr-Graphormer</div></div><div class="info-2"><div class="info-item-1">Vcr-graphormer:A mini-batch graph transformer via virtual connections</div></div></div></a><a class="pagination-related" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-22</div><div class="info-item-2">论文阅读：DUALFormer</div></div><div class="info-2"><div class="info-item-1">DUALFormer:Dual Graph Transformer</div></div></div></a><a class="pagination-related" href="/posts/Primphormer.html" title="论文阅读：Primphormer"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-25</div><div class="info-item-2">论文阅读：Primphormer</div></div><div class="info-2"><div class="info-item-1">Primphormer:Efficient Graph Transformers with Primal Representations</div></div></div></a><a class="pagination-related" href="/posts/3374f76a.html" title="Graph Transformer中的问题 ｜ Problems With Graph Transformers"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-23</div><div class="info-item-2">Graph Transformer中的问题 ｜ Problems With Graph Transformers</div></div><div class="info-2"><div class="info-item-1">Graph Transformer中存在的问题</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IMG_2179.JPG" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info-name">EpsilonZ</div><div class="author-info-description">To sleep, or to research, that is the question.</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/EpsilonZYJ"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/EpsilonZYJ" target="_blank" title="Github"><i class="fab fa-github" style="color:#24292e"></i></a><a class="social-icon" href="mailto:biopic.tweeter_2u@icloud.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color:#4a7dbe"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Research everyday!</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#Metadata"><span class="toc-number">1.</span> <span class="toc-text">Metadata</span></a></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number"></span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E9%97%AE%E9%A2%98"><span class="toc-number"></span> <span class="toc-text">研究问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-number"></span> <span class="toc-text">方法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#NTFormer%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number"></span> <span class="toc-text">NTFormer方法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81Node2Par%E6%A0%87%E8%AE%B0%E5%BA%8F%E5%88%97%E7%94%9F%E6%88%90%E5%99%A8"><span class="toc-number"></span> <span class="toc-text">一、Node2Par标记序列生成器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E9%82%BB%E5%9F%9F%E6%A0%87%E8%AE%B0%E7%94%9F%E6%88%90%E5%99%A8"><span class="toc-number">1.</span> <span class="toc-text">1.1 邻域标记生成器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E8%8A%82%E7%82%B9%E6%A0%87%E8%AE%B0%E7%94%9F%E6%88%90%E5%99%A8"><span class="toc-number">2.</span> <span class="toc-text">1.2 节点标记生成器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E5%9F%BA%E4%BA%8ETransformer%E5%B1%82%E7%9A%84%E4%B8%BB%E5%B9%B2%E7%BD%91%E7%BB%9C"><span class="toc-number"></span> <span class="toc-text">二、基于Transformer层的主干网络</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-Transformer%E5%B1%82%E8%BE%93%E5%85%A5%E6%8A%95%E5%BD%B1"><span class="toc-number">1.</span> <span class="toc-text">2.1 Transformer层输入投影</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-Transformer%E5%B1%82%E5%A4%84%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">2.2 Transformer层处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-%E8%87%AA%E9%80%82%E5%BA%94%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"><span class="toc-number">3.</span> <span class="toc-text">2.3 自适应特征融合</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-4-%E9%A2%84%E6%B5%8B%E5%99%A8%E4%B8%8E%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">4.</span> <span class="toc-text">2.4 预测器与损失函数</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E6%96%B9%E6%B3%95%E5%88%9B%E6%96%B0%E7%82%B9%E4%B8%8E%E4%BC%98%E5%8A%BF"><span class="toc-number"></span> <span class="toc-text">三、方法创新点与优势</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%99%84%E5%BD%95"><span class="toc-number"></span> <span class="toc-text">附录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-PPR%E8%AE%A1%E7%AE%97%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number"></span> <span class="toc-text">1.PPR计算方法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PPR%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="toc-number"></span> <span class="toc-text">PPR计算公式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4"><span class="toc-number"></span> <span class="toc-text">计算步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%93%E6%89%91%E7%9F%A9%E9%98%B5A"><span class="toc-number"></span> <span class="toc-text">拓扑矩阵Â</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number"></span> <span class="toc-text">References</span></a></li></ol></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/SPSE.html" title="论文阅读：Simple Path Structural Encoding"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：Simple Path Structural Encoding"></a><div class="content"><a class="title" href="/posts/SPSE.html" title="论文阅读：Simple Path Structural Encoding">论文阅读：Simple Path Structural Encoding</a><time datetime="2025-10-27T08:47:27.000Z" title="发表于 2025-10-27 16:47:27">2025-10-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/Primphormer.html" title="论文阅读：Primphormer"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：Primphormer"></a><div class="content"><a class="title" href="/posts/Primphormer.html" title="论文阅读：Primphormer">论文阅读：Primphormer</a><time datetime="2025-10-25T05:20:01.000Z" title="发表于 2025-10-25 13:20:01">2025-10-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/90649c8.html" title="动态图基础 ｜ Dynamic Graphs"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="动态图基础 ｜ Dynamic Graphs"></a><div class="content"><a class="title" href="/posts/90649c8.html" title="动态图基础 ｜ Dynamic Graphs">动态图基础 ｜ Dynamic Graphs</a><time datetime="2025-10-23T16:32:11.000Z" title="发表于 2025-10-24 00:32:11">2025-10-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/3374f76a.html" title="Graph Transformer中的问题 ｜ Problems With Graph Transformers"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Graph Transformer中的问题 ｜ Problems With Graph Transformers"></a><div class="content"><a class="title" href="/posts/3374f76a.html" title="Graph Transformer中的问题 ｜ Problems With Graph Transformers">Graph Transformer中的问题 ｜ Problems With Graph Transformers</a><time datetime="2025-10-23T11:49:46.000Z" title="发表于 2025-10-23 19:49:46">2025-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/GNNCover.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="论文阅读：DUALFormer"></a><div class="content"><a class="title" href="/posts/DUALFormer.html" title="论文阅读：DUALFormer">论文阅读：DUALFormer</a><time datetime="2025-10-22T02:12:34.000Z" title="发表于 2025-10-22 10:12:34">2025-10-22</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/GNNCover.png)"><div id="footer-wrap"><div class="copyright">&copy;2025 By EpsilonZ</div><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (false) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script></div><div class="app-refresh" id="app-refresh" style="position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease"><div class="app-refresh-wrap" style="display:flex;color:#fff;height:100%;align-items:center;justify-content:center"><label>✨ 有新文章啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color:#fff;text-decoration:underline;cursor:pointer">偷偷看一看 👀</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 有新文章啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍗点击食用🍔',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#3b70fc' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script data-pjax>function butterfly_footer_beautify_injector_config(){var t=document.getElementById("footer-wrap");console.log("已挂载butterfly_footer_beautify"),t.insertAdjacentHTML("beforeend",'<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a></p>')}for(var elist="null".split(","),cpage=location.pathname,epage="all",flag=0,i=0;i<elist.length;i++)cpage.includes(elist[i])&&flag++;"all"===epage&&0==flag?butterfly_footer_beautify_injector_config():epage===cpage&&butterfly_footer_beautify_injector_config()</script><script async src="https://unpkg.zhimg.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.min.js"></script><script async src="/js/ali_font.js"></script><div class="js-pjax"><script async>for(var arr=document.getElementsByClassName("recent-post-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset","30"),arr[i].setAttribute("data-wow-iteration","1")</script><script async>for(var arr=document.getElementsByClassName("card-widget"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__zoomIn"),arr[i].setAttribute("data-wow-duration",""),arr[i].setAttribute("data-wow-delay","200ms"),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("flink-list-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("article-sort-item"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__slideInRight"),arr[i].setAttribute("data-wow-duration","1.5s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__flipInY"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script><script async>for(var arr=document.getElementsByClassName("site-card"),i=0;i<arr.length;i++)arr[i].classList.add("wow"),arr[i].classList.add("animate__animated"),arr[i].setAttribute("data-wow-duration","3s"),arr[i].setAttribute("data-wow-delay",""),arr[i].setAttribute("data-wow-offset",""),arr[i].setAttribute("data-wow-iteration","")</script></div><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://cdn.cbd.int/hexo-butterfly-wowjs/lib/wow_init.js"></script></body></html>